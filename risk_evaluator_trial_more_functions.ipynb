{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"10\" halign=\"left\">FNA</th>\n",
       "      <th>...</th>\n",
       "      <th colspan=\"8\" halign=\"left\">diagnostic_consensus</th>\n",
       "      <th colspan=\"2\" halign=\"left\">info</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"10\" halign=\"left\">contra</th>\n",
       "      <th>...</th>\n",
       "      <th colspan=\"6\" halign=\"left\">contra</th>\n",
       "      <th>ipsi</th>\n",
       "      <th>contra</th>\n",
       "      <th colspan=\"2\" halign=\"left\">tumor</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>I</th>\n",
       "      <th>Ia</th>\n",
       "      <th>Ib</th>\n",
       "      <th>II</th>\n",
       "      <th>IIa</th>\n",
       "      <th>IIb</th>\n",
       "      <th>III</th>\n",
       "      <th>IV</th>\n",
       "      <th>V</th>\n",
       "      <th>VI</th>\n",
       "      <th>...</th>\n",
       "      <th>Ib</th>\n",
       "      <th>II</th>\n",
       "      <th>III</th>\n",
       "      <th>IV</th>\n",
       "      <th>V</th>\n",
       "      <th>VII</th>\n",
       "      <th>I</th>\n",
       "      <th>I</th>\n",
       "      <th>t_stage</th>\n",
       "      <th>midline_extension</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>late</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>early</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>late</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>late</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>early</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>545</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>early</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>546</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>late</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>547</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>early</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>548</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>early</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>549</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>early</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>550 rows × 244 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       FNA                                                   ...  \\\n",
       "    contra                                                   ...   \n",
       "         I   Ia   Ib     II   IIa  IIb    III   IV    V  VI  ...   \n",
       "0      NaN  NaN  NaN  False   NaN  NaN  False  NaN  NaN NaN  ...   \n",
       "1      NaN  NaN  NaN   True  True  NaN    NaN  NaN  NaN NaN  ...   \n",
       "2      NaN  NaN  NaN    NaN   NaN  NaN    NaN  NaN  NaN NaN  ...   \n",
       "3      NaN  NaN  NaN    NaN   NaN  NaN    NaN  NaN  NaN NaN  ...   \n",
       "4      NaN  NaN  NaN    NaN   NaN  NaN    NaN  NaN  NaN NaN  ...   \n",
       "..     ...  ...  ...    ...   ...  ...    ...  ...  ...  ..  ...   \n",
       "545    NaN  NaN  NaN    NaN   NaN  NaN    NaN  NaN  NaN NaN  ...   \n",
       "546    NaN  NaN  NaN    NaN   NaN  NaN    NaN  NaN  NaN NaN  ...   \n",
       "547    NaN  NaN  NaN    NaN   NaN  NaN    NaN  NaN  NaN NaN  ...   \n",
       "548    NaN  NaN  NaN    NaN   NaN  NaN    NaN  NaN  NaN NaN  ...   \n",
       "549    NaN  NaN  NaN    NaN   NaN  NaN    NaN  NaN  NaN NaN  ...   \n",
       "\n",
       "    diagnostic_consensus                                                \\\n",
       "                  contra                                   ipsi contra   \n",
       "                      Ib     II    III     IV      V VII      I      I   \n",
       "0                    NaN    NaN    NaN    NaN    NaN NaN    NaN    NaN   \n",
       "1                    NaN    NaN    NaN    NaN    NaN NaN    NaN    NaN   \n",
       "2                    NaN    NaN    NaN    NaN    NaN NaN    NaN    NaN   \n",
       "3                    NaN    NaN    NaN    NaN    NaN NaN    NaN    NaN   \n",
       "4                    NaN    NaN    NaN    NaN    NaN NaN    NaN    NaN   \n",
       "..                   ...    ...    ...    ...    ...  ..    ...    ...   \n",
       "545                False  False  False  False  False NaN  False  False   \n",
       "546                False  False  False  False  False NaN  False  False   \n",
       "547                False  False  False  False  False NaN  False  False   \n",
       "548                False  False  False  False  False NaN  False  False   \n",
       "549                False  False  False  False  False NaN  False  False   \n",
       "\n",
       "       info                    \n",
       "      tumor                    \n",
       "    t_stage midline_extension  \n",
       "0      late              True  \n",
       "1     early             False  \n",
       "2      late              True  \n",
       "3      late              True  \n",
       "4     early             False  \n",
       "..      ...               ...  \n",
       "545   early             False  \n",
       "546    late              True  \n",
       "547   early             False  \n",
       "548   early             False  \n",
       "549   early             False  \n",
       "\n",
       "[550 rows x 244 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import lymph\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "from scipy.special import factorial\n",
    "import matplotlib.pyplot as plt\n",
    "import emcee                      # inference and backends for sample storage\n",
    "from multiprocessing import Pool  # for parallelization of the inference\n",
    "\n",
    "\n",
    "dataset_full = pd.read_csv(\"../lynference/data/cleaned.csv\", header=[0,1,2]) #import data\n",
    "dataset_USZ =  pd.read_csv(\"../lynference/data/cleanedUSZ.csv\", header=[0,1,2]) #import data\n",
    "\n",
    "\n",
    "maxllh =  dataset_USZ['max_llh']\n",
    "t_stage = dataset_USZ['info']\n",
    "ipsi = maxllh.loc[:,'ipsi'].drop(['IIa','IIb','VIII','Ib','IX','VI','X','Ia'],axis = 1)[['I','II','III','IV','V','VII']]\n",
    "contra = maxllh.loc[:,'contra'].drop(['IIa','IIb','VIII','Ib','IX','VI','X','Ia'],axis = 1)[['I','II','III','IV','V','VII']]\n",
    "ipsi_header = header = pd.MultiIndex.from_product([ ['ipsi'], ['I','II','III','IV','V','VII']], names=['', ''])\n",
    "contra_header = pd.MultiIndex.from_product([['contra'], ['I','II','III','IV','V','VII']], names=['', ''])\n",
    "ipsi.columns = ipsi_header\n",
    "contra.columns = contra_header\n",
    "\n",
    "dataset_analyze = pd.concat([t_stage,ipsi,contra],axis = 1)\n",
    "\n",
    "dataset_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = {\n",
    "    ('tumor', 'primary')  : ['I','II', 'III', 'IV','V', 'VII'],\n",
    "    ('lnl'  , 'I') :        [],\n",
    "    ('lnl'  , 'II') :       ['I','III','V'], \n",
    "    ('lnl'  , 'III'):       ['IV','V'], \n",
    "    ('lnl'  , 'IV') :       [],\n",
    "    ('lnl'  , 'V') :        [],\n",
    "    ('lnl'  , 'VII') :      [],\n",
    "}\n",
    "\n",
    "model = lymph.MidlineBilateral(graph = graph,use_mixing= True, trans_symmetric =True)\n",
    "model.modalities = {'CT': [0.76, 0.81],\n",
    "                    'MRI': [0.63, 0.81],\n",
    "                    'PET': [0.86, 0.79],\n",
    "                    'FNA': [0.98, 0.80],\n",
    "                    'diagnostic_consensus': [0.86, 0.81],\n",
    "                    'pathology': [1.0, 1.0],\n",
    "                    'pCT': [0.86, 0.81],\n",
    "                    'max_llh': [1.0, 1.0]\n",
    "                    }\n",
    "\n",
    "\n",
    "# Time prior with p(early) = 0.3\n",
    "def binom_pmf(k: np.ndarray, n: int, p: float):\n",
    "    \"\"\"Binomial PMF\"\"\"\n",
    "    if p > 1. or p < 0.:\n",
    "        raise ValueError(\"Binomial prob must be btw. 0 and 1\")\n",
    "    q = (1. - p)\n",
    "    binom_coeff = factorial(n) / (factorial(k) * factorial(n - k))\n",
    "    return binom_coeff * p**k * q**(n - k)\n",
    "\n",
    "def parametric_binom_pmf(n: int):\n",
    "    \"\"\"Return a parametric binomial PMF\"\"\"\n",
    "    def inner(t, p):\n",
    "        \"\"\"Parametric binomial PMF\"\"\"\n",
    "        return binom_pmf(t, n, p)\n",
    "    return inner\n",
    "\n",
    "max_t = 10\n",
    "model.diag_time_dists[\"early\"] = sp.stats.binom.pmf(np.arange(max_t+1), max_t, 0.3)\n",
    "model.diag_time_dists[\"late\"] = parametric_binom_pmf(max_t)\n",
    "model.patient_data = dataset_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "backend = emcee.backends.HDFBackend(filename = \"../lynference/models/samples.hdf5\")\n",
    "samples = backend.get_chain(flat = True)\n",
    "model.check_and_assign(samples.mean(axis = 0))\n",
    "model.modalities = {'max_llh_diagnose' : [1,0.81]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LNL_ranking_old(model, risks):\n",
    "    state_list = model.noext.ipsi.state_list\n",
    "    lnls = ['I', 'II', 'III', 'IV', 'V', 'VII']\n",
    "    overall_risk_ipsi = {}\n",
    "    overall_risk_contra = {}\n",
    "    for index, lnl in enumerate(lnls):\n",
    "        overall_risk_ipsi[lnl] = risks[np.where((state_list[:,index] == 1))[0]].sum()\n",
    "        overall_risk_contra[lnl] = risks.T[np.where((state_list[:,index] == 1))[0]].sum()\n",
    "\n",
    "    combined_dict = {f'ipsi {key}': value for key, value in overall_risk_ipsi.items()}\n",
    "    combined_dict.update({f'contra {key}': value for key, value in overall_risk_contra.items()})\n",
    "    ranked_combined = sorted(combined_dict.items(), key = lambda item: item[1])\n",
    "    return ranked_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LNL_ranking(model, sampled_risks):\n",
    "    state_list = model.noext.ipsi.state_list\n",
    "    lnls = ['I', 'II', 'III', 'IV', 'V', 'VII']\n",
    "    overall_risk_ipsi = {}\n",
    "    overall_risk_contra = {}\n",
    "    for index, lnl in enumerate(lnls):\n",
    "        overall_risk_ipsi[lnl] = sampled_risks[:,list(np.where((state_list[:,index] == 1))[0])].sum(axis = (1,2))\n",
    "        overall_risk_contra[lnl] = sampled_risks.transpose((0,2,1))[:,list(np.where((state_list[:,index] == 1))[0])].sum(axis = (1,2))\n",
    "\n",
    "    combined_dict = {f'ipsi {key}': value for key, value in overall_risk_ipsi.items()}\n",
    "    combined_dict.update({f'contra {key}': value for key, value in overall_risk_contra.items()})\n",
    "    ranked_combined = sorted(combined_dict.items(), key = lambda item: item[1].mean())\n",
    "    return ranked_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def levels_to_spare(threshold, model, risks, sampled_risks):\n",
    "    \"\"\"Computes which LNLs to irradiate given the threshold, model and the risk of each state.\n",
    "\n",
    "    Args:\n",
    "        threshold (float): Risk threshold we want to apply\n",
    "        model (lymph.Unilateral): lymph.unilateral object with fully analyzed patients\n",
    "        risks (ndarray): Array with the risk of each state\n",
    "\n",
    "    Returns:\n",
    "        _type_: _description_\n",
    "    \"\"\"\n",
    "    state_list = model.noext.ipsi.state_list\n",
    "    lnls = ['I', 'II', 'III', 'IV', 'V', 'VII']\n",
    "\n",
    "    ranked_combined = LNL_ranking_old(model,risks)\n",
    "    total_risk_new = 0\n",
    "    sampled_total_risks_new = np.zeros(sampled_risks.shape[0])\n",
    "    looper = 1\n",
    "    treated_array = np.ones(12)\n",
    "    contra_lnl_indices = []\n",
    "    ipsi_lnl_indices = []\n",
    "    treated_ipsi = []\n",
    "    treated_contra = []\n",
    "    while total_risk_new < threshold:\n",
    "        sampled_total_risks = sampled_total_risks_new\n",
    "        total_risk = total_risk_new\n",
    "        if ipsi_lnl_indices != []:\n",
    "            treated_array[ipsi_lnl_indices] = 0\n",
    "        if contra_lnl_indices != []:\n",
    "            treated_array[np.array(contra_lnl_indices)+6] = 0\n",
    "        lnls_of_interest = ranked_combined[0:looper]\n",
    "        lnls_of_interest_names = [t[0] for t in lnls_of_interest]\n",
    "        contra_lnl_indices = []\n",
    "        ipsi_lnl_indices = []\n",
    "        for i,lnl_looper in enumerate(lnls_of_interest_names):\n",
    "            contra_lnl_indices.append(np.where(np.array(lnls) == lnls_of_interest_names[i].split()[1])[0][0]) if lnl_looper.split()[0] == 'contra' else ipsi_lnl_indices.append(np.where(np.array(lnls) == lnls_of_interest_names[i].split()[1])[0][0])\n",
    "        indices_list_contra = []\n",
    "        indices_list_ipsi = []\n",
    "        for index in contra_lnl_indices:\n",
    "            condition_contra = (state_list[:, index] == 1)\n",
    "            indices_contra = np.where(condition_contra)[0]\n",
    "            indices_list_contra.extend(indices_contra)\n",
    "            unique_contra = np.unique(indices_list_contra)\n",
    "        for index in ipsi_lnl_indices:\n",
    "            condition_ipsi = (state_list[:, index] == 1)\n",
    "            indices_ipsi = np.where(condition_ipsi)[0]\n",
    "            indices_list_ipsi.extend(indices_ipsi)\n",
    "            unique_ipsi = np.unique(indices_list_ipsi)    \n",
    "        if len(ipsi_lnl_indices) == 0:\n",
    "            total_risk_new = risks.T[unique_contra].sum()\n",
    "            sampled_total_risks_new = sampled_risks.transpose((0,2,1))[:,unique_contra].sum(axis = (1,2))\n",
    "        elif len(contra_lnl_indices) == 0:\n",
    "            total_risk_new = risks[unique_ipsi].sum()\n",
    "            sampled_total_risks_new = sampled_risks[:,unique_ipsi].sum(axis = (1,2))\n",
    "        else:\n",
    "            total_risk_new = 0\n",
    "            sampled_total_risks_new = np.zeros(sampled_risks.shape[0])\n",
    "            total_risk_new += risks[unique_ipsi].sum()\n",
    "            total_risk_new += risks.T[unique_contra][:,[np.setdiff1d(np.array(range(64)),unique_ipsi)]].sum()\n",
    "            sampled_total_risks_new += sampled_risks[:,unique_ipsi].sum(axis = (1,2))\n",
    "            sampled_total_risks_new += sampled_risks.transpose((0,2,1))[:,unique_contra][:,:,list(np.setdiff1d(np.array(range(64)),unique_ipsi))].sum(axis = (1,2))\n",
    "\n",
    "        spared_lnls = lnls_of_interest[:-1]\n",
    "        treated_lnls = ranked_combined[looper-1:]\n",
    "        looper += 1\n",
    "    for to_treat in treated_lnls:\n",
    "        if to_treat[0].split()[0] == 'ipsi':\n",
    "            treated_ipsi.append(to_treat[0].split()[1])\n",
    "        else: \n",
    "            treated_contra.append(to_treat[0].split()[1])\n",
    "    return spared_lnls, total_risk, ranked_combined, treated_lnls, treated_array, treated_ipsi, treated_contra,sampled_total_risks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def risk_sampled(samples, model, t_stage, given_diagnoses, midline_extension, thin = 89):\n",
    "    sampled_risks = np.zeros(shape=(len(samples[::thin]),64,64), dtype=float)\n",
    "    for i, sample in enumerate(np.random.permutation(samples[::thin])):\n",
    "        sampled_risks[i] = model.risk(given_params = sample, t_stage = t_stage, given_diagnoses = given_diagnoses,midline_extension=midline_extension) \n",
    "    mean_risk = sampled_risks.mean(axis = 0)\n",
    "    return sampled_risks, mean_risk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('ipsi IV', 0.06313844621081308), ('ipsi III', 0.3812858014795705), ('ipsi I', 0.9999999999999998), ('ipsi II', 0.9999999999999998), ('ipsi V', 0.9999999999999998), ('contra II', 0.9999999999999998), ('contra III', 0.9999999999999998), ('contra IV', 0.9999999999999998), ('contra V', 0.9999999999999998), ('contra VII', 0.9999999999999998)]\n",
      "6.521793425811631\n",
      "[('ipsi VII', 0.027127698062365944), ('contra I', 0.039194956235152595)]\n"
     ]
    }
   ],
   "source": [
    "diagnose = {'max_llh_diagnose':{\n",
    "    \"ipsi\": {\n",
    "        \"I\": 1,\n",
    "        \"II\": 1,\n",
    "        \"III\": 0,\n",
    "        \"IV\": 0,\n",
    "        \"V\": 1,\n",
    "        \"VII\": 0,\n",
    "    },\n",
    "    \"contra\": {\n",
    "        \"I\": 0,\n",
    "        \"II\": 1,\n",
    "        \"III\": 1,\n",
    "        \"IV\": 1,\n",
    "        \"V\": 1,\n",
    "        \"VII\": 1,\n",
    "    }\n",
    "}}\n",
    "sampled_risks, risk = risk_sampled(samples = samples, model = model, t_stage = 'late', given_diagnoses= diagnose, midline_extension= False)     \n",
    "spared_lnls, total_risk, ranked_combined, treated_lnls, treated_array, treated_ipsi, treated_contra, sampled_total_risks = levels_to_spare(0.10, model, risk, sampled_risks)\n",
    "print(treated_lnls)\n",
    "print(total_risk*100)\n",
    "print(spared_lnls)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ipsi VII', 0.027127698062365944),\n",
       " ('contra I', 0.039194956235152595),\n",
       " ('ipsi IV', 0.06313844621081308),\n",
       " ('ipsi III', 0.3812858014795705),\n",
       " ('ipsi I', 0.9999999999999998),\n",
       " ('ipsi II', 0.9999999999999998),\n",
       " ('ipsi V', 0.9999999999999998),\n",
       " ('contra II', 0.9999999999999998),\n",
       " ('contra III', 0.9999999999999998),\n",
       " ('contra IV', 0.9999999999999998),\n",
       " ('contra V', 0.9999999999999998),\n",
       " ('contra VII', 0.9999999999999998)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ranked_combined"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combination analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "# Sample array with different entry combinations\n",
    "data = np.array(dataset_analyze)\n",
    "\n",
    "entry_combinations_with_indexes = defaultdict(list)\n",
    "for index, row in enumerate(data):\n",
    "    combination = tuple(row)\n",
    "    entry_combinations_with_indexes[combination].append(index)\n",
    "USZ_counts = []\n",
    "USZ_combinations = []\n",
    "USZ_indexes = []\n",
    "# Print the most common combinations, their USZ_counts, and indexes\n",
    "for combination, indexes in entry_combinations_with_indexes.items():\n",
    "    count = len(indexes)\n",
    "    USZ_indexes.append(indexes)\n",
    "    # print(f\"Combination: {combination}, Count: {count}, Indexes: {indexes}\")\n",
    "    USZ_counts.append(count)\n",
    "    USZ_combinations.append(combination)\n",
    "\n",
    "lnls = ['I','II', 'III', 'IV','V', 'VII']\n",
    "t_stage = []\n",
    "midline_extension = []\n",
    "invovlvement_ipsi_USZ = []\n",
    "invovlvement_contra_USZ = []\n",
    "for diagnose_type in USZ_combinations:\n",
    "    involved_ipsi = []\n",
    "    involved_contra = []\n",
    "    t_stage.append(diagnose_type[0])\n",
    "    midline_extension.append(diagnose_type[1])\n",
    "    for lnl_looper, involved_level in enumerate(lnls):\n",
    "        if diagnose_type[lnl_looper +2] == True:\n",
    "            involved_ipsi.append(involved_level) \n",
    "        if diagnose_type[lnl_looper +8] == True:\n",
    "            involved_contra.append(involved_level)\n",
    "    invovlvement_ipsi_USZ.append(involved_ipsi)\n",
    "    invovlvement_contra_USZ.append(involved_contra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df2 = pd.DataFrame(USZ_combinations)\n",
    "# df2.to_csv('involvement_combinations_USZ.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analysis_treated_lnls(combinations):\n",
    "    treatment_array = np.zeros((len(combinations),12))\n",
    "    top3_spared = []\n",
    "    diagnose_looper = {'max_llh_diagnose':{\n",
    "        \"ipsi\": {\n",
    "            \"I\": 0,\n",
    "            \"II\": 0,\n",
    "            \"III\": 0,\n",
    "            \"IV\": 0,\n",
    "            \"V\": 0,\n",
    "            \"VII\": 0,\n",
    "        },\n",
    "        \"contra\": {\n",
    "            \"I\": 0,\n",
    "            \"II\": 0,\n",
    "            \"III\": 0,\n",
    "            \"IV\": 0,\n",
    "            \"V\": 0,\n",
    "            \"VII\": 0,\n",
    "        }\n",
    "    }}\n",
    "    treated_lnls_all = []\n",
    "    treated_lnls_no_risk = []\n",
    "    total_risks = np.zeros(len(combinations))\n",
    "    treated_ipsi_all = []\n",
    "    treated_contra_all = []\n",
    "    for index, pattern in enumerate(combinations):\n",
    "        treated_looper = set()\n",
    "        stage = pattern[0]\n",
    "        midline_extension = pattern[1]\n",
    "        counter_ipsi = 0\n",
    "        for lnl_ipsi, status in diagnose_looper['max_llh_diagnose']['ipsi'].items():\n",
    "            diagnose_looper['max_llh_diagnose']['ipsi'][lnl_ipsi] = pattern[2+counter_ipsi]\n",
    "            counter_ipsi += 1\n",
    "        counter_contra = 0\n",
    "        for lnl_contra, status in diagnose_looper['max_llh_diagnose']['contra'].items():\n",
    "            diagnose_looper['max_llh_diagnose']['contra'][lnl_contra] = pattern[8+counter_contra]\n",
    "            counter_contra += 1\n",
    "        risk = model.risk(given_params = samples.mean(axis = 0), t_stage = stage, given_diagnoses = diagnose_looper,midline_extension=midline_extension)     \n",
    "        spared_lnls, total_risk, ranked_combined, treated_lnls, treated_array, treated_ipsi, treated_contra =levels_to_spare(0.10, model, risk)\n",
    "        for i in treated_lnls:\n",
    "            treated_looper.add(i[0])\n",
    "        treated_lnls_all.append(treated_lnls)\n",
    "        treated_lnls_no_risk.append(treated_looper)\n",
    "        treatment_array[index] = treated_array\n",
    "        total_risks[index] = total_risk\n",
    "        top3_spared.append(spared_lnls[::-1][:3])\n",
    "        treated_ipsi_all.append(treated_ipsi)\n",
    "        treated_contra_all.append(treated_contra)\n",
    "    return treated_lnls_no_risk, treated_lnls_all, treatment_array, top3_spared, total_risks, treated_ipsi_all, treated_contra_all\n",
    "\n",
    "def analysis_treated_lnls_sampled(combinations):\n",
    "    treatment_array = np.zeros((len(combinations),12))\n",
    "    top3_spared = []\n",
    "    diagnose_looper = {'max_llh_diagnose':{\n",
    "        \"ipsi\": {\n",
    "            \"I\": 0,\n",
    "            \"II\": 0,\n",
    "            \"III\": 0,\n",
    "            \"IV\": 0,\n",
    "            \"V\": 0,\n",
    "            \"VII\": 0,\n",
    "        },\n",
    "        \"contra\": {\n",
    "            \"I\": 0,\n",
    "            \"II\": 0,\n",
    "            \"III\": 0,\n",
    "            \"IV\": 0,\n",
    "            \"V\": 0,\n",
    "            \"VII\": 0,\n",
    "        }\n",
    "    }}\n",
    "    treated_lnls_all = []\n",
    "    treated_lnls_no_risk = []\n",
    "    total_risks = np.zeros(len(combinations))\n",
    "    sampled_risks_array = np.zeros((len(combinations),214))\n",
    "    treated_ipsi_all = []\n",
    "    treated_contra_all = []\n",
    "    for index, pattern in enumerate(combinations):\n",
    "        treated_looper = set()\n",
    "        stage = pattern[0]\n",
    "        midline_extension = pattern[1]\n",
    "        counter_ipsi = 0\n",
    "        for lnl_ipsi, status in diagnose_looper['max_llh_diagnose']['ipsi'].items():\n",
    "            diagnose_looper['max_llh_diagnose']['ipsi'][lnl_ipsi] = pattern[2+counter_ipsi]\n",
    "            counter_ipsi += 1\n",
    "        counter_contra = 0\n",
    "        for lnl_contra, status in diagnose_looper['max_llh_diagnose']['contra'].items():\n",
    "            diagnose_looper['max_llh_diagnose']['contra'][lnl_contra] = pattern[8+counter_contra]\n",
    "            counter_contra += 1\n",
    "        sampled_risks, mean_risk = risk_sampled(samples = samples, model = model, t_stage = stage, given_diagnoses=diagnose_looper,midline_extension=midline_extension)     \n",
    "        spared_lnls, total_risk, ranked_combined, treated_lnls, treated_array, treated_ipsi, treated_contra, sampled_total_risks =levels_to_spare(0.10, model, mean_risk, sampled_risks)\n",
    "        for i in treated_lnls:\n",
    "            treated_looper.add(i[0])\n",
    "        treated_lnls_all.append(treated_lnls)\n",
    "        treated_lnls_no_risk.append(treated_looper)\n",
    "        treatment_array[index] = treated_array\n",
    "        total_risks[index] = total_risk\n",
    "        sampled_risks_array[index] = sampled_total_risks\n",
    "        top3_spared.append(spared_lnls[::-1][:3])\n",
    "        treated_ipsi_all.append(treated_ipsi)\n",
    "        treated_contra_all.append(treated_contra)\n",
    "    return treated_lnls_no_risk, treated_lnls_all, treatment_array, top3_spared, total_risks, treated_ipsi_all, treated_contra_all, sampled_risks_array\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def count_numnber_treatments(treated_lnls_no_risk):\n",
    "    set_counts = {}\n",
    "    # Iterate through the list and update the counts in the dictionary\n",
    "    for value in treated_lnls_no_risk:\n",
    "        frozen_set = frozenset(value)  # Convert the set to a frozenset\n",
    "        if frozen_set in set_counts:\n",
    "            set_counts[frozen_set] += 1\n",
    "        else:\n",
    "            set_counts[frozen_set] = 1\n",
    "    return set_counts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.07627213 0.37259436]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.2018923734630237"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lower = (1-0.95)/2*100\n",
    "upper = 100- lower\n",
    "ci = np.percentile((sampled_risks[:,0,1]+sampled_risks[:,0,2]),[lower,upper])\n",
    "(sampled_risks[:,0,1]+sampled_risks[:,0,2])\n",
    "print(ci*100)\n",
    "np.mean((sampled_risks[:,0,1]+sampled_risks[:,0,2]))*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/yoel/Documents/GitHub/home_workspace_imported/risk_evaluator_trial copy.ipynb Cell 16\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/yoel/Documents/GitHub/home_workspace_imported/risk_evaluator_trial%20copy.ipynb#X15sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m usz_treated_lnls_no_risk, usz_treated_lnls_all, usz_treatment_array, usz_top3_spared, usz_total_risks, usz_treated_ipsi, usz_treated_contra, usz_sampled_risks_array \u001b[39m=\u001b[39m analysis_treated_lnls_sampled(USZ_combinations)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/yoel/Documents/GitHub/home_workspace_imported/risk_evaluator_trial%20copy.ipynb#X15sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m usz_set_counts \u001b[39m=\u001b[39m count_numnber_treatments(usz_treated_lnls_no_risk)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/yoel/Documents/GitHub/home_workspace_imported/risk_evaluator_trial%20copy.ipynb#X15sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mlen\u001b[39m(usz_set_counts)\n",
      "\u001b[1;32m/home/yoel/Documents/GitHub/home_workspace_imported/risk_evaluator_trial copy.ipynb Cell 16\u001b[0m line \u001b[0;36m9\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/yoel/Documents/GitHub/home_workspace_imported/risk_evaluator_trial%20copy.ipynb#X15sZmlsZQ%3D%3D?line=88'>89</a>\u001b[0m     diagnose_looper[\u001b[39m'\u001b[39m\u001b[39mmax_llh_diagnose\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m'\u001b[39m\u001b[39mcontra\u001b[39m\u001b[39m'\u001b[39m][lnl_contra] \u001b[39m=\u001b[39m pattern[\u001b[39m8\u001b[39m\u001b[39m+\u001b[39mcounter_contra]\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/yoel/Documents/GitHub/home_workspace_imported/risk_evaluator_trial%20copy.ipynb#X15sZmlsZQ%3D%3D?line=89'>90</a>\u001b[0m     counter_contra \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/yoel/Documents/GitHub/home_workspace_imported/risk_evaluator_trial%20copy.ipynb#X15sZmlsZQ%3D%3D?line=90'>91</a>\u001b[0m sampled_risks, mean_risk \u001b[39m=\u001b[39m risk_sampled(samples \u001b[39m=\u001b[39;49m samples, model \u001b[39m=\u001b[39;49m model, t_stage \u001b[39m=\u001b[39;49m stage, given_diagnoses\u001b[39m=\u001b[39;49mdiagnose_looper,midline_extension\u001b[39m=\u001b[39;49mmidline_extension)     \n\u001b[1;32m     <a href='vscode-notebook-cell:/home/yoel/Documents/GitHub/home_workspace_imported/risk_evaluator_trial%20copy.ipynb#X15sZmlsZQ%3D%3D?line=91'>92</a>\u001b[0m spared_lnls, total_risk, ranked_combined, treated_lnls, treated_array, treated_ipsi, treated_contra, sampled_total_risks \u001b[39m=\u001b[39mlevels_to_spare(\u001b[39m0.10\u001b[39m, model, mean_risk, sampled_risks)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/yoel/Documents/GitHub/home_workspace_imported/risk_evaluator_trial%20copy.ipynb#X15sZmlsZQ%3D%3D?line=92'>93</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m treated_lnls:\n",
      "\u001b[1;32m/home/yoel/Documents/GitHub/home_workspace_imported/risk_evaluator_trial copy.ipynb Cell 16\u001b[0m line \u001b[0;36m4\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/yoel/Documents/GitHub/home_workspace_imported/risk_evaluator_trial%20copy.ipynb#X15sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m sampled_risks \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mzeros(shape\u001b[39m=\u001b[39m(\u001b[39mlen\u001b[39m(samples[::thin]),\u001b[39m64\u001b[39m,\u001b[39m64\u001b[39m), dtype\u001b[39m=\u001b[39m\u001b[39mfloat\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/yoel/Documents/GitHub/home_workspace_imported/risk_evaluator_trial%20copy.ipynb#X15sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mfor\u001b[39;00m i, sample \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(np\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39mpermutation(samples[::thin])):\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/yoel/Documents/GitHub/home_workspace_imported/risk_evaluator_trial%20copy.ipynb#X15sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     sampled_risks[i] \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mrisk(given_params \u001b[39m=\u001b[39;49m sample, t_stage \u001b[39m=\u001b[39;49m t_stage, given_diagnoses \u001b[39m=\u001b[39;49m given_diagnoses,midline_extension\u001b[39m=\u001b[39;49mmidline_extension) \n\u001b[1;32m      <a href='vscode-notebook-cell:/home/yoel/Documents/GitHub/home_workspace_imported/risk_evaluator_trial%20copy.ipynb#X15sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m mean_risk \u001b[39m=\u001b[39m sampled_risks\u001b[39m.\u001b[39mmean(axis \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/yoel/Documents/GitHub/home_workspace_imported/risk_evaluator_trial%20copy.ipynb#X15sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39mreturn\u001b[39;00m sampled_risks, mean_risk\n",
      "File \u001b[0;32m~/Documents/GitHub/home_workspace_imported/.venv/lib/python3.10/site-packages/lymph/midline.py:459\u001b[0m, in \u001b[0;36mMidlineBilateral.risk\u001b[0;34m(self, given_params, midline_extension, **kwargs)\u001b[0m\n\u001b[1;32m    445\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Compute the risk of nodal involvement given a specific diagnose.\u001b[39;00m\n\u001b[1;32m    446\u001b[0m \n\u001b[1;32m    447\u001b[0m \u001b[39mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    456\u001b[0m \u001b[39m    respective :class:`Bilateral` instance gets called.\u001b[39;00m\n\u001b[1;32m    457\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    458\u001b[0m \u001b[39mif\u001b[39;00m given_params \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 459\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcheck_and_assign(given_params)\n\u001b[1;32m    461\u001b[0m \u001b[39mif\u001b[39;00m midline_extension:\n\u001b[1;32m    462\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mext\u001b[39m.\u001b[39mrisk(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/Documents/GitHub/home_workspace_imported/.venv/lib/python3.10/site-packages/lymph/midline.py:370\u001b[0m, in \u001b[0;36mMidlineBilateral.check_and_assign\u001b[0;34m(self, new_params)\u001b[0m\n\u001b[1;32m    365\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mValueError\u001b[39;00m \u001b[39mas\u001b[39;00m val_err:\n\u001b[1;32m    366\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    367\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mParameters for marginalization over diagnose times are invalid\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    368\u001b[0m     ) \u001b[39mfrom\u001b[39;00m \u001b[39mval_err\u001b[39;00m\n\u001b[0;32m--> 370\u001b[0m \u001b[39mif\u001b[39;00m new_spread_probs\u001b[39m.\u001b[39mshape \u001b[39m!=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mspread_probs\u001b[39m.\u001b[39mshape:\n\u001b[1;32m    371\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    372\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mShape of provided spread parameters does not match network\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    373\u001b[0m     )\n\u001b[1;32m    374\u001b[0m \u001b[39mif\u001b[39;00m np\u001b[39m.\u001b[39many(\u001b[39m0.\u001b[39m \u001b[39m>\u001b[39m new_spread_probs) \u001b[39mor\u001b[39;00m np\u001b[39m.\u001b[39many(new_spread_probs \u001b[39m>\u001b[39m \u001b[39m1.\u001b[39m):\n",
      "File \u001b[0;32m~/Documents/GitHub/home_workspace_imported/.venv/lib/python3.10/site-packages/lymph/midline.py:170\u001b[0m, in \u001b[0;36mMidlineBilateral.spread_probs\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[39m@property\u001b[39m\n\u001b[1;32m    159\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mspread_probs\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m np\u001b[39m.\u001b[39mndarray:\n\u001b[1;32m    160\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"These are the probabilities representing the spread of cancer along\u001b[39;00m\n\u001b[1;32m    161\u001b[0m \u001b[39m    lymphatic drainage pathways per timestep.\u001b[39;00m\n\u001b[1;32m    162\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[39m    +-------------+-------------+\u001b[39;00m\n\u001b[1;32m    169\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 170\u001b[0m     \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39mconcatenate([\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbase_probs, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrans_probs])\n",
      "File \u001b[0;32m~/Documents/GitHub/home_workspace_imported/.venv/lib/python3.10/site-packages/lymph/midline.py:102\u001b[0m, in \u001b[0;36mMidlineBilateral.base_probs\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Base probabilities of metastatic lymphatic spread from the tumor(s)\u001b[39;00m\n\u001b[1;32m     84\u001b[0m \u001b[39mto the lymph node levels. This will return the following concatenation of\u001b[39;00m\n\u001b[1;32m     85\u001b[0m \u001b[39mbase spread probs depending on whether ``use_mixing`` is set to ``True`` or\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[39mWhen setting these, one needs to provide the respective shape.\u001b[39;00m\n\u001b[1;32m     99\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    100\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39muse_mixing:\n\u001b[1;32m    101\u001b[0m     \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39mconcatenate([\n\u001b[0;32m--> 102\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mext\u001b[39m.\u001b[39;49mipsi\u001b[39m.\u001b[39;49mbase_probs,\n\u001b[1;32m    103\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnoext\u001b[39m.\u001b[39mcontra\u001b[39m.\u001b[39mbase_probs,\n\u001b[1;32m    104\u001b[0m         [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39malpha_mix],\n\u001b[1;32m    105\u001b[0m     ])\n\u001b[1;32m    106\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    107\u001b[0m     \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39mconcatenate([\n\u001b[1;32m    108\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mext\u001b[39m.\u001b[39mipsi\u001b[39m.\u001b[39mbase_probs,\n\u001b[1;32m    109\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mext\u001b[39m.\u001b[39mcontra\u001b[39m.\u001b[39mbase_probs,\n\u001b[1;32m    110\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnoext\u001b[39m.\u001b[39mcontra\u001b[39m.\u001b[39mbase_probs,\n\u001b[1;32m    111\u001b[0m     ])\n",
      "File \u001b[0;32m~/Documents/GitHub/home_workspace_imported/.venv/lib/python3.10/site-packages/lymph/unilateral.py:190\u001b[0m, in \u001b[0;36mUnilateral.base_probs\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[39m@property\u001b[39m\n\u001b[1;32m    174\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mbase_probs\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    175\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"The spread probablities parametrizing the edges that represent the\u001b[39;00m\n\u001b[1;32m    176\u001b[0m \u001b[39m    lymphatic drainage from the tumor(s) to the individual lymph node\u001b[39;00m\n\u001b[1;32m    177\u001b[0m \u001b[39m    levels. This array is composed of these elements:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    188\u001b[0m \u001b[39m    so it can be recomputed with the new parameters.\u001b[39;00m\n\u001b[1;32m    189\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 190\u001b[0m     \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39;49marray([edge\u001b[39m.\u001b[39;49mt \u001b[39mfor\u001b[39;49;00m edge \u001b[39min\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbase_edges], dtype\u001b[39m=\u001b[39;49m\u001b[39mfloat\u001b[39;49m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "usz_treated_lnls_no_risk, usz_treated_lnls_all, usz_treatment_array, usz_top3_spared, usz_total_risks, usz_treated_ipsi, usz_treated_contra, usz_sampled_risks_array = analysis_treated_lnls_sampled(USZ_combinations)\n",
    "usz_set_counts = count_numnber_treatments(usz_treated_lnls_no_risk)\n",
    "len(usz_set_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(77, 2)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lower = (1-0.95)/2*100\n",
    "upper = 100- lower\n",
    "ci = np.zeros((77,2))\n",
    "for index in range(77):\n",
    "    ci[index] = np.percentile(usz_sampled_risks_array[index],[lower,upper])\n",
    "\n",
    "ci.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(usz_treatment_array)\n",
    "df.to_csv('treatment_array_010_new.csv')\n",
    "\n",
    "data_export_usz = pd.DataFrame({'Percentage of patients': np.array(USZ_counts)/287,\n",
    "                                'T-stage': t_stage,\n",
    "                                'Midline Extension': midline_extension,\n",
    "                                'Involvement Ipsi' : invovlvement_ipsi_USZ,\n",
    "                                'Involvement Contra': invovlvement_contra_USZ,\n",
    "                                'Treated Ipsi':  usz_treated_ipsi,\n",
    "                                'Treated Contra': usz_treated_contra,\n",
    "                                'risk': usz_total_risks,\n",
    "                                'lower bound': ci.T[0],\n",
    "                                'upper bound': ci.T[1],\n",
    "                                'top 3 spared lnls risk': usz_top3_spared\n",
    "\n",
    "})\n",
    "data_export_usz.to_csv('analyzed_usz_data_010_new.csv', sep = ';', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "usz_treated_lnls_no_risk, usz_treated_lnls_all = analysis_treated_lnls(USZ_combinations)\n",
    "usz_set_counts = count_numnber_treatments(usz_treated_lnls_no_risk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([], dtype=int64),)\n"
     ]
    }
   ],
   "source": [
    "number_of_repetitions = []\n",
    "for key, value in usz_set_counts.items():\n",
    "    number_of_repetitions.append(value)\n",
    "usz_set_counts[frozenset({'ipsi II'})]\n",
    "asdf = (np.array(USZ_combinations) == ['late',False,False,True,False,False,False,False,False,False,False,False,False,False,])\n",
    "# Define the condition (e.g., all 'True' values)\n",
    "condition = (asdf[:, 1:] == 'True').all(axis=1)\n",
    "\n",
    "# Find indices where the condition is met\n",
    "indices = np.where(condition)\n",
    "\n",
    "print(indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Here we repeat the analysis for all possible combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "\n",
    "# Define the possible values for the first element and the 13 boolean values\n",
    "first_element_values = ['early', 'late']\n",
    "boolean_values = [True, False]\n",
    "\n",
    "# Generate all possible combinations using nested loops\n",
    "all_combinations = []\n",
    "\n",
    "for first_element in first_element_values:\n",
    "    for bool_combination in product(boolean_values, repeat=13):\n",
    "        vector = (first_element,) + bool_combination\n",
    "        all_combinations.append(vector)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[0;32m~/Documents/GitHub/home_workspace_imported/.venv/lib/python3.10/site-packages/lymph/unilateral.py:495\u001b[0m, in \u001b[0;36mUnilateral.transition_matrix\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    494\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 495\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_transition_matrix\n\u001b[1;32m    496\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m:\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Unilateral' object has no attribute '_transition_matrix'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/yoel/Documents/GitHub/home_workspace_imported/risk_evaluator_trial.ipynb Cell 18\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/yoel/Documents/GitHub/home_workspace_imported/risk_evaluator_trial.ipynb#X23sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m full_treated_lnls_no_risk, full_treated_lnls_all \u001b[39m=\u001b[39m analysis_treated_lnls(all_combinations)\n",
      "\u001b[1;32m/home/yoel/Documents/GitHub/home_workspace_imported/risk_evaluator_trial.ipynb Cell 18\u001b[0m line \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/yoel/Documents/GitHub/home_workspace_imported/risk_evaluator_trial.ipynb#X23sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m     diagnose_looper[\u001b[39m'\u001b[39m\u001b[39mmax_llh_diagnose\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m'\u001b[39m\u001b[39mcontra\u001b[39m\u001b[39m'\u001b[39m][lnl_contra] \u001b[39m=\u001b[39m pattern[\u001b[39m8\u001b[39m\u001b[39m+\u001b[39mcounter_contra]\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/yoel/Documents/GitHub/home_workspace_imported/risk_evaluator_trial.ipynb#X23sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m     counter_contra \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/yoel/Documents/GitHub/home_workspace_imported/risk_evaluator_trial.ipynb#X23sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m risk \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mrisk(given_params \u001b[39m=\u001b[39;49m samples\u001b[39m.\u001b[39;49mmean(axis \u001b[39m=\u001b[39;49m \u001b[39m0\u001b[39;49m), t_stage \u001b[39m=\u001b[39;49m stage, given_diagnoses \u001b[39m=\u001b[39;49m diagnose_looper,midline_extension\u001b[39m=\u001b[39;49mmidline_extension)     \n\u001b[1;32m     <a href='vscode-notebook-cell:/home/yoel/Documents/GitHub/home_workspace_imported/risk_evaluator_trial.ipynb#X23sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m spared_lnls, total_risk, ranked_combined, treated_lnls \u001b[39m=\u001b[39mlevels_to_spare(\u001b[39m0.10\u001b[39m, model, risk)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/yoel/Documents/GitHub/home_workspace_imported/risk_evaluator_trial.ipynb#X23sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m treated_lnls:\n",
      "File \u001b[0;32m~/Documents/GitHub/home_workspace_imported/.venv/lib/python3.10/site-packages/lymph/midline.py:459\u001b[0m, in \u001b[0;36mMidlineBilateral.risk\u001b[0;34m(self, given_params, midline_extension, **kwargs)\u001b[0m\n\u001b[1;32m    445\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Compute the risk of nodal involvement given a specific diagnose.\u001b[39;00m\n\u001b[1;32m    446\u001b[0m \n\u001b[1;32m    447\u001b[0m \u001b[39mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    456\u001b[0m \u001b[39m    respective :class:`Bilateral` instance gets called.\u001b[39;00m\n\u001b[1;32m    457\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    458\u001b[0m \u001b[39mif\u001b[39;00m given_params \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 459\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcheck_and_assign(given_params)\n\u001b[1;32m    461\u001b[0m \u001b[39mif\u001b[39;00m midline_extension:\n\u001b[1;32m    462\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mext\u001b[39m.\u001b[39mrisk(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/Documents/GitHub/home_workspace_imported/.venv/lib/python3.10/site-packages/lymph/midline.py:379\u001b[0m, in \u001b[0;36mMidlineBilateral.check_and_assign\u001b[0;34m(self, new_params)\u001b[0m\n\u001b[1;32m    374\u001b[0m \u001b[39mif\u001b[39;00m np\u001b[39m.\u001b[39many(\u001b[39m0.\u001b[39m \u001b[39m>\u001b[39m new_spread_probs) \u001b[39mor\u001b[39;00m np\u001b[39m.\u001b[39many(new_spread_probs \u001b[39m>\u001b[39m \u001b[39m1.\u001b[39m):\n\u001b[1;32m    375\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    376\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mSpread probs must be between 0 and 1\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    377\u001b[0m     )\n\u001b[0;32m--> 379\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mspread_probs \u001b[39m=\u001b[39m new_spread_probs\n",
      "File \u001b[0;32m~/Documents/GitHub/home_workspace_imported/.venv/lib/python3.10/site-packages/lymph/midline.py:179\u001b[0m, in \u001b[0;36mMidlineBilateral.spread_probs\u001b[0;34m(self, new_params)\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Set the new spread probabilities and the mixing parameter\u001b[39;00m\n\u001b[1;32m    175\u001b[0m \u001b[39m:math:`\\\\alpha`.\u001b[39;00m\n\u001b[1;32m    176\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    177\u001b[0m num_base_probs \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbase_probs)\n\u001b[0;32m--> 179\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbase_probs  \u001b[39m=\u001b[39m new_params[:num_base_probs]\n\u001b[1;32m    180\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrans_probs \u001b[39m=\u001b[39m new_params[num_base_probs:]\n",
      "File \u001b[0;32m~/Documents/GitHub/home_workspace_imported/.venv/lib/python3.10/site-packages/lymph/midline.py:136\u001b[0m, in \u001b[0;36mMidlineBilateral.base_probs\u001b[0;34m(self, new_params)\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnoext\u001b[39m.\u001b[39mcontra\u001b[39m.\u001b[39mbase_probs \u001b[39m=\u001b[39m new_params[\u001b[39m2\u001b[39m\u001b[39m*\u001b[39mk:\u001b[39m3\u001b[39m\u001b[39m*\u001b[39mk]\n\u001b[1;32m    135\u001b[0m \u001b[39m# avoid unnecessary double computation of ipsilateral transition matrix\u001b[39;00m\n\u001b[0;32m--> 136\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnoext\u001b[39m.\u001b[39mipsi\u001b[39m.\u001b[39m_transition_matrix \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mext\u001b[39m.\u001b[39;49mipsi\u001b[39m.\u001b[39;49mtransition_matrix\n",
      "File \u001b[0;32m~/Documents/GitHub/home_workspace_imported/.venv/lib/python3.10/site-packages/lymph/unilateral.py:497\u001b[0m, in \u001b[0;36mUnilateral.transition_matrix\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    495\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_transition_matrix\n\u001b[1;32m    496\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m:\n\u001b[0;32m--> 497\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_gen_transition_matrix()\n\u001b[1;32m    498\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_transition_matrix\n",
      "File \u001b[0;32m~/Documents/GitHub/home_workspace_imported/.venv/lib/python3.10/site-packages/lymph/unilateral.py:457\u001b[0m, in \u001b[0;36mUnilateral._gen_transition_matrix\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate \u001b[39m=\u001b[39m state\n\u001b[1;32m    456\u001b[0m \u001b[39mfor\u001b[39;00m j \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mallowed_transitions[i]:\n\u001b[0;32m--> 457\u001b[0m     transition_prob \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcomp_transition_prob(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstate_list[j])\n\u001b[1;32m    458\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_transition_matrix[i,j] \u001b[39m=\u001b[39m transition_prob\n",
      "File \u001b[0;32m~/Documents/GitHub/home_workspace_imported/.venv/lib/python3.10/site-packages/lymph/unilateral.py:315\u001b[0m, in \u001b[0;36mUnilateral.comp_transition_prob\u001b[0;34m(self, newstate, acquire)\u001b[0m\n\u001b[1;32m    313\u001b[0m     in_states \u001b[39m=\u001b[39m \u001b[39mtuple\u001b[39m(edge\u001b[39m.\u001b[39mstart\u001b[39m.\u001b[39mstate \u001b[39mfor\u001b[39;00m edge \u001b[39min\u001b[39;00m lnl\u001b[39m.\u001b[39minc)\n\u001b[1;32m    314\u001b[0m     in_weights \u001b[39m=\u001b[39m \u001b[39mtuple\u001b[39m(edge\u001b[39m.\u001b[39mt \u001b[39mfor\u001b[39;00m edge \u001b[39min\u001b[39;00m lnl\u001b[39m.\u001b[39minc)\n\u001b[0;32m--> 315\u001b[0m     res \u001b[39m*\u001b[39m\u001b[39m=\u001b[39m Node\u001b[39m.\u001b[39;49mtrans_prob(in_states, in_weights)[newstate[i]]\n\u001b[1;32m    316\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m newstate[i]:\n\u001b[1;32m    317\u001b[0m     res \u001b[39m=\u001b[39m \u001b[39m0.\u001b[39m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "full_treated_lnls_no_risk, full_treated_lnls_all = analysis_treated_lnls(all_combinations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_set_count = count_numnber_treatments(full_treated_lnls_no_risk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.837e+03, 1.400e+02, 1.250e+02, 1.480e+02, 5.900e+01, 5.200e+01,\n",
       "       5.400e+01, 4.900e+01, 2.400e+01, 2.400e+01, 1.540e+02, 1.620e+02,\n",
       "       2.130e+02, 2.270e+02, 4.700e+01, 5.100e+01, 3.500e+01, 3.200e+01,\n",
       "       2.400e+01, 2.400e+01, 1.440e+02, 2.990e+02, 7.400e+01, 2.900e+01,\n",
       "       3.300e+01, 4.800e+01, 2.900e+01, 2.500e+01, 3.050e+02, 2.200e+02,\n",
       "       3.170e+02, 7.700e+01, 2.600e+01, 2.500e+01, 7.200e+01, 4.900e+01,\n",
       "       1.400e+01, 1.400e+01, 1.450e+02, 1.730e+02, 1.650e+02, 5.600e+01,\n",
       "       5.400e+01, 3.200e+01, 3.200e+01, 1.650e+02, 1.630e+02, 1.220e+02,\n",
       "       2.500e+01, 2.500e+01, 1.140e+02, 4.500e+01, 4.200e+01, 1.200e+01,\n",
       "       1.200e+01, 1.940e+02, 3.600e+01, 3.500e+01, 1.130e+02, 5.400e+01,\n",
       "       4.800e+01, 2.600e+01, 2.500e+01, 8.500e+01, 1.280e+02, 7.900e+01,\n",
       "       7.900e+01, 3.700e+01, 3.600e+01, 1.200e+01, 1.200e+01, 1.800e+01,\n",
       "       1.800e+01, 1.500e+01, 1.500e+01, 4.800e+01, 4.000e+01, 4.000e+01,\n",
       "       1.600e+01, 1.600e+01, 1.000e+01, 1.000e+01, 6.000e+00, 6.000e+00,\n",
       "       4.400e+01, 4.000e+01, 2.400e+01, 2.600e+01, 1.100e+01, 1.400e+01,\n",
       "       8.000e+00, 8.000e+00, 4.000e+00, 4.000e+00, 4.800e+01, 2.800e+01,\n",
       "       1.400e+01, 1.200e+01, 1.100e+01, 1.500e+01, 3.000e+01, 2.200e+01,\n",
       "       2.900e+01, 1.400e+01, 1.400e+01, 8.000e+00, 1.000e+01, 2.400e+01,\n",
       "       4.000e+00, 4.000e+00, 4.900e+01, 1.420e+02, 5.100e+01, 2.500e+01,\n",
       "       1.700e+01, 9.000e+00, 1.100e+01, 7.000e+00, 7.000e+00, 6.400e+01,\n",
       "       4.200e+01, 4.200e+01, 1.400e+01, 7.000e+00, 9.000e+00, 2.400e+01,\n",
       "       1.000e+01, 5.000e+00, 6.000e+00, 7.900e+01, 1.300e+01, 5.300e+01,\n",
       "       2.100e+01, 1.000e+01, 9.000e+00, 2.500e+01, 7.000e+00, 7.000e+00,\n",
       "       6.300e+01, 3.400e+01, 3.300e+01, 1.100e+01, 1.400e+01, 7.000e+00,\n",
       "       9.000e+00, 3.000e+01, 5.000e+00, 5.000e+00, 1.900e+01, 5.000e+00,\n",
       "       5.000e+00, 1.830e+02, 2.060e+02, 2.140e+02, 6.800e+01, 6.900e+01,\n",
       "       3.700e+01, 3.800e+01, 2.180e+02, 2.200e+02, 1.690e+02, 1.570e+02,\n",
       "       6.100e+01, 5.500e+01, 3.000e+01, 2.900e+01, 1.300e+01, 1.400e+01,\n",
       "       2.340e+02, 1.640e+02, 6.900e+01, 4.700e+01, 4.600e+01, 8.200e+01,\n",
       "       3.200e+01, 2.900e+01, 1.080e+02, 1.840e+02, 1.070e+02, 9.600e+01,\n",
       "       5.000e+01, 4.900e+01, 1.500e+01, 1.500e+01, 1.210e+02, 2.800e+01,\n",
       "       2.800e+01, 7.400e+01, 4.000e+01, 4.200e+01, 1.100e+01, 1.200e+01,\n",
       "       2.200e+01, 2.100e+01, 4.800e+01, 5.200e+01, 2.600e+01, 2.400e+01,\n",
       "       7.600e+01, 1.800e+01, 1.700e+01, 2.200e+01, 2.400e+01, 6.600e+01,\n",
       "       1.900e+01, 2.000e+01, 2.600e+01, 1.100e+01, 8.000e+00, 1.400e+01,\n",
       "       1.300e+01, 1.400e+01, 3.800e+01, 4.400e+01, 2.900e+01, 3.500e+01,\n",
       "       1.900e+01, 1.900e+01, 9.000e+00, 9.000e+00, 3.900e+01, 2.000e+01,\n",
       "       2.000e+01, 1.000e+01, 1.100e+01, 1.000e+01, 1.000e+01, 7.000e+00,\n",
       "       6.000e+00, 2.300e+01, 2.400e+01, 1.600e+01, 1.700e+01, 9.000e+00,\n",
       "       9.000e+00, 4.000e+00, 5.000e+00, 2.200e+01, 9.000e+00, 9.000e+00,\n",
       "       1.000e+01, 2.900e+01, 6.000e+00, 5.000e+00, 1.800e+01, 1.300e+01,\n",
       "       1.200e+01, 1.600e+01, 7.000e+00, 8.000e+00, 4.000e+00, 5.000e+00,\n",
       "       5.300e+01, 1.900e+01, 3.300e+01, 1.500e+01, 1.100e+01, 1.300e+01,\n",
       "       7.000e+00, 7.000e+00, 4.300e+01, 2.300e+01, 2.700e+01, 1.000e+01,\n",
       "       1.000e+01, 9.000e+00, 2.400e+01, 7.000e+00, 4.000e+00, 6.000e+00,\n",
       "       5.100e+01, 2.500e+01, 1.200e+01, 9.000e+00, 1.200e+01, 1.300e+01,\n",
       "       6.000e+00, 6.000e+00, 3.600e+01, 2.100e+01, 2.500e+01, 1.000e+01,\n",
       "       9.000e+00, 8.000e+00, 2.200e+01, 7.000e+00, 5.000e+00, 7.000e+00,\n",
       "       1.900e+01, 1.700e+01, 9.000e+00, 9.000e+00, 7.000e+00, 8.000e+00,\n",
       "       3.000e+00, 4.000e+00, 4.000e+00, 5.000e+00, 4.000e+00, 3.000e+00,\n",
       "       3.000e+00, 4.000e+00, 1.000e+00, 1.000e+00, 1.000e+00, 1.000e+00,\n",
       "       1.000e+00, 1.000e+00, 1.000e+00, 3.000e+00, 1.200e+01, 1.200e+01,\n",
       "       1.200e+01, 1.200e+01, 1.200e+01, 1.200e+01, 7.000e+00, 6.000e+00,\n",
       "       6.000e+00, 1.200e+01, 1.200e+01, 1.200e+01, 1.200e+01, 1.300e+01,\n",
       "       1.100e+01, 1.200e+01, 1.200e+01, 1.400e+01, 1.200e+01, 1.200e+01,\n",
       "       1.200e+01, 3.000e+00, 6.000e+00, 6.000e+00, 1.100e+01, 3.000e+00,\n",
       "       3.000e+00, 4.000e+00, 3.000e+00, 2.000e+00, 2.000e+00, 4.000e+00,\n",
       "       4.000e+00, 5.000e+00, 3.000e+00, 3.000e+00, 3.000e+00, 4.000e+00,\n",
       "       4.000e+00, 1.000e+00, 2.000e+00, 2.000e+00, 3.000e+00, 4.000e+00,\n",
       "       4.000e+00, 4.000e+00, 4.000e+00, 4.000e+00, 2.000e+00, 2.000e+00,\n",
       "       3.000e+00, 4.000e+00, 4.000e+00, 1.000e+00, 1.000e+00, 1.000e+00,\n",
       "       1.000e+00, 1.600e+01, 1.400e+01, 1.300e+01, 1.300e+01, 1.600e+01,\n",
       "       1.500e+01, 1.500e+01, 1.400e+01, 1.100e+01, 1.100e+01, 9.000e+00,\n",
       "       6.000e+00, 6.000e+00, 6.000e+00, 5.000e+00, 4.000e+00, 4.000e+00,\n",
       "       9.000e+00, 3.000e+00, 2.000e+00, 4.000e+00, 4.000e+00, 2.000e+00,\n",
       "       4.000e+00, 4.000e+00, 1.000e+00, 3.000e+00, 3.000e+00, 3.000e+00,\n",
       "       3.000e+00, 3.000e+00, 3.000e+00, 1.000e+00, 2.000e+00, 3.000e+00,\n",
       "       3.000e+00, 3.000e+00, 3.000e+00, 3.000e+00, 1.000e+00, 2.000e+00,\n",
       "       2.000e+00, 2.000e+00, 2.000e+00, 2.000e+00, 2.000e+00, 2.000e+00,\n",
       "       2.000e+00, 1.000e+00, 1.000e+00, 1.000e+00, 1.000e+00, 1.000e+00,\n",
       "       1.000e+00, 1.000e+00, 1.000e+00, 1.000e+00, 1.000e+00, 1.000e+00,\n",
       "       1.000e+00, 1.000e+00, 1.000e+00, 1.000e+00, 1.100e+01, 2.000e+00,\n",
       "       2.000e+00, 2.000e+00, 1.000e+00, 1.000e+00])"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "number_of_repetitions = []\n",
    "full_combinations_array = np.zeros(len(full_set_count))\n",
    "loop = 0\n",
    "for key, value in full_set_count.items():\n",
    "    number_of_repetitions.append(value)\n",
    "    full_combinations_array[loop] = value\n",
    "    loop+=1\n",
    "full_combinations_array"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
