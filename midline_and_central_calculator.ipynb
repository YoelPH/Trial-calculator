{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DeEsco Trial Treatment Guidelines Calculator\n",
    "\n",
    "⚠️ **This code uses lymph version 1.0.0.clin-trial specifically!**\n",
    "\n",
    "## Overview\n",
    "This notebook generates treatment guidelines for the DeEsco trial by:\n",
    "1. Setting up a lymphatic spread model with 6 lymph node levels (LNLs) per side\n",
    "2. Using Bayesian risk assessment with 216 MCMC samples for uncertainty quantification  \n",
    "3. Applying a 10% risk threshold with 95% confidence intervals for treatment decisions\n",
    "4. Generating comprehensive treatment tables for all diagnostic combinations\n",
    "\n",
    "**Install required version:** `pip install git+https://github.com/rmnldwg/lymph.git@1.0.0.clin-trial`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Model Setup and Configuration\n",
    "\n",
    "**Built on lymph 1.0.0.clin-trial**\n",
    "\n",
    "### Lymphatic Network Model\n",
    "- Models lymphatic spread between 6 lymph node levels: I, II, III, IV, V, VII\n",
    "- Supports both ipsilateral and contralateral spread patterns\n",
    "- Handles central tumors with bilateral spread capabilities\n",
    "- Uses maximum likelihood estimation for diagnostic inference\n",
    "\n",
    "### Key Parameters:\n",
    "- **Graph structure**: Defines anatomical connections between LNLs\n",
    "- **Time evolution**: 10 time steps maximum with early/late progression patterns\n",
    "- **Early diagnosis probability**: 30% (p=0.3) \n",
    "- **Diagnostic modalities**: \n",
    "  - `max_llh`: Perfect diagnostic (100% sensitivity/specificity) for model fitting\n",
    "  - `treatment_diagnose`: Clinical diagnostic (81% sensitivity, 100% specificity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.special import factorial\n",
    "import scipy as sp\n",
    "import emcee                      # inference and backends for sample storage\n",
    "from multiprocessing import Pool  # for parallelization of the inference\n",
    "import lymph\n",
    "\n",
    "graph = {\n",
    "    ('tumor', 'primary')  : ['I','II', 'III', 'IV','V','VII'], \n",
    "    ('lnl'  , 'I') :       ['II'],\n",
    "    ('lnl'  , 'II') :       ['III'], \n",
    "    ('lnl'  , 'III'):       ['IV'], \n",
    "    ('lnl'  , 'IV') :       ['V'],\n",
    "    ('lnl'  , 'V') :       [],\n",
    "    ('lnl'  , 'VII') :       []\n",
    "    \n",
    "}\n",
    "model = lymph.models.Midline(graph_dict= graph,tumor_state = 1, unilateral_kwargs={'allowed_states':[0,1], 'max_time':10}, use_central = True, use_midext_evo = False, marginalize_unknown= False)\n",
    "model.set_modality('max_llh',spec = 1,sens = 1)\n",
    "\n",
    "# Time prior with p(early) = 0.3\n",
    "def binom_pmf(k: np.ndarray, n: int, p: float):\n",
    "    \"\"\"Binomial PMF\"\"\"\n",
    "    if p > 1. or p < 0.:\n",
    "        raise ValueError(\"Binomial prob must be btw. 0 and 1\")\n",
    "    q = (1. - p)\n",
    "    binom_coeff = factorial(n) / (factorial(k) * factorial(n - k))\n",
    "    return binom_coeff * p**k * q**(n - k)\n",
    "\n",
    "def late_binomial(support: np.ndarray, p: float = 0.5) -> np.ndarray:\n",
    "    \"\"\"Parametrized binomial distribution.\"\"\"\n",
    "    return binom_pmf(support, n=support[-1], p=p)\n",
    "\n",
    "max_t = 10\n",
    "model.set_distribution('early',sp.stats.binom.pmf(np.arange(max_t+1), max_t, 0.3))\n",
    "model.set_distribution('late', late_binomial)\n",
    "model.set_modality('treatment_diagnose', spec = 1, sens = 0.81)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Loading MCMC Parameter Samples\n",
    "\n",
    "### Sample Source and Purpose\n",
    "Loading pre-computed MCMC samples from `trial_samples_central.h5`:\n",
    "- **2160 total samples** from Bayesian parameter inference\n",
    "- **18 parameters** per sample (mixing + spread probabilities)\n",
    "- Samples represent uncertainty in lymphatic spread parameters\n",
    "\n",
    "### Parameters Structure:\n",
    "- `mixing`: Mixing coefficient for bilateral involvement\n",
    "- `ipsi_primarytoX_spread`: Primary tumor to ipsilateral LNL X spread probability\n",
    "- `contra_primarytoX_spread`: Primary tumor to contralateral LNL X spread probability  \n",
    "- `XtoY_spread`: LNL-to-LNL spread probabilities (I→II, II→III, III→IV, IV→V)\n",
    "- `late_p`: Late progression probability parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2160, 18)\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "with h5py.File(\"data/samples_trial.h5\", \"r\") as f:\n",
    "    samples1 = f[\"chain\"][...]\n",
    "samples1 = samples1.reshape(-1, samples1.shape[-1])\n",
    "print(samples1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'midext_prob': 0.0,\n",
       " 'ipsi_primarytoI_spread': 0.026599934089507535,\n",
       " 'ipsi_primarytoII_spread': 0.3754362312489512,\n",
       " 'ipsi_primarytoIII_spread': 0.07350634235991671,\n",
       " 'ipsi_primarytoIV_spread': 0.009868764752471882,\n",
       " 'ipsi_primarytoV_spread': 0.01608922143844808,\n",
       " 'ipsi_primarytoVII_spread': 0.021790771223072873,\n",
       " 'contra_primarytoI_spread': 0.0032833634932873815,\n",
       " 'contra_primarytoII_spread': 0.025330185925201906,\n",
       " 'contra_primarytoIII_spread': 0.0023198951662066233,\n",
       " 'contra_primarytoIV_spread': 0.0028514226257283703,\n",
       " 'contra_primarytoV_spread': 0.000656088933696782,\n",
       " 'contra_primarytoVII_spread': 0.006324800116350196,\n",
       " 'mixing': 0.22533811234978024,\n",
       " 'ItoII_spread': 0.7470325433932157,\n",
       " 'IItoIII_spread': 0.1444848004577465,\n",
       " 'IIItoIV_spread': 0.16715051321273394,\n",
       " 'IVtoV_spread': 0.17189301394039708,\n",
       " 'late_p': 0.36914158720690937}"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled_mean = samples1.mean(axis = 0)\n",
    "params = {'mixing': sampled_mean[0],\n",
    "        'ipsi_primarytoI_spread': sampled_mean[1],\n",
    "        'ipsi_primarytoII_spread': sampled_mean[2],\n",
    "        'ipsi_primarytoIII_spread': sampled_mean[3],\n",
    "        'ipsi_primarytoIV_spread': sampled_mean[4],\n",
    "        'ipsi_primarytoV_spread': sampled_mean[5],\n",
    "        'ipsi_primarytoVII_spread': sampled_mean[6],\n",
    "        'contra_primarytoI_spread': sampled_mean[7],\n",
    "        'contra_primarytoII_spread': sampled_mean[8],\n",
    "        'contra_primarytoIII_spread': sampled_mean[9],\n",
    "        'contra_primarytoIV_spread': sampled_mean[10],   \n",
    "        'contra_primarytoV_spread': sampled_mean[11],\n",
    "        'contra_primarytoVII_spread': sampled_mean[12],\n",
    "        'ItoII_spread': sampled_mean[13],\n",
    "        'IItoIII_spread': sampled_mean[14],\n",
    "        'IIItoIV_spread': sampled_mean[15],\n",
    "        'IVtoV_spread': sampled_mean[16],\n",
    "        'late_p': sampled_mean[17]}\n",
    "model.set_params(**params)\n",
    "model.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting Model Parameters from MCMC Samples\n",
    "\n",
    "Using the **mean values** from all MCMC samples to set the model for some example calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "dataset_USZ =  pd.read_csv(\"data/cleanedUSZ.csv\", header=[0,1,2]) #import data\n",
    "\n",
    "maxllh =  dataset_USZ['max_llh']\n",
    "t_stage = dataset_USZ['info']\n",
    "ipsi = maxllh.loc[:,'ipsi'].drop(['IIa','IIb','VIII','Ib','IX','VI','X','Ia'],axis = 1)[['I','II','III','IV','V','VII']]\n",
    "contra = maxllh.loc[:,'contra'].drop(['IIa','IIb','VIII','Ib','IX','VI','X','Ia'],axis = 1)[['I','II','III','IV','V','VII']]\n",
    "ipsi_header = header = pd.MultiIndex.from_product([ ['ipsi'], ['I','II','III','IV','V','VII']], names=['', ''])\n",
    "contra_header = pd.MultiIndex.from_product([['contra'], ['I','II','III','IV','V','VII']], names=['', ''])\n",
    "ipsi.columns = ipsi_header\n",
    "contra.columns = contra_header\n",
    "\n",
    "dataset_analyze = pd.concat([t_stage,ipsi,contra],axis = 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Clinical Dataset\n",
    "\n",
    "Loading the USZ clinical dataset to analyze real patient diagnostic combinations:\n",
    "- `cleanedUSZ.csv`: USZ-specific subset used for validation\n",
    "- Data structure includes T-stage, LNL involvement patterns, and maximum likelihood diagnoses\n",
    "- Filtering to 6 relevant LNLs: I, II, III, IV, V, VII (excluding IIa, IIb, VIII, etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Example Analysis - Individual Cases\n",
    "\n",
    "Before running the full combination analysis, we'll demonstrate the treatment decision algorithm with specific diagnostic scenarios. This helps understand:\n",
    "- How the `levels_to_spare` function works\n",
    "- The effect of different diagnostic patterns\n",
    "- Risk calculation and confidence interval usage\n",
    "- Comparison between algorithm versions (old vs new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Sample Preparation for Analysis\n",
    "\n",
    "**Critical Parameter**: We use exactly **216 samples** with **step_size = 10** for reproducibility:\n",
    "- From 2160 total samples, select every 10th sample\n",
    "- This provides sufficient coverage while maintaining computational efficiency  \n",
    "- Evenly spaced sampling ensures representative uncertainty quantification\n",
    "- These 216 samples will be used for all risk calculations and confidence intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sparing_scripts import sample_from_flattened\n",
    "\n",
    "samples_reduced = sample_from_flattened(samples1, num_samples = 216, spaced = True, step_size = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('ipsi III', 0.08275283447364559), ('ipsi II', 1.0000000000000002)]\n",
      "6.629766388350969\n",
      "[('contra V', 0.00042763173316175606), ('contra I', 0.0009891023055616907), ('contra IV', 0.0014467123203597062), ('contra III', 0.0015009689751277794), ('contra VII', 0.0036182001687979333), ('ipsi IV', 0.007896204657586742), ('ipsi V', 0.009609714097105536), ('ipsi VII', 0.012807244016318392), ('contra II', 0.013067004381272224), ('ipsi I', 0.018191576282428446)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([5.75407088, 7.54938061])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sparing_scripts import risk_sampled, levels_to_spare, ci_single\n",
    "\n",
    "diagnose = {\"ipsi\": {'treatment_diagnose':{\n",
    "        \"I\": 0,\n",
    "        \"II\": 1,\n",
    "        \"III\": 0,\n",
    "        \"IV\": 0,\n",
    "        \"V\": 0,\n",
    "        \"VII\": 0\n",
    "    }},\n",
    "    \"contra\": {'treatment_diagnose':{\n",
    "        \"I\": 0,\n",
    "        \"II\": 0,\n",
    "        \"III\": 0,\n",
    "        \"IV\": 0,\n",
    "        \"V\": 0,\n",
    "        \"VII\": 0\n",
    "    }}}\n",
    "sampled_risks, risk = risk_sampled(samples = samples_reduced, model = model, t_stage = 'early', given_diagnoses= diagnose,central = None, midline_extension= False)     \n",
    "spared_lnls, total_risk, ranked_combined, treated_lnls, treated_array, treated_ipsi, treated_contra, sampled_total_risks = levels_to_spare(0.10, model, risk, sampled_risks, ci = False)\n",
    "print(treated_lnls)\n",
    "print(total_risk*100)\n",
    "print(spared_lnls)\n",
    "ci_single(sampled_total_risks)*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Example Case: Early T-stage with Ipsi Level II involvement\n",
    "\n",
    "**Diagnostic scenario**:\n",
    "- T-stage: Early\n",
    "- Midline extension: False  \n",
    "- Ipsilateral involvement: Level II only (diagnosed positive)\n",
    "- Contralateral involvement: None\n",
    "\n",
    "**Analysis approach**:\n",
    "1. Generate 216 risk estimates using MCMC samples\n",
    "2. Calculate mean risk matrix (64×64 for bilateral involvement patterns)\n",
    "3. Apply `levels_to_spare` algorithm with 10% threshold\n",
    "4. Use `ci = False`: Uses mean risk for threshold comparison (not CI upper bound)\n",
    "5. Show treatment recommendation and confidence intervals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Comprehensive Combination Analysis\n",
    "\n",
    "### Purpose\n",
    "Generate treatment recommendations for **all possible diagnostic combinations** to create complete clinical guidelines.\n",
    "\n",
    "### Scope\n",
    "- **Non-central tumors**: 2^14 = 16,384 combinations\n",
    "- **Central tumors**: 2^13 = 8,192 combinations  \n",
    "- **Each combination includes**: T-stage, midline extension, and all LNL involvement patterns\n",
    "\n",
    "### Process Overview\n",
    "1. **USZ Dataset Analysis**: Validate algorithm on real patient data\n",
    "2. **Full Combination Generation**: Create all theoretical diagnostic scenarios\n",
    "3. **Risk Calculation**: Apply 216-sample uncertainty quantification to each combination\n",
    "4. **Treatment Decision**: Use 95% CI upper bound with 10% threshold\n",
    "5. **Table Export**: Generate comprehensive treatment lookup tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Processing USZ Clinical Dataset\n",
    "\n",
    "**Goal**: Extract unique diagnostic combinations from real patient data for validation.\n",
    "\n",
    "**Process**:\n",
    "1. **Group patients** by identical diagnostic patterns (T-stage + LNL involvement)\n",
    "2. **Count frequencies** of each unique combination  \n",
    "3. **Extract involvement patterns** for ipsilateral and contralateral sides\n",
    "4. **Prepare for analysis** with the treatment algorithm\n",
    "\n",
    "**Output**: \n",
    "- Unique diagnostic combinations from clinical practice\n",
    "- Patient frequencies for each combination\n",
    "- Structured format for risk analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "# Sample array with different entry combinations\n",
    "data = np.array(dataset_analyze)\n",
    "\n",
    "entry_combinations_with_indexes = defaultdict(list)\n",
    "for index, row in enumerate(data):\n",
    "    combination = tuple(row)\n",
    "    entry_combinations_with_indexes[combination].append(index)\n",
    "USZ_counts = []\n",
    "USZ_combinations = []\n",
    "USZ_indexes = []\n",
    "for combination, indexes in entry_combinations_with_indexes.items():\n",
    "    count = len(indexes)\n",
    "    USZ_indexes.append(indexes)\n",
    "    USZ_counts.append(count)\n",
    "    USZ_combinations.append(combination)\n",
    "\n",
    "lnls = ['I','II', 'III', 'IV','V', 'VII']\n",
    "t_stage = []\n",
    "midline_extension = []\n",
    "invovlvement_ipsi_USZ = []\n",
    "invovlvement_contra_USZ = []\n",
    "for diagnose_type in USZ_combinations:\n",
    "    involved_ipsi = []\n",
    "    involved_contra = []\n",
    "    t_stage.append(diagnose_type[0])\n",
    "    midline_extension.append(diagnose_type[1])\n",
    "    for lnl_looper, involved_level in enumerate(lnls):\n",
    "        if diagnose_type[lnl_looper +2] == True:\n",
    "            involved_ipsi.append(involved_level) \n",
    "        if diagnose_type[lnl_looper +8] == True:\n",
    "            involved_contra.append(involved_level)\n",
    "    invovlvement_ipsi_USZ.append(involved_ipsi)\n",
    "    invovlvement_contra_USZ.append(involved_contra)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 USZ Dataset Analysis Results\n",
    "\n",
    "**Analysis of real clinical combinations**:\n",
    "- Uses the **corrected algorithm** (`analysis_treated_lnls_combinations`)  \n",
    "- **216 samples** for uncertainty quantification\n",
    "- **10% risk threshold** with **95% confidence intervals**\n",
    "- **CI upper bound** used for conservative treatment decisions\n",
    "\n",
    "**Output metrics**:\n",
    "- Treatment recommendations for each clinical combination\n",
    "- Risk estimates with confidence intervals  \n",
    "- Top 3 spared LNLs (lowest risk levels that can be omitted)\n",
    "- Frequency distribution of unique treatment strategies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sparing_scripts import count_number_treatments, analysis_treated_lnls_combinations\n",
    "usz_treated_lnls_no_risk, usz_treated_lnls_all, usz_treatment_array, usz_top3_spared, usz_total_risks, usz_treated_ipsi, usz_treated_contra, usz_sampled_risks_array, usz_lnls_ranked, cis = analysis_treated_lnls_combinations(combinations = USZ_combinations, model = model, samples = samples_reduced, threshold = 0.10)\n",
    "usz_set_counts = count_number_treatments(usz_treated_lnls_no_risk)\n",
    "len(usz_set_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Percentage of patients</th>\n",
       "      <th>T-stage</th>\n",
       "      <th>Midline Extension</th>\n",
       "      <th>Involvement Ipsi</th>\n",
       "      <th>Involvement Contra</th>\n",
       "      <th>Treated Ipsi</th>\n",
       "      <th>Treated Contra</th>\n",
       "      <th>risk</th>\n",
       "      <th>lower bound</th>\n",
       "      <th>upper bound</th>\n",
       "      <th>top 3 spared lnls risk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.048780</td>\n",
       "      <td>late</td>\n",
       "      <td>True</td>\n",
       "      <td>[II]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[III, II]</td>\n",
       "      <td>[II]</td>\n",
       "      <td>0.078032</td>\n",
       "      <td>0.066303</td>\n",
       "      <td>0.091473</td>\n",
       "      <td>[(ipsi I, 0.02018212044831703), (ipsi VII, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.010453</td>\n",
       "      <td>early</td>\n",
       "      <td>False</td>\n",
       "      <td>[II]</td>\n",
       "      <td>[II]</td>\n",
       "      <td>[III, II]</td>\n",
       "      <td>[III, II]</td>\n",
       "      <td>0.076328</td>\n",
       "      <td>0.062081</td>\n",
       "      <td>0.097589</td>\n",
       "      <td>[(ipsi I, 0.020745164441888973), (contra I, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.003484</td>\n",
       "      <td>late</td>\n",
       "      <td>True</td>\n",
       "      <td>[I, II, III, IV, VII]</td>\n",
       "      <td>[I, II, III, IV]</td>\n",
       "      <td>[V, I, II, III, IV, VII]</td>\n",
       "      <td>[I, II, III, IV]</td>\n",
       "      <td>0.061390</td>\n",
       "      <td>0.034468</td>\n",
       "      <td>0.095027</td>\n",
       "      <td>[(contra V, 0.049917866263852986), (contra VII...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.003484</td>\n",
       "      <td>late</td>\n",
       "      <td>True</td>\n",
       "      <td>[II, III, IV, VII]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[V, VII, II, III, IV]</td>\n",
       "      <td>[II]</td>\n",
       "      <td>0.066456</td>\n",
       "      <td>0.055051</td>\n",
       "      <td>0.077370</td>\n",
       "      <td>[(ipsi I, 0.028686386918113108), (contra III, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.010453</td>\n",
       "      <td>early</td>\n",
       "      <td>False</td>\n",
       "      <td>[II, VII]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[III, II, VII]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.063806</td>\n",
       "      <td>0.054496</td>\n",
       "      <td>0.073761</td>\n",
       "      <td>[(ipsi I, 0.021186904157757556), (contra II, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>0.003484</td>\n",
       "      <td>early</td>\n",
       "      <td>False</td>\n",
       "      <td>[II, IV]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[V, III, II, IV]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.062058</td>\n",
       "      <td>0.052172</td>\n",
       "      <td>0.072464</td>\n",
       "      <td>[(ipsi I, 0.022471174486049225), (ipsi VII, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>0.006969</td>\n",
       "      <td>late</td>\n",
       "      <td>False</td>\n",
       "      <td>[II, III, V]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[IV, II, III, V]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.075202</td>\n",
       "      <td>0.062002</td>\n",
       "      <td>0.087899</td>\n",
       "      <td>[(ipsi I, 0.02735384799828265), (ipsi VII, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>0.003484</td>\n",
       "      <td>late</td>\n",
       "      <td>True</td>\n",
       "      <td>[II, III]</td>\n",
       "      <td>[II, III, IV]</td>\n",
       "      <td>[I, IV, II, III]</td>\n",
       "      <td>[V, II, III, IV]</td>\n",
       "      <td>0.066285</td>\n",
       "      <td>0.054837</td>\n",
       "      <td>0.080623</td>\n",
       "      <td>[(ipsi VII, 0.02303066023513181), (ipsi V, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>0.003484</td>\n",
       "      <td>late</td>\n",
       "      <td>False</td>\n",
       "      <td>[II, V]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[IV, III, II, V]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.066396</td>\n",
       "      <td>0.054162</td>\n",
       "      <td>0.077747</td>\n",
       "      <td>[(ipsi I, 0.024086145154078375), (ipsi VII, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>0.003484</td>\n",
       "      <td>late</td>\n",
       "      <td>True</td>\n",
       "      <td>[II, III, V]</td>\n",
       "      <td>[II, III, VII]</td>\n",
       "      <td>[IV, II, III, V]</td>\n",
       "      <td>[IV, II, III, VII]</td>\n",
       "      <td>0.077072</td>\n",
       "      <td>0.063330</td>\n",
       "      <td>0.094659</td>\n",
       "      <td>[(ipsi I, 0.032094726768564626), (ipsi VII, 0....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>77 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Percentage of patients T-stage  Midline Extension       Involvement Ipsi  \\\n",
       "0                 0.048780    late               True                   [II]   \n",
       "1                 0.010453   early              False                   [II]   \n",
       "2                 0.003484    late               True  [I, II, III, IV, VII]   \n",
       "3                 0.003484    late               True     [II, III, IV, VII]   \n",
       "4                 0.010453   early              False              [II, VII]   \n",
       "..                     ...     ...                ...                    ...   \n",
       "72                0.003484   early              False               [II, IV]   \n",
       "73                0.006969    late              False           [II, III, V]   \n",
       "74                0.003484    late               True              [II, III]   \n",
       "75                0.003484    late              False                [II, V]   \n",
       "76                0.003484    late               True           [II, III, V]   \n",
       "\n",
       "   Involvement Contra              Treated Ipsi      Treated Contra      risk  \\\n",
       "0                  []                 [III, II]                [II]  0.078032   \n",
       "1                [II]                 [III, II]           [III, II]  0.076328   \n",
       "2    [I, II, III, IV]  [V, I, II, III, IV, VII]    [I, II, III, IV]  0.061390   \n",
       "3                  []     [V, VII, II, III, IV]                [II]  0.066456   \n",
       "4                  []            [III, II, VII]                  []  0.063806   \n",
       "..                ...                       ...                 ...       ...   \n",
       "72                 []          [V, III, II, IV]                  []  0.062058   \n",
       "73                 []          [IV, II, III, V]                  []  0.075202   \n",
       "74      [II, III, IV]          [I, IV, II, III]    [V, II, III, IV]  0.066285   \n",
       "75                 []          [IV, III, II, V]                  []  0.066396   \n",
       "76     [II, III, VII]          [IV, II, III, V]  [IV, II, III, VII]  0.077072   \n",
       "\n",
       "    lower bound  upper bound  \\\n",
       "0      0.066303     0.091473   \n",
       "1      0.062081     0.097589   \n",
       "2      0.034468     0.095027   \n",
       "3      0.055051     0.077370   \n",
       "4      0.054496     0.073761   \n",
       "..          ...          ...   \n",
       "72     0.052172     0.072464   \n",
       "73     0.062002     0.087899   \n",
       "74     0.054837     0.080623   \n",
       "75     0.054162     0.077747   \n",
       "76     0.063330     0.094659   \n",
       "\n",
       "                               top 3 spared lnls risk  \n",
       "0   [(ipsi I, 0.02018212044831703), (ipsi VII, 0.0...  \n",
       "1   [(ipsi I, 0.020745164441888973), (contra I, 0....  \n",
       "2   [(contra V, 0.049917866263852986), (contra VII...  \n",
       "3   [(ipsi I, 0.028686386918113108), (contra III, ...  \n",
       "4   [(ipsi I, 0.021186904157757556), (contra II, 0...  \n",
       "..                                                ...  \n",
       "72  [(ipsi I, 0.022471174486049225), (ipsi VII, 0....  \n",
       "73  [(ipsi I, 0.02735384799828265), (ipsi VII, 0.0...  \n",
       "74  [(ipsi VII, 0.02303066023513181), (ipsi V, 0.0...  \n",
       "75  [(ipsi I, 0.024086145154078375), (ipsi VII, 0....  \n",
       "76  [(ipsi I, 0.032094726768564626), (ipsi VII, 0....  \n",
       "\n",
       "[77 rows x 11 columns]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sparing_scripts import ci_multiple\n",
    "ci = ci_multiple(usz_sampled_risks_array)\n",
    "data_export_usz = pd.DataFrame({'Percentage of patients': np.array(USZ_counts)/287,\n",
    "                                'T-stage': t_stage,\n",
    "                                'Midline Extension': midline_extension,\n",
    "                                'Involvement Ipsi' : invovlvement_ipsi_USZ,\n",
    "                                'Involvement Contra': invovlvement_contra_USZ,\n",
    "                                'Treated Ipsi':  usz_treated_ipsi,\n",
    "                                'Treated Contra': usz_treated_contra,\n",
    "                                'risk': usz_total_risks,\n",
    "                                'lower bound': ci.T[0],\n",
    "                                'upper bound': ci.T[1],\n",
    "                                'top 3 spared lnls risk': usz_top3_spared\n",
    "\n",
    "})\n",
    "# data_export_usz.to_csv('analyzed_usz_data_new_dataset.csv', sep = ';', index = False)\n",
    "# data_export_usz.sort_values(by = 'Percentage of patients', ascending = False, inplace = True)\n",
    "data_export_usz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Generating All Possible Diagnostic Combinations\n",
    "\n",
    "**⚠️ THIS CALCULATION TAKES A FEW HOURS**\n",
    "\n",
    "**Complete enumeration approach**:\n",
    "- Generate **2^14 = 16,384 combinations** for non-central tumors\n",
    "- Each combination represents a unique diagnostic scenario\n",
    "- **14 binary variables**: T-stage + midline extension + 12 LNLs (6 ipsi + 6 contra)\n",
    "\n",
    "**Combination structure**:\n",
    "1. **T-stage**: Early (0) or Late (1)  \n",
    "2. **Midline extension**: False (0) or True (1)\n",
    "3. **LNL involvement**: 12 binary values (0=negative, 1=positive)\n",
    "   - Positions 2-7: Ipsilateral I,II,III,IV,V,VII\n",
    "   - Positions 8-13: Contralateral I,II,III,IV,V,VII\n",
    "\n",
    "**Purpose**: Create lookup tables covering every possible clinical scenario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "from sparing_scripts import change_base\n",
    "\n",
    "def produce_combinations_list(array):\n",
    "    combinations_list = []\n",
    "    for entry in array:\n",
    "        combination = []\n",
    "        for index, cells in enumerate(entry):\n",
    "            if index == 0:\n",
    "                combination.append('early') if cells == 0 else combination.append('late')\n",
    "            else:\n",
    "                combination.append(False) if cells == 0 else combination.append(True)\n",
    "        combination = tuple(combination)\n",
    "        combinations_list.append(combination)\n",
    "    return(combinations_list)\n",
    "\n",
    "combination_array = np.zeros((2**14,14))\n",
    "for i in range(2**14):\n",
    "    combination_array[i] = [\n",
    "        int(digit) for digit in change_base(i, 2, length=14)\n",
    "    ]\n",
    "\n",
    "all_combinations = produce_combinations_list(combination_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Parallelized Analysis of All Combinations\n",
    "\n",
    "**Computational strategy**:\n",
    "- **16,384 combinations** require significant computation time\n",
    "- **Multiprocessing**: Divide work across CPU cores for efficiency\n",
    "- **New algorithm**: Uses corrected `levels_to_spare` with CI-based decisions\n",
    "\n",
    "**Analysis parameters**:\n",
    "- **216 MCMC samples** per combination for uncertainty quantification\n",
    "- **10% risk threshold** for treatment decisions  \n",
    "- **95% CI upper bound** for conservative threshold comparison\n",
    "- **Parallel processing**: Utilizes multiple CPU cores to reduce computation time\n",
    "\n",
    "**Expected output**:\n",
    "- Complete treatment recommendations for all diagnostic scenarios\n",
    "- Risk estimates with confidence intervals\n",
    "- Comprehensive clinical lookup tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing as mp\n",
    "\n",
    "# Function to process a chunk of combinations\n",
    "def process_combinations(chunk):\n",
    "    return analysis_treated_lnls_combinations(chunk, samples_reduced, model)\n",
    "\n",
    "# Divide the combinations into chunks\n",
    "num_cores = mp.cpu_count() - 1\n",
    "chunk_size = len(all_combinations) // num_cores\n",
    "chunks = [all_combinations[i:i + chunk_size] for i in range(0, len(all_combinations), chunk_size)]\n",
    "\n",
    "# Use multiprocessing to process the chunks\n",
    "with mp.Pool(num_cores) as pool:\n",
    "    results = pool.map(process_combinations, chunks)\n",
    "\n",
    "# Combine the results from all chunks\n",
    "treated_lnls_no_risk, treated_lnls_all, treatment_array, top3_spared, total_risks, treated_ipsi, treated_contra, sampled_risks_array, lnls_ranked, cis = zip(*results)\n",
    "\n",
    "# Flatten the results\n",
    "treated_lnls_no_risk = [item for sublist in treated_lnls_no_risk for item in sublist]\n",
    "treated_lnls_all = [item for sublist in treated_lnls_all for item in sublist]\n",
    "treatment_array = np.vstack(treatment_array)\n",
    "top3_spared = [item for sublist in top3_spared for item in sublist]\n",
    "total_risks = np.concatenate(total_risks)\n",
    "treated_ipsi = [item for sublist in treated_ipsi for item in sublist]\n",
    "treated_contra = [item for sublist in treated_contra for item in sublist]\n",
    "sampled_risks_array = np.vstack(sampled_risks_array)\n",
    "lnls_ranked = [item for sublist in lnls_ranked for item in sublist]\n",
    "cis_lower = []\n",
    "cis_upper = []\n",
    "for item in cis:\n",
    "    cis_lower.append(item[0])\n",
    "    cis_upper.append(item[1])\n",
    "flat_lower = [item for sublist in cis_lower for item in sublist]\n",
    "flat_upper = [item for sublist in cis_upper for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yoel/Documents/Risk_evaluator/.venv/lib/python3.10/site-packages/lymph/models/bilateral.py:601: UserWarning: No diagnoses given for ipsilateral side.\n",
      "  warnings.warn(f\"No diagnoses given for {side}lateral side.\")\n",
      "/home/yoel/Documents/Risk_evaluator/.venv/lib/python3.10/site-packages/lymph/models/bilateral.py:601: UserWarning: No diagnoses given for contralateral side.\n",
      "  warnings.warn(f\"No diagnoses given for {side}lateral side.\")\n"
     ]
    }
   ],
   "source": [
    "sampled_risks_early_no_ext, mean_risk_early_no_ext = risk_sampled(samples_reduced, model, 'early', midline_extension = False, given_diagnoses = None) \n",
    "sampled_risks_early_ext, mean_risk_early_ext = risk_sampled(samples_reduced, model, 'early', midline_extension = True, given_diagnoses = None)\n",
    "sampled_risks_late_no_ext, mean_risk_late_no_ext = risk_sampled(samples_reduced, model, 'late', midline_extension = False, given_diagnoses = None)\n",
    "sampled_risks_late_ext, mean_risk_late_ext = risk_sampled(samples_reduced, model, 'late', midline_extension = True, given_diagnoses = None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5 Baseline Risk Calculations\n",
    "\n",
    "**Computing population-level risks** to get the \"prevalence\" of each diagnose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate state list\n",
    "state_list = np.array(np.meshgrid(*[[0, 1]] * 14)).T.reshape(-1, 14)\n",
    "state_list = state_list[np.lexsort(np.fliplr(state_list).T)]\n",
    "# Reshape the risk arrays into 1x4096 arrays\n",
    "mean_risk_early_noext_flat = mean_risk_early_no_ext.reshape(-1)\n",
    "mean_risk_early_ext_flat = mean_risk_early_ext.reshape(-1)\n",
    "mean_risk_late_noext_flat = mean_risk_late_no_ext.reshape(-1)\n",
    "mean_risk_late_ext_flat = mean_risk_late_ext.reshape(-1)\n",
    "#combine them\n",
    "full_risks = np.hstack([mean_risk_early_noext_flat, mean_risk_early_ext_flat, mean_risk_late_noext_flat, mean_risk_late_ext_flat])/4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "lnls = ['I','II', 'III', 'IV','V', 'VII']\n",
    "t_stage = []\n",
    "midline_extension = []\n",
    "invovlvement_ipsi = []\n",
    "invovlvement_contra = []\n",
    "for diagnose_type in all_combinations:\n",
    "    involved_ipsi = []\n",
    "    involved_contra = []\n",
    "    t_stage.append(diagnose_type[0])\n",
    "    midline_extension.append(diagnose_type[1])\n",
    "    for lnl_looper, involved_level in enumerate(lnls):\n",
    "        if diagnose_type[lnl_looper +2] == True:\n",
    "            involved_ipsi.append(involved_level) \n",
    "        if diagnose_type[lnl_looper +8] == True:\n",
    "            involved_contra.append(involved_level)\n",
    "    invovlvement_ipsi.append(involved_ipsi)\n",
    "    invovlvement_contra.append(involved_contra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_export = pd.DataFrame({'Percentage of patients': full_risks,\n",
    "                                'T-stage': t_stage,\n",
    "                                'Midline Extension': midline_extension,\n",
    "                                'Involvement Ipsi' : invovlvement_ipsi,\n",
    "                                'Involvement Contra': invovlvement_contra,\n",
    "                                'Treated Ipsi':  treated_ipsi,\n",
    "                                'Treated Contra': treated_contra,\n",
    "                                'risk': total_risks,\n",
    "                                'lower bound': flat_lower,\n",
    "                                'upper bound': flat_upper,\n",
    "                                'top 3 spared lnls risk': top3_spared,\n",
    "                                'lnls ranked': lnls_ranked\n",
    "})\n",
    "data_export.to_csv('lymph_1_midline_full_table_new_code.csv', sep = ';', index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Central Tumor Analysis\n",
    "\n",
    "This section repeats the comprehensive analysis for **central tumors** (tumors crossing the midline with bilateral spread). The methodology mirrors Section 4 but uses different tumor characteristics:\n",
    "\n",
    "- **Tumor Stage**: Late T-stage (more advanced tumors)\n",
    "- **Central Parameter**: `central = True` (enables bilateral spread modeling) \n",
    "- **Bilateral Spread**: Both ipsilateral and contralateral LNL involvement possible\n",
    "\n",
    "## Key Differences from Midline Analysis:\n",
    "- Central tumors have higher baseline risks due to bilateral spread potential\n",
    "- Analysis considers 2^13 combinations (13 LNLs: 6 per side + 1 midline level)\n",
    "- Risk calculations account for cross-midline tumor extension patterns\n",
    "\n",
    "This parallel analysis ensures treatment guidelines cover both midline-only and centrally-extending tumor presentations in the DeEsco trial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: Here we assume that the probability of early no extension, late no extension, early extension, and late extension are all equal for the prevalence calculation (which is generally not true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 Combination Generation for Central Tumors\n",
    "\n",
    "For central tumors, we generate all possible treatment combinations for **13 LNLs**:\n",
    "- **6 ipsilateral LNLs**: I, II, III, IV, V, VII (left side) \n",
    "- **6 contralateral LNLs**: I, II, III, IV, V, VII (right side)\n",
    "- **1 central LNL**: VII (midline)\n",
    "\n",
    "This creates **2^13 = 8,192 possible treatment combinations**, each representing a different clinical decision about which LNLs to treat versus spare."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combination_array_central = np.zeros((2**13,13))\n",
    "for i in range(2**13):\n",
    "    combination_array_central[i] = [\n",
    "        int(digit) for digit in change_base(i, 2, length=13)\n",
    "    ]\n",
    "\n",
    "all_combinations_central = produce_combinations_list(combination_array_central)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing as mp\n",
    "\n",
    "# Function to process a chunk of combinations\n",
    "def process_combinations(chunk):\n",
    "    return analysis_treated_lnls_combinations(chunk, samples_reduced, model, central = True)\n",
    "\n",
    "# Divide the combinations into chunks\n",
    "num_cores = mp.cpu_count() - 2\n",
    "chunk_size = len(all_combinations_central) // num_cores\n",
    "chunks = [all_combinations_central[i:i + chunk_size] for i in range(0, len(all_combinations_central), chunk_size)]\n",
    "\n",
    "# Use multiprocessing to process the chunks\n",
    "with mp.Pool(num_cores) as pool:\n",
    "    results = pool.map(process_combinations, chunks)\n",
    "\n",
    "# Combine the results from all chunks\n",
    "treated_lnls_no_risk, treated_lnls_all, treatment_array, top3_spared, total_risks, treated_ipsi, treated_contra, sampled_risks_array, lnls_ranked, cis = zip(*results)\n",
    "\n",
    "# Flatten the results\n",
    "treated_lnls_no_risk = [item for sublist in treated_lnls_no_risk for item in sublist]\n",
    "treated_lnls_all = [item for sublist in treated_lnls_all for item in sublist]\n",
    "treatment_array = np.vstack(treatment_array)\n",
    "top3_spared = [item for sublist in top3_spared for item in sublist]\n",
    "total_risks = np.concatenate(total_risks)\n",
    "treated_ipsi = [item for sublist in treated_ipsi for item in sublist]\n",
    "treated_contra = [item for sublist in treated_contra for item in sublist]\n",
    "sampled_risks_array = np.vstack(sampled_risks_array)\n",
    "lnls_ranked = [item for sublist in lnls_ranked for item in sublist]\n",
    "cis_lower = []\n",
    "cis_upper = []\n",
    "for item in cis:\n",
    "    cis_lower.append(item[0])\n",
    "    cis_upper.append(item[1])\n",
    "flat_lower = [item for sublist in cis_lower for item in sublist]\n",
    "flat_upper = [item for sublist in cis_upper for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_risks_early, mean_risk_early = risk_sampled(samples_reduced, model, 'early', central = True, given_diagnoses = None) \n",
    "sampled_risks_late, mean_risk_late = risk_sampled(samples_reduced, model, 'late', central = True, given_diagnoses = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate state list\n",
    "state_list = np.array(np.meshgrid(*[[0, 1]] * 13)).T.reshape(-1, 13)\n",
    "state_list = state_list[np.lexsort(np.fliplr(state_list).T)]\n",
    "# Reshape the risk arrays into 1x4096 arrays\n",
    "mean_risk_early = mean_risk_early.reshape(-1)\n",
    "mean_risk_late = mean_risk_late.reshape(-1)\n",
    "#combine them\n",
    "full_risks = np.hstack([mean_risk_early, mean_risk_late])/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "lnls = ['I','II', 'III', 'IV','V', 'VII']\n",
    "t_stage = []\n",
    "invovlvement_ipsi = []\n",
    "invovlvement_contra = []\n",
    "for diagnose_type in all_combinations_central:\n",
    "    involved_ipsi = []\n",
    "    involved_contra = []\n",
    "    t_stage.append(diagnose_type[0])\n",
    "    for lnl_looper, involved_level in enumerate(lnls):\n",
    "        if diagnose_type[lnl_looper +1] == True:\n",
    "            involved_ipsi.append(involved_level) \n",
    "        if diagnose_type[lnl_looper +7] == True:\n",
    "            involved_contra.append(involved_level)\n",
    "    invovlvement_ipsi.append(involved_ipsi)\n",
    "    invovlvement_contra.append(involved_contra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8192"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(t_stage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_export = pd.DataFrame({'Percentage of patients': full_risks,\n",
    "                                'T-stage': t_stage,\n",
    "                                'Involvement Ipsi' : invovlvement_ipsi,\n",
    "                                'Involvement Contra': invovlvement_contra,\n",
    "                                'Treated Ipsi':  treated_ipsi,\n",
    "                                'Treated Contra': treated_contra,\n",
    "                                'risk': total_risks,\n",
    "                                'lower bound': flat_lower,\n",
    "                                'upper bound': flat_upper,\n",
    "                                'top 3 spared lnls risk': top3_spared,\n",
    "                                'lnls ranked': lnls_ranked\n",
    "})\n",
    "data_export.to_csv('lymph_1_midline_full_table_central_new_code.csv', sep = ';', index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Results Export\n",
    "\n",
    "## Final Treatment Table Export\n",
    "\n",
    "The completed analysis generates the final clinical decision tables\n",
    "\n",
    "This CSV file contains:\n",
    "- **All diagnostic scenarios**: Every possible combination of LNL involvement patterns\n",
    "- **Treatment recommendations**: Which LNLs can be safely spared for each scenario\n",
    "- **Risk assessments**: 95% CI upper bounds ensuring safety thresholds\n",
    "- **Clinical applicability**: Ready-to-use guidelines for DeEsco trial treatment decisions\n",
    "\n",
    "The table serves as the primary clinical reference for treatment planning in the DeEsco trial, ensuring both midline and central tumor cases receive appropriate, evidence-based care while maximizing LNL sparing opportunities."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
