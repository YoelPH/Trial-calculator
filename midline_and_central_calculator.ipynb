{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This code uses a specific lymph version!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Setup\n",
    "built on lymph 1.0.0.clin-trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.special import factorial\n",
    "import scipy as sp\n",
    "import emcee                      # inference and backends for sample storage\n",
    "from multiprocessing import Pool  # for parallelization of the inference\n",
    "import lymph\n",
    "\n",
    "graph = {\n",
    "    ('tumor', 'primary')  : ['I','II', 'III', 'IV','V','VII'], \n",
    "    ('lnl'  , 'I') :       ['II'],\n",
    "    ('lnl'  , 'II') :       ['III'], \n",
    "    ('lnl'  , 'III'):       ['IV'], \n",
    "    ('lnl'  , 'IV') :       ['V'],\n",
    "    ('lnl'  , 'V') :       [],\n",
    "    ('lnl'  , 'VII') :       []\n",
    "    \n",
    "}\n",
    "model = lymph.models.Midline(graph_dict= graph,tumor_state = 1, unilateral_kwargs={'allowed_states':[0,1], 'max_time':10}, use_central = True, use_midext_evo = False, marginalize_unknown= False)\n",
    "model.set_modality('max_llh',spec = 1,sens = 1)\n",
    "\n",
    "# Time prior with p(early) = 0.3\n",
    "def binom_pmf(k: np.ndarray, n: int, p: float):\n",
    "    \"\"\"Binomial PMF\"\"\"\n",
    "    if p > 1. or p < 0.:\n",
    "        raise ValueError(\"Binomial prob must be btw. 0 and 1\")\n",
    "    q = (1. - p)\n",
    "    binom_coeff = factorial(n) / (factorial(k) * factorial(n - k))\n",
    "    return binom_coeff * p**k * q**(n - k)\n",
    "\n",
    "def late_binomial(support: np.ndarray, p: float = 0.5) -> np.ndarray:\n",
    "    \"\"\"Parametrized binomial distribution.\"\"\"\n",
    "    return binom_pmf(support, n=support[-1], p=p)\n",
    "\n",
    "max_t = 10\n",
    "model.set_distribution('early',sp.stats.binom.pmf(np.arange(max_t+1), max_t, 0.3))\n",
    "model.set_distribution('late', late_binomial)\n",
    "model.set_modality('treatment_diagnose', spec = 1, sens = 0.81)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2160, 18)\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "with h5py.File(\"trial_samples_central.h5\", \"r\") as f:\n",
    "    samples1 = f[\"chain\"][...]\n",
    "samples1 = samples1.reshape(-1, samples1.shape[-1])\n",
    "print(samples1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'midext_prob': 0.0,\n",
       " 'ipsi_primarytoI_spread': 0.026599934089507535,\n",
       " 'ipsi_primarytoII_spread': 0.3754362312489512,\n",
       " 'ipsi_primarytoIII_spread': 0.07350634235991671,\n",
       " 'ipsi_primarytoIV_spread': 0.009868764752471882,\n",
       " 'ipsi_primarytoV_spread': 0.01608922143844808,\n",
       " 'ipsi_primarytoVII_spread': 0.021790771223072873,\n",
       " 'contra_primarytoI_spread': 0.0032833634932873815,\n",
       " 'contra_primarytoII_spread': 0.025330185925201906,\n",
       " 'contra_primarytoIII_spread': 0.0023198951662066233,\n",
       " 'contra_primarytoIV_spread': 0.0028514226257283703,\n",
       " 'contra_primarytoV_spread': 0.000656088933696782,\n",
       " 'contra_primarytoVII_spread': 0.006324800116350196,\n",
       " 'mixing': 0.22533811234978024,\n",
       " 'ItoII_spread': 0.7470325433932157,\n",
       " 'IItoIII_spread': 0.1444848004577465,\n",
       " 'IIItoIV_spread': 0.16715051321273394,\n",
       " 'IVtoV_spread': 0.17189301394039708,\n",
       " 'late_p': 0.36914158720690937}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled_mean = samples1.mean(axis = 0)\n",
    "params = {'mixing': sampled_mean[0],\n",
    "        'ipsi_primarytoI_spread': sampled_mean[1],\n",
    "        'ipsi_primarytoII_spread': sampled_mean[2],\n",
    "        'ipsi_primarytoIII_spread': sampled_mean[3],\n",
    "        'ipsi_primarytoIV_spread': sampled_mean[4],\n",
    "        'ipsi_primarytoV_spread': sampled_mean[5],\n",
    "        'ipsi_primarytoVII_spread': sampled_mean[6],\n",
    "        'contra_primarytoI_spread': sampled_mean[7],\n",
    "        'contra_primarytoII_spread': sampled_mean[8],\n",
    "        'contra_primarytoIII_spread': sampled_mean[9],\n",
    "        'contra_primarytoIV_spread': sampled_mean[10],   \n",
    "        'contra_primarytoV_spread': sampled_mean[11],\n",
    "        'contra_primarytoVII_spread': sampled_mean[12],\n",
    "        'ItoII_spread': sampled_mean[13],\n",
    "        'IItoIII_spread': sampled_mean[14],\n",
    "        'IIItoIV_spread': sampled_mean[15],\n",
    "        'IVtoV_spread': sampled_mean[16],\n",
    "        'late_p': sampled_mean[17]}\n",
    "model.set_params(**params)\n",
    "model.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "dataset_full = pd.read_csv(\"data/cleaned.csv\", header=[0,1,2]) #import data\n",
    "dataset_USZ =  pd.read_csv(\"data/cleanedUSZ.csv\", header=[0,1,2]) #import data\n",
    "\n",
    "maxllh =  dataset_USZ['max_llh']\n",
    "t_stage = dataset_USZ['info']\n",
    "ipsi = maxllh.loc[:,'ipsi'].drop(['IIa','IIb','VIII','Ib','IX','VI','X','Ia'],axis = 1)[['I','II','III','IV','V','VII']]\n",
    "contra = maxllh.loc[:,'contra'].drop(['IIa','IIb','VIII','Ib','IX','VI','X','Ia'],axis = 1)[['I','II','III','IV','V','VII']]\n",
    "ipsi_header = header = pd.MultiIndex.from_product([ ['ipsi'], ['I','II','III','IV','V','VII']], names=['', ''])\n",
    "contra_header = pd.MultiIndex.from_product([['contra'], ['I','II','III','IV','V','VII']], names=['', ''])\n",
    "ipsi.columns = ipsi_header\n",
    "contra.columns = contra_header\n",
    "\n",
    "dataset_analyze = pd.concat([t_stage,ipsi,contra],axis = 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's take a look at some examples\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "reduce the samples to the needed amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sparing_scripts import sample_from_flattened\n",
    "\n",
    "samples_reduced = sample_from_flattened(samples1, num_samples = 216, spaced = True, step_size = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('ipsi III', 0.08275283447364559), ('ipsi II', 1.0000000000000002)]\n",
      "6.629766388350969\n",
      "[('contra V', 0.00042763173316175606), ('contra I', 0.0009891023055616907), ('contra IV', 0.0014467123203597062), ('contra III', 0.0015009689751277794), ('contra VII', 0.0036182001687979333), ('ipsi IV', 0.007896204657586742), ('ipsi V', 0.009609714097105536), ('ipsi VII', 0.012807244016318392), ('contra II', 0.013067004381272224), ('ipsi I', 0.018191576282428446)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([5.75407088, 7.54938061])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sparing_scripts import risk_sampled, levels_to_spare, ci_single\n",
    "\n",
    "diagnose = {\"ipsi\": {'treatment_diagnose':{\n",
    "        \"I\": 0,\n",
    "        \"II\": 1,\n",
    "        \"III\": 0,\n",
    "        \"IV\": 0,\n",
    "        \"V\": 0,\n",
    "        \"VII\": 0\n",
    "    }},\n",
    "    \"contra\": {'treatment_diagnose':{\n",
    "        \"I\": 0,\n",
    "        \"II\": 0,\n",
    "        \"III\": 0,\n",
    "        \"IV\": 0,\n",
    "        \"V\": 0,\n",
    "        \"VII\": 0\n",
    "    }}}\n",
    "sampled_risks, risk = risk_sampled(samples = samples_reduced, model = model, t_stage = 'early', given_diagnoses= diagnose,central = None, midline_extension= False)     \n",
    "spared_lnls, total_risk, ranked_combined, treated_lnls, treated_array, treated_ipsi, treated_contra, sampled_total_risks = levels_to_spare(0.10, model, risk, sampled_risks, ci = False)\n",
    "print(treated_lnls)\n",
    "print(total_risk*100)\n",
    "print(spared_lnls)\n",
    "ci_single(sampled_total_risks)*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combination analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we produce all possible combinations of diagnoses to compute the risks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "# Sample array with different entry combinations\n",
    "data = np.array(dataset_analyze)\n",
    "\n",
    "entry_combinations_with_indexes = defaultdict(list)\n",
    "for index, row in enumerate(data):\n",
    "    combination = tuple(row)\n",
    "    entry_combinations_with_indexes[combination].append(index)\n",
    "USZ_counts = []\n",
    "USZ_combinations = []\n",
    "USZ_indexes = []\n",
    "for combination, indexes in entry_combinations_with_indexes.items():\n",
    "    count = len(indexes)\n",
    "    USZ_indexes.append(indexes)\n",
    "    USZ_counts.append(count)\n",
    "    USZ_combinations.append(combination)\n",
    "\n",
    "lnls = ['I','II', 'III', 'IV','V', 'VII']\n",
    "t_stage = []\n",
    "midline_extension = []\n",
    "invovlvement_ipsi_USZ = []\n",
    "invovlvement_contra_USZ = []\n",
    "for diagnose_type in USZ_combinations:\n",
    "    involved_ipsi = []\n",
    "    involved_contra = []\n",
    "    t_stage.append(diagnose_type[0])\n",
    "    midline_extension.append(diagnose_type[1])\n",
    "    for lnl_looper, involved_level in enumerate(lnls):\n",
    "        if diagnose_type[lnl_looper +2] == True:\n",
    "            involved_ipsi.append(involved_level) \n",
    "        if diagnose_type[lnl_looper +8] == True:\n",
    "            involved_contra.append(involved_level)\n",
    "    invovlvement_ipsi_USZ.append(involved_ipsi)\n",
    "    invovlvement_contra_USZ.append(involved_contra)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "first only check the USZ dataset for relevant entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sparing_scripts import count_number_treatments, analysis_treated_lnls_combinations\n",
    "usz_treated_lnls_no_risk, usz_treated_lnls_all, usz_treatment_array, usz_top3_spared, usz_total_risks, usz_treated_ipsi, usz_treated_contra, usz_sampled_risks_array, usz_lnls_ranked, cis = analysis_treated_lnls_combinations(combinations = USZ_combinations, model = model, samples = samples_reduced, threshold = 0.10)\n",
    "usz_set_counts = count_number_treatments(usz_treated_lnls_no_risk)\n",
    "len(usz_set_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Percentage of patients</th>\n",
       "      <th>T-stage</th>\n",
       "      <th>Midline Extension</th>\n",
       "      <th>Involvement Ipsi</th>\n",
       "      <th>Involvement Contra</th>\n",
       "      <th>Treated Ipsi</th>\n",
       "      <th>Treated Contra</th>\n",
       "      <th>risk</th>\n",
       "      <th>lower bound</th>\n",
       "      <th>upper bound</th>\n",
       "      <th>top 3 spared lnls risk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.048780</td>\n",
       "      <td>late</td>\n",
       "      <td>True</td>\n",
       "      <td>[II]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[III, II]</td>\n",
       "      <td>[II]</td>\n",
       "      <td>0.078032</td>\n",
       "      <td>0.066303</td>\n",
       "      <td>0.091473</td>\n",
       "      <td>[(ipsi I, 0.02018212044831703), (ipsi VII, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.010453</td>\n",
       "      <td>early</td>\n",
       "      <td>False</td>\n",
       "      <td>[II]</td>\n",
       "      <td>[II]</td>\n",
       "      <td>[III, II]</td>\n",
       "      <td>[III, II]</td>\n",
       "      <td>0.076328</td>\n",
       "      <td>0.062081</td>\n",
       "      <td>0.097589</td>\n",
       "      <td>[(ipsi I, 0.020745164441888973), (contra I, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.003484</td>\n",
       "      <td>late</td>\n",
       "      <td>True</td>\n",
       "      <td>[I, II, III, IV, VII]</td>\n",
       "      <td>[I, II, III, IV]</td>\n",
       "      <td>[V, I, II, III, IV, VII]</td>\n",
       "      <td>[I, II, III, IV]</td>\n",
       "      <td>0.061390</td>\n",
       "      <td>0.034468</td>\n",
       "      <td>0.095027</td>\n",
       "      <td>[(contra V, 0.049917866263852986), (contra VII...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.003484</td>\n",
       "      <td>late</td>\n",
       "      <td>True</td>\n",
       "      <td>[II, III, IV, VII]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[V, VII, II, III, IV]</td>\n",
       "      <td>[II]</td>\n",
       "      <td>0.066456</td>\n",
       "      <td>0.055051</td>\n",
       "      <td>0.077370</td>\n",
       "      <td>[(ipsi I, 0.028686386918113108), (contra III, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.010453</td>\n",
       "      <td>early</td>\n",
       "      <td>False</td>\n",
       "      <td>[II, VII]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[III, II, VII]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.063806</td>\n",
       "      <td>0.054496</td>\n",
       "      <td>0.073761</td>\n",
       "      <td>[(ipsi I, 0.021186904157757556), (contra II, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>0.003484</td>\n",
       "      <td>early</td>\n",
       "      <td>False</td>\n",
       "      <td>[II, IV]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[V, III, II, IV]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.062058</td>\n",
       "      <td>0.052172</td>\n",
       "      <td>0.072464</td>\n",
       "      <td>[(ipsi I, 0.022471174486049225), (ipsi VII, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>0.006969</td>\n",
       "      <td>late</td>\n",
       "      <td>False</td>\n",
       "      <td>[II, III, V]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[IV, II, III, V]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.075202</td>\n",
       "      <td>0.062002</td>\n",
       "      <td>0.087899</td>\n",
       "      <td>[(ipsi I, 0.02735384799828265), (ipsi VII, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>0.003484</td>\n",
       "      <td>late</td>\n",
       "      <td>True</td>\n",
       "      <td>[II, III]</td>\n",
       "      <td>[II, III, IV]</td>\n",
       "      <td>[I, IV, II, III]</td>\n",
       "      <td>[V, II, III, IV]</td>\n",
       "      <td>0.066285</td>\n",
       "      <td>0.054837</td>\n",
       "      <td>0.080623</td>\n",
       "      <td>[(ipsi VII, 0.02303066023513181), (ipsi V, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>0.003484</td>\n",
       "      <td>late</td>\n",
       "      <td>False</td>\n",
       "      <td>[II, V]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[IV, III, II, V]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.066396</td>\n",
       "      <td>0.054162</td>\n",
       "      <td>0.077747</td>\n",
       "      <td>[(ipsi I, 0.024086145154078375), (ipsi VII, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>0.003484</td>\n",
       "      <td>late</td>\n",
       "      <td>True</td>\n",
       "      <td>[II, III, V]</td>\n",
       "      <td>[II, III, VII]</td>\n",
       "      <td>[IV, II, III, V]</td>\n",
       "      <td>[IV, II, III, VII]</td>\n",
       "      <td>0.077072</td>\n",
       "      <td>0.063330</td>\n",
       "      <td>0.094659</td>\n",
       "      <td>[(ipsi I, 0.032094726768564626), (ipsi VII, 0....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>77 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Percentage of patients T-stage  Midline Extension       Involvement Ipsi  \\\n",
       "0                 0.048780    late               True                   [II]   \n",
       "1                 0.010453   early              False                   [II]   \n",
       "2                 0.003484    late               True  [I, II, III, IV, VII]   \n",
       "3                 0.003484    late               True     [II, III, IV, VII]   \n",
       "4                 0.010453   early              False              [II, VII]   \n",
       "..                     ...     ...                ...                    ...   \n",
       "72                0.003484   early              False               [II, IV]   \n",
       "73                0.006969    late              False           [II, III, V]   \n",
       "74                0.003484    late               True              [II, III]   \n",
       "75                0.003484    late              False                [II, V]   \n",
       "76                0.003484    late               True           [II, III, V]   \n",
       "\n",
       "   Involvement Contra              Treated Ipsi      Treated Contra      risk  \\\n",
       "0                  []                 [III, II]                [II]  0.078032   \n",
       "1                [II]                 [III, II]           [III, II]  0.076328   \n",
       "2    [I, II, III, IV]  [V, I, II, III, IV, VII]    [I, II, III, IV]  0.061390   \n",
       "3                  []     [V, VII, II, III, IV]                [II]  0.066456   \n",
       "4                  []            [III, II, VII]                  []  0.063806   \n",
       "..                ...                       ...                 ...       ...   \n",
       "72                 []          [V, III, II, IV]                  []  0.062058   \n",
       "73                 []          [IV, II, III, V]                  []  0.075202   \n",
       "74      [II, III, IV]          [I, IV, II, III]    [V, II, III, IV]  0.066285   \n",
       "75                 []          [IV, III, II, V]                  []  0.066396   \n",
       "76     [II, III, VII]          [IV, II, III, V]  [IV, II, III, VII]  0.077072   \n",
       "\n",
       "    lower bound  upper bound  \\\n",
       "0      0.066303     0.091473   \n",
       "1      0.062081     0.097589   \n",
       "2      0.034468     0.095027   \n",
       "3      0.055051     0.077370   \n",
       "4      0.054496     0.073761   \n",
       "..          ...          ...   \n",
       "72     0.052172     0.072464   \n",
       "73     0.062002     0.087899   \n",
       "74     0.054837     0.080623   \n",
       "75     0.054162     0.077747   \n",
       "76     0.063330     0.094659   \n",
       "\n",
       "                               top 3 spared lnls risk  \n",
       "0   [(ipsi I, 0.02018212044831703), (ipsi VII, 0.0...  \n",
       "1   [(ipsi I, 0.020745164441888973), (contra I, 0....  \n",
       "2   [(contra V, 0.049917866263852986), (contra VII...  \n",
       "3   [(ipsi I, 0.028686386918113108), (contra III, ...  \n",
       "4   [(ipsi I, 0.021186904157757556), (contra II, 0...  \n",
       "..                                                ...  \n",
       "72  [(ipsi I, 0.022471174486049225), (ipsi VII, 0....  \n",
       "73  [(ipsi I, 0.02735384799828265), (ipsi VII, 0.0...  \n",
       "74  [(ipsi VII, 0.02303066023513181), (ipsi V, 0.0...  \n",
       "75  [(ipsi I, 0.024086145154078375), (ipsi VII, 0....  \n",
       "76  [(ipsi I, 0.032094726768564626), (ipsi VII, 0....  \n",
       "\n",
       "[77 rows x 11 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sparing_scripts import ci_multiple\n",
    "ci = ci_multiple(usz_sampled_risks_array)\n",
    "data_export_usz = pd.DataFrame({'Percentage of patients': np.array(USZ_counts)/287,\n",
    "                                'T-stage': t_stage,\n",
    "                                'Midline Extension': midline_extension,\n",
    "                                'Involvement Ipsi' : invovlvement_ipsi_USZ,\n",
    "                                'Involvement Contra': invovlvement_contra_USZ,\n",
    "                                'Treated Ipsi':  usz_treated_ipsi,\n",
    "                                'Treated Contra': usz_treated_contra,\n",
    "                                'risk': usz_total_risks,\n",
    "                                'lower bound': ci.T[0],\n",
    "                                'upper bound': ci.T[1],\n",
    "                                'top 3 spared lnls risk': usz_top3_spared\n",
    "\n",
    "})\n",
    "# data_export_usz.to_csv('analyzed_usz_data_new_dataset.csv', sep = ';', index = False)\n",
    "# data_export_usz.sort_values(by = 'Percentage of patients', ascending = False, inplace = True)\n",
    "data_export_usz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now let's go for all possible combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "from sparing_scripts import change_base\n",
    "\n",
    "def produce_combinations_list(array):\n",
    "    combinations_list = []\n",
    "    for entry in array:\n",
    "        combination = []\n",
    "        for index, cells in enumerate(entry):\n",
    "            if index == 0:\n",
    "                combination.append('early') if cells == 0 else combination.append('late')\n",
    "            else:\n",
    "                combination.append(False) if cells == 0 else combination.append(True)\n",
    "        combination = tuple(combination)\n",
    "        combinations_list.append(combination)\n",
    "    return(combinations_list)\n",
    "\n",
    "combination_array = np.zeros((2**14,14))\n",
    "for i in range(2**14):\n",
    "    combination_array[i] = [\n",
    "        int(digit) for digit in change_base(i, 2, length=14)\n",
    "    ]\n",
    "\n",
    "all_combinations = produce_combinations_list(combination_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's add some multiprocessing to speed up the analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing as mp\n",
    "\n",
    "# Function to process a chunk of combinations\n",
    "def process_combinations(chunk):\n",
    "    return analysis_treated_lnls_combinations(chunk, samples_reduced, model)\n",
    "\n",
    "# Divide the combinations into chunks\n",
    "num_cores = mp.cpu_count() - 1\n",
    "chunk_size = len(all_combinations) // num_cores\n",
    "chunks = [all_combinations[i:i + chunk_size] for i in range(0, len(all_combinations), chunk_size)]\n",
    "\n",
    "# Use multiprocessing to process the chunks\n",
    "with mp.Pool(num_cores) as pool:\n",
    "    results = pool.map(process_combinations, chunks)\n",
    "\n",
    "# Combine the results from all chunks\n",
    "treated_lnls_no_risk, treated_lnls_all, treatment_array, top3_spared, total_risks, treated_ipsi, treated_contra, sampled_risks_array, lnls_ranked, cis = zip(*results)\n",
    "\n",
    "# Flatten the results\n",
    "treated_lnls_no_risk = [item for sublist in treated_lnls_no_risk for item in sublist]\n",
    "treated_lnls_all = [item for sublist in treated_lnls_all for item in sublist]\n",
    "treatment_array = np.vstack(treatment_array)\n",
    "top3_spared = [item for sublist in top3_spared for item in sublist]\n",
    "total_risks = np.concatenate(total_risks)\n",
    "treated_ipsi = [item for sublist in treated_ipsi for item in sublist]\n",
    "treated_contra = [item for sublist in treated_contra for item in sublist]\n",
    "sampled_risks_array = np.vstack(sampled_risks_array)\n",
    "lnls_ranked = [item for sublist in lnls_ranked for item in sublist]\n",
    "cis_lower = []\n",
    "cis_upper = []\n",
    "for item in cis:\n",
    "    cis_lower.append(item[0])\n",
    "    cis_upper.append(item[1])\n",
    "flat_lower = [item for sublist in cis_lower for item in sublist]\n",
    "flat_upper = [item for sublist in cis_upper for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yoel/Documents/Risk_evaluator/.venv/lib/python3.10/site-packages/lymph/models/bilateral.py:601: UserWarning: No diagnoses given for ipsilateral side.\n",
      "  warnings.warn(f\"No diagnoses given for {side}lateral side.\")\n",
      "/home/yoel/Documents/Risk_evaluator/.venv/lib/python3.10/site-packages/lymph/models/bilateral.py:601: UserWarning: No diagnoses given for contralateral side.\n",
      "  warnings.warn(f\"No diagnoses given for {side}lateral side.\")\n"
     ]
    }
   ],
   "source": [
    "sampled_risks_early_no_ext, mean_risk_early_no_ext = risk_sampled(samples_reduced, model, 'early', midline_extension = False, given_diagnoses = None) \n",
    "sampled_risks_early_ext, mean_risk_early_ext = risk_sampled(samples_reduced, model, 'early', midline_extension = True, given_diagnoses = None)\n",
    "sampled_risks_late_no_ext, mean_risk_late_no_ext = risk_sampled(samples_reduced, model, 'late', midline_extension = False, given_diagnoses = None)\n",
    "sampled_risks_late_ext, mean_risk_late_ext = risk_sampled(samples_reduced, model, 'late', midline_extension = True, given_diagnoses = None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: Here we assume that the probability of early no extension, late no extension, early extension, and late extension are all equal for the prevalence calculation (which is generally not true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate state list\n",
    "state_list = np.array(np.meshgrid(*[[0, 1]] * 14)).T.reshape(-1, 14)\n",
    "state_list = state_list[np.lexsort(np.fliplr(state_list).T)]\n",
    "# Reshape the risk arrays into 1x4096 arrays\n",
    "mean_risk_early_noext_flat = mean_risk_early_no_ext.reshape(-1)\n",
    "mean_risk_early_ext_flat = mean_risk_early_ext.reshape(-1)\n",
    "mean_risk_late_noext_flat = mean_risk_late_no_ext.reshape(-1)\n",
    "mean_risk_late_ext_flat = mean_risk_late_ext.reshape(-1)\n",
    "#combine them\n",
    "full_risks = np.hstack([mean_risk_early_noext_flat, mean_risk_early_ext_flat, mean_risk_late_noext_flat, mean_risk_late_ext_flat])/4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "lnls = ['I','II', 'III', 'IV','V', 'VII']\n",
    "t_stage = []\n",
    "midline_extension = []\n",
    "invovlvement_ipsi = []\n",
    "invovlvement_contra = []\n",
    "for diagnose_type in all_combinations:\n",
    "    involved_ipsi = []\n",
    "    involved_contra = []\n",
    "    t_stage.append(diagnose_type[0])\n",
    "    midline_extension.append(diagnose_type[1])\n",
    "    for lnl_looper, involved_level in enumerate(lnls):\n",
    "        if diagnose_type[lnl_looper +2] == True:\n",
    "            involved_ipsi.append(involved_level) \n",
    "        if diagnose_type[lnl_looper +8] == True:\n",
    "            involved_contra.append(involved_level)\n",
    "    invovlvement_ipsi.append(involved_ipsi)\n",
    "    invovlvement_contra.append(involved_contra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_export = pd.DataFrame({'Percentage of patients': full_risks,\n",
    "                                'T-stage': t_stage,\n",
    "                                'Midline Extension': midline_extension,\n",
    "                                'Involvement Ipsi' : invovlvement_ipsi,\n",
    "                                'Involvement Contra': invovlvement_contra,\n",
    "                                'Treated Ipsi':  treated_ipsi,\n",
    "                                'Treated Contra': treated_contra,\n",
    "                                'risk': total_risks,\n",
    "                                'lower bound': flat_lower,\n",
    "                                'upper bound': flat_upper,\n",
    "                                'top 3 spared lnls risk': top3_spared,\n",
    "                                'lnls ranked': lnls_ranked\n",
    "})\n",
    "data_export.to_csv('lymph_1_midline_full_table_new_code.csv', sep = ';', index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate state list\n",
    "state_list = np.array(np.meshgrid(*[[0, 1]] * 14)).T.reshape(-1, 14)\n",
    "state_list = state_list[np.lexsort(np.fliplr(state_list).T)]\n",
    "# Reshape the risk arrays into 1x4096 arrays\n",
    "mean_risk_early_noext_flat = mean_risk_early_no_ext.reshape(-1)\n",
    "mean_risk_early_ext_flat = mean_risk_early_ext.reshape(-1)\n",
    "mean_risk_late_noext_flat = mean_risk_late_no_ext.reshape(-1)\n",
    "mean_risk_late_ext_flat = mean_risk_late_ext.reshape(-1)\n",
    "#combine them\n",
    "full_risks = np.hstack([mean_risk_early_noext_flat, mean_risk_early_ext_flat, mean_risk_late_noext_flat, mean_risk_late_ext_flat])/4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lnls = ['I','II', 'III', 'IV','V', 'VII']\n",
    "t_stage = []\n",
    "midline_extension = []\n",
    "invovlvement_ipsi = []\n",
    "invovlvement_contra = []\n",
    "for diagnose_type in all_combinations:\n",
    "    involved_ipsi = []\n",
    "    involved_contra = []\n",
    "    t_stage.append(diagnose_type[0])\n",
    "    midline_extension.append(diagnose_type[1])\n",
    "    for lnl_looper, involved_level in enumerate(lnls):\n",
    "        if diagnose_type[lnl_looper +2] == True:\n",
    "            involved_ipsi.append(involved_level) \n",
    "        if diagnose_type[lnl_looper +8] == True:\n",
    "            involved_contra.append(involved_level)\n",
    "    invovlvement_ipsi.append(involved_ipsi)\n",
    "    invovlvement_contra.append(involved_contra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_export = pd.DataFrame({'Percentage of patients': full_risks,\n",
    "                                'T-stage': t_stage,\n",
    "                                'Midline Extension': midline_extension,\n",
    "                                'Involvement Ipsi' : invovlvement_ipsi,\n",
    "                                'Involvement Contra': invovlvement_contra,\n",
    "                                'Treated Ipsi':  treated_ipsi,\n",
    "                                'Treated Contra': treated_contra,\n",
    "                                'risk': total_risks,\n",
    "                                'lower bound': flat_lower,\n",
    "                                'upper bound': flat_upper,\n",
    "                                'top 3 spared lnls risk': top3_spared,\n",
    "                                'lnls ranked': lnls_ranked\n",
    "})\n",
    "# data_export.to_csv('lymph_1_midline_full_table_new_code.csv', sep = ';', index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "data_export = pd.read_csv('lymph_1_midline_full_table_new_code.csv', sep = ';',index_col = 0)\n",
    "\n",
    "# Convert the 'top 3 spared lnls risk' column entries from string to list\n",
    "data_export['top 3 spared lnls risk'] = data_export['top 3 spared lnls risk'].apply(ast.literal_eval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Repetition for central tumors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('contra IV', 0.037551931885452604), ('ipsi III', 0.07113523562144895), ('contra III', 0.07753806577784034), ('ipsi II', 0.3901153901968219), ('contra II', 0.3910006966386991), ('contra V', 0.9999999999999999), ('contra VII', 0.9999999999999999)]\n",
      "5.934673708187034\n",
      "[('ipsi IV', 0.008840717851276231), ('ipsi V', 0.011207865507930409), ('ipsi I', 0.013270528909690948), ('contra I', 0.013291558979265285), ('ipsi VII', 0.014863897704879543)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([4.90089467, 7.10058273])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sparing_scripts import risk_sampled, levels_to_spare, ci_single\n",
    "\n",
    "diagnose = {\"ipsi\": {'treatment_diagnose':{\n",
    "        \"I\": 0,\n",
    "        \"II\": 0,\n",
    "        \"III\": 1,\n",
    "        \"IV\": 0,\n",
    "        \"V\": 0,\n",
    "        \"VII\": 0\n",
    "    }},\n",
    "    \"contra\": {'treatment_diagnose':{\n",
    "        \"I\": 0,\n",
    "        \"II\": 0,\n",
    "        \"III\": 0,\n",
    "        \"IV\": 0,\n",
    "        \"V\": 1,\n",
    "        \"VII\": 1\n",
    "    }}}\n",
    "sampled_risks, risk = risk_sampled(samples = samples_reduced, model = model, t_stage = 'late', given_diagnoses= diagnose,central = True)     \n",
    "spared_lnls, total_risk, ranked_combined, treated_lnls, treated_array, treated_ipsi, treated_contra, sampled_total_risks = levels_to_spare(0.10, model, risk, sampled_risks, ci = True)\n",
    "print(treated_lnls)\n",
    "print(total_risk*100)\n",
    "print(spared_lnls)\n",
    "ci_single(sampled_total_risks)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "combination_array_central = np.zeros((2**13,13))\n",
    "for i in range(2**13):\n",
    "    combination_array_central[i] = [\n",
    "        int(digit) for digit in change_base(i, 2, length=13)\n",
    "    ]\n",
    "\n",
    "all_combinations_central = produce_combinations_list(combination_array_central)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing as mp\n",
    "\n",
    "# Function to process a chunk of combinations\n",
    "def process_combinations(chunk):\n",
    "    return analysis_treated_lnls_combinations(chunk, samples_reduced, model, central = True)\n",
    "\n",
    "# Divide the combinations into chunks\n",
    "num_cores = mp.cpu_count() - 2\n",
    "chunk_size = len(all_combinations_central) // num_cores\n",
    "chunks = [all_combinations_central[i:i + chunk_size] for i in range(0, len(all_combinations_central), chunk_size)]\n",
    "\n",
    "# Use multiprocessing to process the chunks\n",
    "with mp.Pool(num_cores) as pool:\n",
    "    results = pool.map(process_combinations, chunks)\n",
    "\n",
    "# Combine the results from all chunks\n",
    "treated_lnls_no_risk, treated_lnls_all, treatment_array, top3_spared, total_risks, treated_ipsi, treated_contra, sampled_risks_array, lnls_ranked, cis = zip(*results)\n",
    "\n",
    "# Flatten the results\n",
    "treated_lnls_no_risk = [item for sublist in treated_lnls_no_risk for item in sublist]\n",
    "treated_lnls_all = [item for sublist in treated_lnls_all for item in sublist]\n",
    "treatment_array = np.vstack(treatment_array)\n",
    "top3_spared = [item for sublist in top3_spared for item in sublist]\n",
    "total_risks = np.concatenate(total_risks)\n",
    "treated_ipsi = [item for sublist in treated_ipsi for item in sublist]\n",
    "treated_contra = [item for sublist in treated_contra for item in sublist]\n",
    "sampled_risks_array = np.vstack(sampled_risks_array)\n",
    "lnls_ranked = [item for sublist in lnls_ranked for item in sublist]\n",
    "cis_lower = []\n",
    "cis_upper = []\n",
    "for item in cis:\n",
    "    cis_lower.append(item[0])\n",
    "    cis_upper.append(item[1])\n",
    "flat_lower = [item for sublist in cis_lower for item in sublist]\n",
    "flat_upper = [item for sublist in cis_upper for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_risks_early, mean_risk_early = risk_sampled(samples_reduced, model, 'early', central = True, given_diagnoses = None) \n",
    "sampled_risks_late, mean_risk_late = risk_sampled(samples_reduced, model, 'late', central = True, given_diagnoses = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate state list\n",
    "state_list = np.array(np.meshgrid(*[[0, 1]] * 13)).T.reshape(-1, 13)\n",
    "state_list = state_list[np.lexsort(np.fliplr(state_list).T)]\n",
    "# Reshape the risk arrays into 1x4096 arrays\n",
    "mean_risk_early = mean_risk_early.reshape(-1)\n",
    "mean_risk_late = mean_risk_late.reshape(-1)\n",
    "#combine them\n",
    "full_risks = np.hstack([mean_risk_early, mean_risk_late])/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "lnls = ['I','II', 'III', 'IV','V', 'VII']\n",
    "t_stage = []\n",
    "invovlvement_ipsi = []\n",
    "invovlvement_contra = []\n",
    "for diagnose_type in all_combinations_central:\n",
    "    involved_ipsi = []\n",
    "    involved_contra = []\n",
    "    t_stage.append(diagnose_type[0])\n",
    "    for lnl_looper, involved_level in enumerate(lnls):\n",
    "        if diagnose_type[lnl_looper +1] == True:\n",
    "            involved_ipsi.append(involved_level) \n",
    "        if diagnose_type[lnl_looper +7] == True:\n",
    "            involved_contra.append(involved_level)\n",
    "    invovlvement_ipsi.append(involved_ipsi)\n",
    "    invovlvement_contra.append(involved_contra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8192"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(t_stage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_export = pd.DataFrame({'Percentage of patients': full_risks,\n",
    "                                'T-stage': t_stage,\n",
    "                                'Involvement Ipsi' : invovlvement_ipsi,\n",
    "                                'Involvement Contra': invovlvement_contra,\n",
    "                                'Treated Ipsi':  treated_ipsi,\n",
    "                                'Treated Contra': treated_contra,\n",
    "                                'risk': total_risks,\n",
    "                                'lower bound': flat_lower,\n",
    "                                'upper bound': flat_upper,\n",
    "                                'top 3 spared lnls risk': top3_spared,\n",
    "                                'lnls ranked': lnls_ranked\n",
    "})\n",
    "data_export.to_csv('lymph_1_midline_full_table_central_new_code.csv', sep = ';', index = True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
