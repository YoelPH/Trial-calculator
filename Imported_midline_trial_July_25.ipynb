{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This code is not functional as it uses a different version of lymph!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "built on lymph 1.0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.special import factorial\n",
    "import scipy as sp\n",
    "import emcee                      # inference and backends for sample storage\n",
    "from multiprocessing import Pool  # for parallelization of the inference\n",
    "import lymph\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "graph = {\n",
    "    ('tumor', 'primary')  : ['I','II', 'III', 'IV','V','VII'], \n",
    "    ('lnl'  , 'I') :       ['II'],\n",
    "    ('lnl'  , 'II') :       ['III'], \n",
    "    ('lnl'  , 'III'):       ['IV'], \n",
    "    ('lnl'  , 'IV') :       ['V'],\n",
    "    ('lnl'  , 'V') :       [],\n",
    "    ('lnl'  , 'VII') :       []\n",
    "    \n",
    "}\n",
    "model = lymph.models.Midline(graph_dict= graph,tumor_state = 1, unilateral_kwargs={'allowed_states':[0,1], 'max_time':10}, use_central = False, use_midext_evo = False, marginalize_unknown= False)\n",
    "model.set_modality('max_llh',spec = 1,sens = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# Time prior with p(early) = 0.3\n",
    "def binom_pmf(k: np.ndarray, n: int, p: float):\n",
    "    \"\"\"Binomial PMF\"\"\"\n",
    "    if p > 1. or p < 0.:\n",
    "        raise ValueError(\"Binomial prob must be btw. 0 and 1\")\n",
    "    q = (1. - p)\n",
    "    binom_coeff = factorial(n) / (factorial(k) * factorial(n - k))\n",
    "    return binom_coeff * p**k * q**(n - k)\n",
    "\n",
    "def late_binomial(support: np.ndarray, p: float = 0.5) -> np.ndarray:\n",
    "    \"\"\"Parametrized binomial distribution.\"\"\"\n",
    "    return binom_pmf(support, n=support[-1], p=p)\n",
    "\n",
    "max_t = 10\n",
    "model.set_distribution('early',sp.stats.binom.pmf(np.arange(max_t+1), max_t, 0.3))\n",
    "model.set_distribution('late', late_binomial)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2160, 18)\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "with h5py.File(\"trial_samples_central.h5\", \"r\") as f:\n",
    "    samples1 = f[\"chain\"][...]\n",
    "samples1 = samples1.reshape(-1, samples1.shape[-1])\n",
    "print(samples1.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "former way to thin the original samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# tau = 2000\n",
    "# burnin = int(2 * np.max(tau))\n",
    "# thin = int(0.5 * np.min(tau))\n",
    "# samples1 = backend.get_chain(discard=burnin, flat=True, thin=thin)\n",
    "# print(\"burn-in: {0}\".format(burnin))\n",
    "# print(\"thin: {0}\".format(thin))\n",
    "# print(\"flat chain shape: {0}\".format(samples1.shape))\n",
    "# print(backend.get_chain().shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'midext_prob': 0.0,\n",
       " 'ipsi_primarytoI_spread': 0.026599934089507535,\n",
       " 'ipsi_primarytoII_spread': 0.3754362312489512,\n",
       " 'ipsi_primarytoIII_spread': 0.07350634235991671,\n",
       " 'ipsi_primarytoIV_spread': 0.009868764752471882,\n",
       " 'ipsi_primarytoV_spread': 0.01608922143844808,\n",
       " 'ipsi_primarytoVII_spread': 0.021790771223072873,\n",
       " 'contra_primarytoI_spread': 0.0032833634932873815,\n",
       " 'contra_primarytoII_spread': 0.025330185925201906,\n",
       " 'contra_primarytoIII_spread': 0.0023198951662066233,\n",
       " 'contra_primarytoIV_spread': 0.0028514226257283703,\n",
       " 'contra_primarytoV_spread': 0.000656088933696782,\n",
       " 'contra_primarytoVII_spread': 0.006324800116350196,\n",
       " 'mixing': 0.22533811234978024,\n",
       " 'ItoII_spread': 0.7470325433932157,\n",
       " 'IItoIII_spread': 0.1444848004577465,\n",
       " 'IIItoIV_spread': 0.16715051321273394,\n",
       " 'IVtoV_spread': 0.17189301394039708,\n",
       " 'late_p': 0.36914158720690937}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled_mean = samples1.mean(axis = 0)\n",
    "params = {'mixing': sampled_mean[0],\n",
    "        'ipsi_primarytoI_spread': sampled_mean[1],\n",
    "        'ipsi_primarytoII_spread': sampled_mean[2],\n",
    "        'ipsi_primarytoIII_spread': sampled_mean[3],\n",
    "        'ipsi_primarytoIV_spread': sampled_mean[4],\n",
    "        'ipsi_primarytoV_spread': sampled_mean[5],\n",
    "        'ipsi_primarytoVII_spread': sampled_mean[6],\n",
    "        'contra_primarytoI_spread': sampled_mean[7],\n",
    "        'contra_primarytoII_spread': sampled_mean[8],\n",
    "        'contra_primarytoIII_spread': sampled_mean[9],\n",
    "        'contra_primarytoIV_spread': sampled_mean[10],   \n",
    "        'contra_primarytoV_spread': sampled_mean[11],\n",
    "        'contra_primarytoVII_spread': sampled_mean[12],\n",
    "        'ItoII_spread': sampled_mean[13],\n",
    "        'IItoIII_spread': sampled_mean[14],\n",
    "        'IIItoIV_spread': sampled_mean[15],\n",
    "        'IVtoV_spread': sampled_mean[16],\n",
    "        'late_p': sampled_mean[17]}\n",
    "model.set_params(**params)\n",
    "model.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "()"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.set_params(**{'midext_prob':1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yoel/Documents/Risk_evaluator/.venv/lib/python3.10/site-packages/lymph/models/bilateral.py:601: UserWarning: No diagnoses given for ipsilateral side.\n",
      "  warnings.warn(f\"No diagnoses given for {side}lateral side.\")\n",
      "/home/yoel/Documents/Risk_evaluator/.venv/lib/python3.10/site-packages/lymph/models/bilateral.py:601: UserWarning: No diagnoses given for contralateral side.\n",
      "  warnings.warn(f\"No diagnoses given for {side}lateral side.\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.2818128586929223"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "involvement = {\n",
    "    'contra' :{\n",
    "        'II' :True\n",
    "    },\n",
    "    'ipsi':{\n",
    "        \n",
    "    }\n",
    "}\n",
    "model.risk(involvement = involvement, given_params = params, midline_extension=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "model.set_modality('treatment_diagnose', spec = 1, sens = 0.81)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "dataset_full = pd.read_csv(\"cleaned.csv\", header=[0,1,2]) #import data\n",
    "dataset_USZ =  pd.read_csv(\"cleanedUSZ.csv\", header=[0,1,2]) #import data\n",
    "\n",
    "maxllh =  dataset_USZ['max_llh']\n",
    "t_stage = dataset_USZ['info']\n",
    "ipsi = maxllh.loc[:,'ipsi'].drop(['IIa','IIb','VIII','Ib','IX','VI','X','Ia'],axis = 1)[['I','II','III','IV','V','VII']]\n",
    "contra = maxllh.loc[:,'contra'].drop(['IIa','IIb','VIII','Ib','IX','VI','X','Ia'],axis = 1)[['I','II','III','IV','V','VII']]\n",
    "ipsi_header = header = pd.MultiIndex.from_product([ ['ipsi'], ['I','II','III','IV','V','VII']], names=['', ''])\n",
    "contra_header = pd.MultiIndex.from_product([['contra'], ['I','II','III','IV','V','VII']], names=['', ''])\n",
    "ipsi.columns = ipsi_header\n",
    "contra.columns = contra_header\n",
    "\n",
    "dataset_analyze = pd.concat([t_stage,ipsi,contra],axis = 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Here follows the analysis on the central tumor location patients in the USZ dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "full_USZ =  pd.read_csv(\"2021-usz-oropharynx.csv\", header=[0,1,2]) #import data\n",
    "central_patients = dataset_analyze.loc[full_USZ['tumor']['1']['central']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "def risk_sampled_central(samples, model, t_stage, given_diagnoses, thin = 10):\n",
    "    sampled_risks = np.zeros(shape=(len(samples[::thin]),64,64), dtype=float)\n",
    "    for i, sample in enumerate(np.random.permutation(samples[::thin])):\n",
    "        params = {'mixing': sample[0],\n",
    "        'ipsi_primarytoI_spread': sample[1],\n",
    "        'ipsi_primarytoII_spread': sample[2],\n",
    "        'ipsi_primarytoIII_spread': sample[3],\n",
    "        'ipsi_primarytoIV_spread': sample[4],\n",
    "        'ipsi_primarytoV_spread': sample[5],\n",
    "        'ipsi_primarytoVII_spread': sample[6],\n",
    "        'contra_primarytoI_spread': sample[7],\n",
    "        'contra_primarytoII_spread': sample[8],\n",
    "        'contra_primarytoIII_spread': sample[9],\n",
    "        'contra_primarytoIV_spread': sample[10],   \n",
    "        'contra_primarytoV_spread': sample[11],\n",
    "        'contra_primarytoVII_spread': sample[12],\n",
    "        'ItoII_spread': sample[13],\n",
    "        'IItoIII_spread': sample[14],\n",
    "        'IIItoIV_spread': sample[15],\n",
    "        'IVtoV_spread': sample[16],\n",
    "        'late_p': sample[17]}\n",
    "        model.assign_params(**params)\n",
    "        sampled_risks[i] = model.risk(t_stage = t_stage, given_diagnoses = given_diagnoses, central = True) \n",
    "    mean_risk = sampled_risks.mean(axis = 0)\n",
    "    return sampled_risks, mean_risk\n",
    "\n",
    "def levelstospare_central(threshold, model, risks, sampled_risks):\n",
    "    \"\"\"Computes which LNLs to irradiate given the threshold, model and the risk of each state.\n",
    "\n",
    "    Args:\n",
    "        threshold (float): Risk threshold we want to apply\n",
    "        model (lymph.Unilateral): lymph.unilateral object with fully analyzed patients\n",
    "        risks (ndarray): Array with the risk of each state\n",
    "\n",
    "    Returns:\n",
    "        _type_: _description_\n",
    "    \"\"\"\n",
    "    state_list = model.central.ipsi.state_list\n",
    "    lnls = ['I', 'II', 'III', 'IV', 'V', 'VII']\n",
    "    overall_risk_ipsi = {}\n",
    "    overall_risk_contra = {}\n",
    "    for index, lnl in enumerate(lnls):\n",
    "        overall_risk_ipsi[lnl] = risks[np.where((state_list[:,index] == 1))[0]].sum()\n",
    "        overall_risk_contra[lnl] = risks.T[np.where((state_list[:,index] == 1))[0]].sum()\n",
    "\n",
    "    combined_dict = {f'ipsi {key}': value for key, value in overall_risk_ipsi.items()}\n",
    "    combined_dict.update({f'contra {key}': value for key, value in overall_risk_contra.items()})\n",
    "    ranked_combined = sorted(combined_dict.items(), key = lambda item: item[1])\n",
    "    total_risk_new = 0\n",
    "    sampled_total_risks_new = np.zeros(sampled_risks.shape[0])\n",
    "    looper = 1\n",
    "    treated_array = np.ones(12)\n",
    "    contra_lnl_indices = []\n",
    "    ipsi_lnl_indices = []\n",
    "    treated_ipsi = []\n",
    "    treated_contra = []\n",
    "    while total_risk_new < threshold:\n",
    "        sampled_total_risks = sampled_total_risks_new\n",
    "        total_risk = total_risk_new\n",
    "        if ipsi_lnl_indices != []:\n",
    "            treated_array[ipsi_lnl_indices] = 0\n",
    "        if contra_lnl_indices != []:\n",
    "            treated_array[np.array(contra_lnl_indices)+6] = 0\n",
    "        lnls_of_interest = ranked_combined[0:looper]\n",
    "        lnls_of_interest_names = [t[0] for t in lnls_of_interest]\n",
    "        contra_lnl_indices = []\n",
    "        ipsi_lnl_indices = []\n",
    "        for i,lnl_looper in enumerate(lnls_of_interest_names):\n",
    "            contra_lnl_indices.append(np.where(np.array(lnls) == lnls_of_interest_names[i].split()[1])[0][0]) if lnl_looper.split()[0] == 'contra' else ipsi_lnl_indices.append(np.where(np.array(lnls) == lnls_of_interest_names[i].split()[1])[0][0])\n",
    "        indices_list_contra = []\n",
    "        indices_list_ipsi = []\n",
    "        for index in contra_lnl_indices:\n",
    "            condition_contra = (state_list[:, index] == 1)\n",
    "            indices_contra = np.where(condition_contra)[0]\n",
    "            indices_list_contra.extend(indices_contra)\n",
    "            unique_contra = np.unique(indices_list_contra)\n",
    "        for index in ipsi_lnl_indices:\n",
    "            condition_ipsi = (state_list[:, index] == 1)\n",
    "            indices_ipsi = np.where(condition_ipsi)[0]\n",
    "            indices_list_ipsi.extend(indices_ipsi)\n",
    "            unique_ipsi = np.unique(indices_list_ipsi)    \n",
    "        if len(ipsi_lnl_indices) == 0:\n",
    "            total_risk_new = risks.T[unique_contra].sum()\n",
    "            sampled_total_risks_new = sampled_risks.transpose((0,2,1))[:,unique_contra].sum(axis = (1,2))\n",
    "        elif len(contra_lnl_indices) == 0:\n",
    "            total_risk_new = risks[unique_ipsi].sum()\n",
    "            sampled_total_risks_new = sampled_risks[:,unique_ipsi].sum(axis = (1,2))\n",
    "        else:\n",
    "            total_risk_new = 0\n",
    "            sampled_total_risks_new = np.zeros(sampled_risks.shape[0])\n",
    "            total_risk_new += risks[unique_ipsi].sum()\n",
    "            total_risk_new += risks.T[unique_contra][:,[np.setdiff1d(np.array(range(64)),unique_ipsi)]].sum()\n",
    "            sampled_total_risks_new += sampled_risks[:,unique_ipsi].sum(axis = (1,2))\n",
    "            sampled_total_risks_new += sampled_risks.transpose((0,2,1))[:,unique_contra][:,:,list(np.setdiff1d(np.array(range(64)),unique_ipsi))].sum(axis = (1,2))\n",
    "\n",
    "        spared_lnls = lnls_of_interest[:-1]\n",
    "        treated_lnls = ranked_combined[looper-1:]\n",
    "        looper += 1\n",
    "    for to_treat in treated_lnls:\n",
    "        if to_treat[0].split()[0] == 'ipsi':\n",
    "            treated_ipsi.append(to_treat[0].split()[1])\n",
    "        else: \n",
    "            treated_contra.append(to_treat[0].split()[1])\n",
    "    return spared_lnls, total_risk, ranked_combined, treated_lnls, treated_array, treated_ipsi, treated_contra,sampled_total_risks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sparing_scripts import sample_from_flattened\n",
    "\n",
    "samples_reduced = sample_from_flattened(samples1, num_samples = 216, spaced = True, step_size = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('contra II', 0.06700558976741193), ('ipsi III', 0.09544252013137532), ('ipsi II', 1.0000000000000004)]\n",
      "7.803191450136049\n",
      "[('contra V', 0.0027096298969616446), ('contra IV', 0.002879082831950057), ('contra I', 0.0028877936682658477), ('contra VII', 0.006292845036804311), ('ipsi IV', 0.009386054215524034), ('ipsi V', 0.01086744558213284), ('contra III', 0.012683190788655168), ('ipsi VII', 0.01439047847542773), ('ipsi I', 0.02018212044831703)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([6.63026685, 9.14726159])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sparing_scripts import risk_sampled, levels_to_spare_old, levels_to_spare, ci_single\n",
    "\n",
    "diagnose = {\"ipsi\": {'treatment_diagnose':{\n",
    "        \"I\": 0,\n",
    "        \"II\": 1,\n",
    "        \"III\": 0,\n",
    "        \"IV\": 0,\n",
    "        \"V\": 0,\n",
    "        \"VII\": 0\n",
    "    }},\n",
    "    \"contra\": {'treatment_diagnose':{\n",
    "        \"I\": 0,\n",
    "        \"II\": 0,\n",
    "        \"III\": 0,\n",
    "        \"IV\": 0,\n",
    "        \"V\": 0,\n",
    "        \"VII\": 0\n",
    "    }}}\n",
    "sampled_risks, risk = risk_sampled(samples = samples_reduced, model = model, t_stage = 'late', given_diagnoses= diagnose,central = None, midline_extension= True)     \n",
    "spared_lnls, total_risk, ranked_combined, treated_lnls, treated_array, treated_ipsi, treated_contra, sampled_total_risks = levels_to_spare_old(0.10, model, risk, sampled_risks)\n",
    "print(treated_lnls)\n",
    "print(total_risk*100)\n",
    "print(spared_lnls)\n",
    "ci_single(sampled_total_risks)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sparing_scripts import get_risks_by_side, get_lnl_indices, get_state_indices, change_base\n",
    "def levels_to_spare(threshold, model, mean_risks, sampled_risks, ci=False):\n",
    "    \"\"\"\n",
    "    Determine the levels of lymph nodes to spare based on a risk threshold.\n",
    "    This function evaluates the risks associated with ipsilateral (ipsi) and \n",
    "    contralateral (contra) lymph node levels (LNLs) and determines which levels \n",
    "    can be spared while keeping the total risk below a specified threshold.\n",
    "    Parameters:\n",
    "    -----------\n",
    "    threshold : float\n",
    "        The maximum allowable total risk for sparing lymph node levels.\n",
    "    model : object\n",
    "        A model object containing the state list and lymph node level (LNL) information.\n",
    "    risks_mean : numpy.ndarray\n",
    "        Array of risks associated with each state in the model.\n",
    "    sampled_risks : numpy.ndarray\n",
    "        Array of sampled risks for uncertainty estimation, with shape \n",
    "        (num_samples, num_states, num_states).\n",
    "    ci : bool, optional\n",
    "        If True, confidence intervals are used to determine sparing decisions. \n",
    "        Default is False.\n",
    "    Returns:\n",
    "    --------\n",
    "    spared_lnls : list of tuples\n",
    "        List of spared lymph node levels and their associated risks, sorted by risk.\n",
    "    total_risk_new : float\n",
    "        The total risk after sparing the selected lymph node levels.\n",
    "    ranked_combined : list of tuples\n",
    "        List of all lymph node levels and their associated risks, sorted by risk.\n",
    "    treated_lnls : list of tuples\n",
    "        List of treated lymph node levels and their associated risks.\n",
    "    treated_array : numpy.ndarray\n",
    "        Array indicating which states are treated (1 for treated, 0 for spared).\n",
    "    treated_ipsi : list of str\n",
    "        Names of treated ipsilateral lymph node levels.\n",
    "    treated_contra : list of str\n",
    "        Names of treated contralateral lymph node levels.\n",
    "    sampled_total_risks_new : numpy.ndarray\n",
    "        Array of sampled total risks after sparing the selected lymph node levels.\n",
    "    Notes:\n",
    "    ------\n",
    "    - The function iteratively evaluates lymph node levels to spare, starting \n",
    "      from the lowest risk levels, until the total risk exceeds the threshold.\n",
    "    - If `ci` is True, confidence intervals are used to refine the sparing \n",
    "      decision.\n",
    "    \"\"\"\n",
    "    if threshold <= 0:\n",
    "        raise ValueError(\"Threshold must be larger than zero\")\n",
    "    if isinstance(model, lymph.models.Midline):\n",
    "        lnls = list(model.noext.ipsi.graph.lnls.keys())\n",
    "    else:\n",
    "        raise TypeError(\"Model must be an instance of lymph.models.Midline\")\n",
    "\n",
    "    state_list = np.zeros((2**len(lnls), len(lnls)))\n",
    "    for i in range(2**len(lnls)):  # Updated to use len(lnls)\n",
    "        state_list[i] = [\n",
    "            int(digit) for digit in change_base(i, 2, length=len(lnls))  # Updated length to len(lnls)\n",
    "        ]\n",
    "        \n",
    "    ipsi_risks, contra_risks = get_risks_by_side(mean_risks, state_list, lnls)\n",
    "    combined_risks = {f'ipsi {k}': v for k, v in ipsi_risks.items()}\n",
    "    combined_risks.update({f'contra {k}': v for k, v in contra_risks.items()})\n",
    "    ranked_combined = sorted(combined_risks.items(), key=lambda x: x[1])\n",
    "\n",
    "    looper = 1\n",
    "    treated_array = np.ones(len(ranked_combined))\n",
    "    total_risk_new = 0\n",
    "    sampled_total_risks_new = np.zeros(sampled_risks.shape[0])\n",
    "    treated_array[:] = 1\n",
    "    ipsi_idx = []\n",
    "    contra_idx = []\n",
    "    spared_lnls = []\n",
    "    treated_lnls = ranked_combined.copy()\n",
    "    while looper < len(lnls) * 2 + 2:\n",
    "        # define which LNLs are treated\n",
    "        if ci and (ci_single(sampled_total_risks_new)[1] >= threshold):\n",
    "            spared_lnls = ranked_combined[:looper - 2]\n",
    "            treated_lnls = ranked_combined[looper - 2:]\n",
    "            break\n",
    "        elif total_risk_new >= threshold:\n",
    "            spared_lnls = ranked_combined[:looper - 2]\n",
    "            treated_lnls = ranked_combined[looper - 2:]\n",
    "            break\n",
    "        total_risk = total_risk_new\n",
    "        sampled_total_risk = sampled_total_risks_new\n",
    "        treated_array[ipsi_idx] = 0\n",
    "        treated_array[list(np.array(contra_idx) + 6)] = 0\n",
    "        # exclude the next LNL from the target volume\n",
    "        lnls_of_interest = [name for name, _ in ranked_combined[:looper]]\n",
    "        ipsi_idx, contra_idx = get_lnl_indices(lnls_of_interest, lnls)\n",
    "        idx_ipsi = get_state_indices(state_list, ipsi_idx)\n",
    "        idx_contra = get_state_indices(state_list, contra_idx)\n",
    "        not_idx_ipsi = np.setdiff1d(np.arange(state_list.shape[0]), idx_ipsi) #we get all the indices of the ipsilateral that are in the target volume\n",
    "\n",
    "        # calculate risk of the spared LNLs\n",
    "        # if no ipsi LNLs are excluded from the target volume, we simply sum the contra risks and vice versa\n",
    "        if not ipsi_idx:\n",
    "            total_risk_new = mean_risks.T[idx_contra].sum()\n",
    "            sampled_total_risks_new = sampled_risks.transpose(0, 2, 1)[:, idx_contra].sum(axis=(1, 2))\n",
    "        elif not contra_idx:\n",
    "            total_risk_new = mean_risks[idx_ipsi].sum()\n",
    "            sampled_total_risks_new = sampled_risks[:, idx_ipsi].sum(axis=(1, 2))\n",
    "        else:\n",
    "            total_risk_new = (\n",
    "                mean_risks[idx_ipsi].sum() +\n",
    "                mean_risks.T[idx_contra][:, not_idx_ipsi].sum()\n",
    "            )\n",
    "            sampled_total_risks_new = (\n",
    "                sampled_risks[:, idx_ipsi].sum(axis=(1, 2)) +\n",
    "                sampled_risks.transpose(0, 2, 1)[:, idx_contra][:, :, not_idx_ipsi].sum(axis=(1, 2))\n",
    "            )\n",
    "        looper += 1\n",
    "\n",
    "    treated_ipsi = [name.split()[1] for name, _ in treated_lnls if name.startswith(\"ipsi\")]\n",
    "    treated_contra = [name.split()[1] for name, _ in treated_lnls if name.startswith(\"contra\")]\n",
    "\n",
    "    return (\n",
    "        spared_lnls,\n",
    "        total_risk,\n",
    "        ranked_combined,\n",
    "        treated_lnls,\n",
    "        treated_array,\n",
    "        treated_ipsi,\n",
    "        treated_contra,\n",
    "        sampled_total_risk,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('contra II', 0.06700558976741193), ('ipsi III', 0.09544252013137532), ('ipsi II', 1.0000000000000004)]\n",
      "7.803191450136049\n",
      "[('contra V', 0.0027096298969616446), ('contra IV', 0.002879082831950057), ('contra I', 0.0028877936682658477), ('contra VII', 0.006292845036804311), ('ipsi IV', 0.009386054215524034), ('ipsi V', 0.01086744558213284), ('contra III', 0.012683190788655168), ('ipsi VII', 0.01439047847542773), ('ipsi I', 0.02018212044831703)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([6.63026685, 9.14726159])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled_risks, risk = risk_sampled(samples = samples_reduced, model = model, t_stage = 'late', given_diagnoses= diagnose,central = None, midline_extension= True)     \n",
    "spared_lnls, total_risk, ranked_combined, treated_lnls, treated_array, treated_ipsi, treated_contra, sampled_total_risks = levels_to_spare(0.10, model, risk, sampled_risks, ci = False)\n",
    "print(treated_lnls)\n",
    "print(total_risk*100)\n",
    "print(spared_lnls)\n",
    "ci_single(sampled_total_risks)*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combination analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "# Sample array with different entry combinations\n",
    "data = np.array(dataset_analyze)\n",
    "\n",
    "entry_combinations_with_indexes = defaultdict(list)\n",
    "for index, row in enumerate(data):\n",
    "    combination = tuple(row)\n",
    "    entry_combinations_with_indexes[combination].append(index)\n",
    "USZ_counts = []\n",
    "USZ_combinations = []\n",
    "USZ_indexes = []\n",
    "# Print the most common combinations, their USZ_counts, and indexes\n",
    "for combination, indexes in entry_combinations_with_indexes.items():\n",
    "    count = len(indexes)\n",
    "    USZ_indexes.append(indexes)\n",
    "    # print(f\"Combination: {combination}, Count: {count}, Indexes: {indexes}\")\n",
    "    USZ_counts.append(count)\n",
    "    USZ_combinations.append(combination)\n",
    "\n",
    "lnls = ['I','II', 'III', 'IV','V', 'VII']\n",
    "t_stage = []\n",
    "midline_extension = []\n",
    "invovlvement_ipsi_USZ = []\n",
    "invovlvement_contra_USZ = []\n",
    "for diagnose_type in USZ_combinations:\n",
    "    involved_ipsi = []\n",
    "    involved_contra = []\n",
    "    t_stage.append(diagnose_type[0])\n",
    "    midline_extension.append(diagnose_type[1])\n",
    "    for lnl_looper, involved_level in enumerate(lnls):\n",
    "        if diagnose_type[lnl_looper +2] == True:\n",
    "            involved_ipsi.append(involved_level) \n",
    "        if diagnose_type[lnl_looper +8] == True:\n",
    "            involved_contra.append(involved_level)\n",
    "    invovlvement_ipsi_USZ.append(involved_ipsi)\n",
    "    invovlvement_contra_USZ.append(involved_contra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "def produce_combinations_list(array):\n",
    "    combinations_list = []\n",
    "    for entry in array:\n",
    "        combination = []\n",
    "        for index, cells in enumerate(entry):\n",
    "            if index == 0:\n",
    "                combination.append('early') if cells == 0 else combination.append('late')\n",
    "            else:\n",
    "                combination.append(False) if cells == 0 else combination.append(True)\n",
    "        combination = tuple(combination)\n",
    "        combinations_list.append(combination)\n",
    "    return(combinations_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "from sparing_scripts import change_base\n",
    "combination_array = np.zeros((2**14,14))\n",
    "for i in range(2**14):\n",
    "    combination_array[i] = [\n",
    "        int(digit) for digit in change_base(i, 2, length=14)\n",
    "    ]\n",
    "\n",
    "all_combinations = produce_combinations_list(combination_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sparing_scripts import analysis_treated_lnls_combinations_old, count_number_treatments, analysis_treated_lnls_combinations\n",
    "usz_treated_lnls_no_risk, usz_treated_lnls_all, usz_treatment_array, usz_top3_spared, usz_total_risks, usz_treated_ipsi, usz_treated_contra, usz_sampled_risks_array = analysis_treated_lnls_combinations_old(combinations = USZ_combinations, model = model, samples = samples_reduced, threshold = 0.10)\n",
    "usz_set_counts = count_number_treatments(usz_treated_lnls_no_risk)\n",
    "len(usz_set_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing as mp\n",
    "\n",
    "# Function to process a chunk of combinations\n",
    "def process_combinations(chunk):\n",
    "    return analysis_treated_lnls_combinations_old(chunk, samples_reduced, model)\n",
    "\n",
    "# Divide the combinations into chunks\n",
    "num_cores = mp.cpu_count() - 1\n",
    "chunk_size = len(USZ_combinations) // num_cores\n",
    "chunks = [USZ_combinations[i:i + chunk_size] for i in range(0, len(USZ_combinations), chunk_size)]\n",
    "\n",
    "# Use multiprocessing to process the chunks\n",
    "with mp.Pool(num_cores) as pool:\n",
    "    results = pool.map(process_combinations, chunks)\n",
    "\n",
    "# Combine the results from all chunks\n",
    "usz_treated_lnls_no_risk, usz_treated_lnls_all, usz_treatment_array, usz_top3_spared, usz_total_risks, usz_treated_ipsi, usz_treated_contra, usz_sampled_risks_array = zip(*results)\n",
    "\n",
    "\n",
    "# Flatten the results\n",
    "usz_treated_lnls_no_risk = [item for sublist in usz_treated_lnls_no_risk for item in sublist]\n",
    "usz_treated_lnls_all = [item for sublist in usz_treated_lnls_all for item in sublist]\n",
    "usz_treatment_array = np.vstack(usz_treatment_array)\n",
    "usz_top3_spared = [item for sublist in usz_top3_spared for item in sublist]\n",
    "usz_total_risks = np.concatenate(usz_total_risks)\n",
    "usz_treated_ipsi = [item for sublist in usz_treated_ipsi for item in sublist]\n",
    "usz_treated_contra = [item for sublist in usz_treated_contra for item in sublist]\n",
    "usz_sampled_risks_array = np.vstack(usz_sampled_risks_array)\n",
    "cis_lower = []\n",
    "cis_upper = []\n",
    "# flat_lower = [item for sublist in cis_lower for item in sublist]\n",
    "# flat_upper = [item for sublist in cis_upper for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sparing_scripts import ci_multiple\n",
    "df = pd.DataFrame(usz_treatment_array)\n",
    "df.to_csv('treatment_array_new_dataset.csv')\n",
    "ci = ci_multiple(usz_sampled_risks_array)\n",
    "data_export_usz = pd.DataFrame({'Percentage of patients': np.array(USZ_counts)/287,\n",
    "                                'T-stage': t_stage,\n",
    "                                'Midline Extension': midline_extension,\n",
    "                                'Involvement Ipsi' : invovlvement_ipsi_USZ,\n",
    "                                'Involvement Contra': invovlvement_contra_USZ,\n",
    "                                'Treated Ipsi':  usz_treated_ipsi,\n",
    "                                'Treated Contra': usz_treated_contra,\n",
    "                                'risk': usz_total_risks,\n",
    "                                'lower bound': ci.T[0],\n",
    "                                'upper bound': ci.T[1],\n",
    "                                'top 3 spared lnls risk': usz_top3_spared\n",
    "\n",
    "})\n",
    "# data_export_usz.to_csv('analyzed_usz_data_new_dataset.csv', sep = ';', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Percentage of patients</th>\n",
       "      <th>T-stage</th>\n",
       "      <th>Midline Extension</th>\n",
       "      <th>Involvement Ipsi</th>\n",
       "      <th>Involvement Contra</th>\n",
       "      <th>Treated Ipsi</th>\n",
       "      <th>Treated Contra</th>\n",
       "      <th>risk</th>\n",
       "      <th>lower bound</th>\n",
       "      <th>upper bound</th>\n",
       "      <th>top 3 spared lnls risk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.048780</td>\n",
       "      <td>late</td>\n",
       "      <td>True</td>\n",
       "      <td>[II]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[III, II]</td>\n",
       "      <td>[II]</td>\n",
       "      <td>0.078032</td>\n",
       "      <td>0.066303</td>\n",
       "      <td>0.091473</td>\n",
       "      <td>[(ipsi I, 0.02018212044831703), (ipsi VII, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.010453</td>\n",
       "      <td>early</td>\n",
       "      <td>False</td>\n",
       "      <td>[II]</td>\n",
       "      <td>[II]</td>\n",
       "      <td>[III, II]</td>\n",
       "      <td>[III, II]</td>\n",
       "      <td>0.076328</td>\n",
       "      <td>0.062081</td>\n",
       "      <td>0.097589</td>\n",
       "      <td>[(ipsi I, 0.020745164441888973), (contra I, 0....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Percentage of patients T-stage  Midline Extension Involvement Ipsi  \\\n",
       "0                0.048780    late               True             [II]   \n",
       "1                0.010453   early              False             [II]   \n",
       "\n",
       "  Involvement Contra Treated Ipsi Treated Contra      risk  lower bound  \\\n",
       "0                 []    [III, II]           [II]  0.078032     0.066303   \n",
       "1               [II]    [III, II]      [III, II]  0.076328     0.062081   \n",
       "\n",
       "   upper bound                             top 3 spared lnls risk  \n",
       "0     0.091473  [(ipsi I, 0.02018212044831703), (ipsi VII, 0.0...  \n",
       "1     0.097589  [(ipsi I, 0.020745164441888973), (contra I, 0....  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_export_usz.sort_values(by = 'Percentage of patients', ascending = False, inplace = True)\n",
    "data_export_usz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing as mp\n",
    "\n",
    "# Function to process a chunk of combinations\n",
    "def process_combinations(chunk):\n",
    "    return analysis_treated_lnls_combinations(chunk, samples_reduced, model)\n",
    "\n",
    "# Divide the combinations into chunks\n",
    "num_cores = mp.cpu_count() - 1\n",
    "chunk_size = len(USZ_combinations) // num_cores\n",
    "chunks = [USZ_combinations[i:i + chunk_size] for i in range(0, len(USZ_combinations), chunk_size)]\n",
    "\n",
    "# Use multiprocessing to process the chunks\n",
    "with mp.Pool(num_cores) as pool:\n",
    "    results = pool.map(process_combinations, chunks)\n",
    "\n",
    "# Combine the results from all chunks\n",
    "treated_lnls_no_risk, treated_lnls_all, treatment_array, top3_spared, total_risks, treated_ipsi, treated_contra, sampled_risks_array, lnls_ranked, cis = zip(*results)\n",
    "\n",
    "spared_lnls, total_risk, ranked_combined, treated_lnls, treated_array, treated_ipsi, treated_contra,sampled_total_risks\n",
    "\n",
    "# Flatten the results\n",
    "treated_lnls_no_risk = [item for sublist in treated_lnls_no_risk for item in sublist]\n",
    "treated_lnls_all = [item for sublist in treated_lnls_all for item in sublist]\n",
    "treatment_array = np.vstack(treatment_array)\n",
    "top3_spared = [item for sublist in top3_spared for item in sublist]\n",
    "total_risks = np.concatenate(total_risks)\n",
    "treated_ipsi = [item for sublist in treated_ipsi for item in sublist]\n",
    "treated_contra = [item for sublist in treated_contra for item in sublist]\n",
    "sampled_risks_array = np.vstack(sampled_risks_array)\n",
    "lnls_ranked = [item for sublist in lnls_ranked for item in sublist]\n",
    "cis_lower = []\n",
    "cis_upper = []\n",
    "for item in cis:\n",
    "    cis_lower.append(item[0])\n",
    "    cis_upper.append(item[1])\n",
    "flat_lower = [item for sublist in cis_lower for item in sublist]\n",
    "flat_upper = [item for sublist in cis_upper for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_export = pd.DataFrame({'Percentage of patients': np.array(USZ_counts)/287,\n",
    "                                'T-stage': t_stage,\n",
    "                                'Midline Extension': midline_extension,\n",
    "                                'Involvement Ipsi' : invovlvement_ipsi_USZ,\n",
    "                                'Involvement Contra': invovlvement_contra_USZ,\n",
    "                                'Treated Ipsi':  treated_ipsi,\n",
    "                                'Treated Contra': treated_contra,\n",
    "                                'risk': total_risks,\n",
    "                                'lower bound': flat_lower,\n",
    "                                'upper bound': flat_upper,\n",
    "                                'top 3 spared lnls risk': top3_spared,\n",
    "                                'lnls ranked': lnls_ranked\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Percentage of patients</th>\n",
       "      <th>T-stage</th>\n",
       "      <th>Midline Extension</th>\n",
       "      <th>Involvement Ipsi</th>\n",
       "      <th>Involvement Contra</th>\n",
       "      <th>Treated Ipsi</th>\n",
       "      <th>Treated Contra</th>\n",
       "      <th>risk</th>\n",
       "      <th>lower bound</th>\n",
       "      <th>upper bound</th>\n",
       "      <th>top 3 spared lnls risk</th>\n",
       "      <th>lnls ranked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.048780</td>\n",
       "      <td>late</td>\n",
       "      <td>True</td>\n",
       "      <td>[II]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[III, II]</td>\n",
       "      <td>[II]</td>\n",
       "      <td>0.078032</td>\n",
       "      <td>0.066303</td>\n",
       "      <td>0.091473</td>\n",
       "      <td>[(ipsi I, 0.02018212044831703), (ipsi VII, 0.0...</td>\n",
       "      <td>[(contra V, 0.0027096298969616446), (contra IV...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.010453</td>\n",
       "      <td>early</td>\n",
       "      <td>False</td>\n",
       "      <td>[II]</td>\n",
       "      <td>[II]</td>\n",
       "      <td>[III, II]</td>\n",
       "      <td>[III, II]</td>\n",
       "      <td>0.076328</td>\n",
       "      <td>0.062081</td>\n",
       "      <td>0.097589</td>\n",
       "      <td>[(ipsi I, 0.020745164441888973), (contra I, 0....</td>\n",
       "      <td>[(contra V, 0.0005149602766912587), (contra IV...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.003484</td>\n",
       "      <td>late</td>\n",
       "      <td>True</td>\n",
       "      <td>[I, II, III, IV, VII]</td>\n",
       "      <td>[I, II, III, IV]</td>\n",
       "      <td>[V, I, II, III, IV, VII]</td>\n",
       "      <td>[I, II, III, IV]</td>\n",
       "      <td>0.061390</td>\n",
       "      <td>0.034468</td>\n",
       "      <td>0.095027</td>\n",
       "      <td>[(contra V, 0.049917866263852986), (contra VII...</td>\n",
       "      <td>[(contra VII, 0.012112972989043888), (contra V...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.003484</td>\n",
       "      <td>late</td>\n",
       "      <td>True</td>\n",
       "      <td>[II, III, IV, VII]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[V, VII, II, III, IV]</td>\n",
       "      <td>[II]</td>\n",
       "      <td>0.066456</td>\n",
       "      <td>0.055051</td>\n",
       "      <td>0.077370</td>\n",
       "      <td>[(ipsi I, 0.028686386918113108), (contra III, ...</td>\n",
       "      <td>[(contra I, 0.0036276705171799607), (contra V,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.010453</td>\n",
       "      <td>early</td>\n",
       "      <td>False</td>\n",
       "      <td>[II, VII]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[III, II, VII]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.063806</td>\n",
       "      <td>0.054496</td>\n",
       "      <td>0.073761</td>\n",
       "      <td>[(ipsi I, 0.021186904157757556), (contra II, 0...</td>\n",
       "      <td>[(contra V, 0.0005162140395875805), (contra I,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>0.003484</td>\n",
       "      <td>early</td>\n",
       "      <td>False</td>\n",
       "      <td>[II, IV]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[V, III, II, IV]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.062058</td>\n",
       "      <td>0.052172</td>\n",
       "      <td>0.072464</td>\n",
       "      <td>[(ipsi I, 0.022471174486049225), (ipsi VII, 0....</td>\n",
       "      <td>[(contra V, 0.0005607980420941032), (contra I,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>0.006969</td>\n",
       "      <td>late</td>\n",
       "      <td>False</td>\n",
       "      <td>[II, III, V]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[IV, II, III, V]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.075202</td>\n",
       "      <td>0.062002</td>\n",
       "      <td>0.087899</td>\n",
       "      <td>[(ipsi I, 0.02735384799828265), (ipsi VII, 0.0...</td>\n",
       "      <td>[(contra V, 0.0007207744996925012), (contra I,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>0.003484</td>\n",
       "      <td>late</td>\n",
       "      <td>True</td>\n",
       "      <td>[II, III]</td>\n",
       "      <td>[II, III, IV]</td>\n",
       "      <td>[I, IV, II, III]</td>\n",
       "      <td>[V, II, III, IV]</td>\n",
       "      <td>0.066285</td>\n",
       "      <td>0.054837</td>\n",
       "      <td>0.080623</td>\n",
       "      <td>[(ipsi VII, 0.02303066023513181), (ipsi V, 0.0...</td>\n",
       "      <td>[(contra VII, 0.010017866467273907), (contra I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>0.003484</td>\n",
       "      <td>late</td>\n",
       "      <td>False</td>\n",
       "      <td>[II, V]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[IV, III, II, V]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.066396</td>\n",
       "      <td>0.054162</td>\n",
       "      <td>0.077747</td>\n",
       "      <td>[(ipsi I, 0.024086145154078375), (ipsi VII, 0....</td>\n",
       "      <td>[(contra V, 0.000611572144306829), (contra I, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>0.003484</td>\n",
       "      <td>late</td>\n",
       "      <td>True</td>\n",
       "      <td>[II, III, V]</td>\n",
       "      <td>[II, III, VII]</td>\n",
       "      <td>[IV, II, III, V]</td>\n",
       "      <td>[IV, II, III, VII]</td>\n",
       "      <td>0.077072</td>\n",
       "      <td>0.063330</td>\n",
       "      <td>0.094659</td>\n",
       "      <td>[(ipsi I, 0.032094726768564626), (ipsi VII, 0....</td>\n",
       "      <td>[(contra V, 0.006536611565867714), (contra I, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>77 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Percentage of patients T-stage  Midline Extension       Involvement Ipsi  \\\n",
       "0                 0.048780    late               True                   [II]   \n",
       "1                 0.010453   early              False                   [II]   \n",
       "2                 0.003484    late               True  [I, II, III, IV, VII]   \n",
       "3                 0.003484    late               True     [II, III, IV, VII]   \n",
       "4                 0.010453   early              False              [II, VII]   \n",
       "..                     ...     ...                ...                    ...   \n",
       "72                0.003484   early              False               [II, IV]   \n",
       "73                0.006969    late              False           [II, III, V]   \n",
       "74                0.003484    late               True              [II, III]   \n",
       "75                0.003484    late              False                [II, V]   \n",
       "76                0.003484    late               True           [II, III, V]   \n",
       "\n",
       "   Involvement Contra              Treated Ipsi      Treated Contra      risk  \\\n",
       "0                  []                 [III, II]                [II]  0.078032   \n",
       "1                [II]                 [III, II]           [III, II]  0.076328   \n",
       "2    [I, II, III, IV]  [V, I, II, III, IV, VII]    [I, II, III, IV]  0.061390   \n",
       "3                  []     [V, VII, II, III, IV]                [II]  0.066456   \n",
       "4                  []            [III, II, VII]                  []  0.063806   \n",
       "..                ...                       ...                 ...       ...   \n",
       "72                 []          [V, III, II, IV]                  []  0.062058   \n",
       "73                 []          [IV, II, III, V]                  []  0.075202   \n",
       "74      [II, III, IV]          [I, IV, II, III]    [V, II, III, IV]  0.066285   \n",
       "75                 []          [IV, III, II, V]                  []  0.066396   \n",
       "76     [II, III, VII]          [IV, II, III, V]  [IV, II, III, VII]  0.077072   \n",
       "\n",
       "    lower bound  upper bound  \\\n",
       "0      0.066303     0.091473   \n",
       "1      0.062081     0.097589   \n",
       "2      0.034468     0.095027   \n",
       "3      0.055051     0.077370   \n",
       "4      0.054496     0.073761   \n",
       "..          ...          ...   \n",
       "72     0.052172     0.072464   \n",
       "73     0.062002     0.087899   \n",
       "74     0.054837     0.080623   \n",
       "75     0.054162     0.077747   \n",
       "76     0.063330     0.094659   \n",
       "\n",
       "                               top 3 spared lnls risk  \\\n",
       "0   [(ipsi I, 0.02018212044831703), (ipsi VII, 0.0...   \n",
       "1   [(ipsi I, 0.020745164441888973), (contra I, 0....   \n",
       "2   [(contra V, 0.049917866263852986), (contra VII...   \n",
       "3   [(ipsi I, 0.028686386918113108), (contra III, ...   \n",
       "4   [(ipsi I, 0.021186904157757556), (contra II, 0...   \n",
       "..                                                ...   \n",
       "72  [(ipsi I, 0.022471174486049225), (ipsi VII, 0....   \n",
       "73  [(ipsi I, 0.02735384799828265), (ipsi VII, 0.0...   \n",
       "74  [(ipsi VII, 0.02303066023513181), (ipsi V, 0.0...   \n",
       "75  [(ipsi I, 0.024086145154078375), (ipsi VII, 0....   \n",
       "76  [(ipsi I, 0.032094726768564626), (ipsi VII, 0....   \n",
       "\n",
       "                                          lnls ranked  \n",
       "0   [(contra V, 0.0027096298969616446), (contra IV...  \n",
       "1   [(contra V, 0.0005149602766912587), (contra IV...  \n",
       "2   [(contra VII, 0.012112972989043888), (contra V...  \n",
       "3   [(contra I, 0.0036276705171799607), (contra V,...  \n",
       "4   [(contra V, 0.0005162140395875805), (contra I,...  \n",
       "..                                                ...  \n",
       "72  [(contra V, 0.0005607980420941032), (contra I,...  \n",
       "73  [(contra V, 0.0007207744996925012), (contra I,...  \n",
       "74  [(contra VII, 0.010017866467273907), (contra I...  \n",
       "75  [(contra V, 0.000611572144306829), (contra I, ...  \n",
       "76  [(contra V, 0.006536611565867714), (contra I, ...  \n",
       "\n",
       "[77 rows x 12 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data_export.sort_values(by = 'Percentage of patients', ascending = False, inplace = True)\n",
    "data_export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m treated_lnls_no_risk, treated_lnls_all, treatment_array, top3_spared, total_risks, treated_ipsi, treated_contra, sampled_risks_array \u001b[38;5;241m=\u001b[39m \u001b[43manalysis_treated_lnls_combinations\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcombinations\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mall_combinations\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msamples\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43msamples_reduced\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthreshold\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Risk_tables/sparing_scripts.py:314\u001b[0m, in \u001b[0;36manalysis_treated_lnls_combinations\u001b[0;34m(combinations, samples, model, threshold)\u001b[0m\n\u001b[1;32m    312\u001b[0m     diagnose_looper[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontra\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtreatment_diagnose\u001b[39m\u001b[38;5;124m'\u001b[39m][lnl_contra] \u001b[38;5;241m=\u001b[39m pattern[\u001b[38;5;241m8\u001b[39m\u001b[38;5;241m+\u001b[39mcounter_contra]\n\u001b[1;32m    313\u001b[0m     counter_contra \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m--> 314\u001b[0m sampled_risks, mean_risk \u001b[38;5;241m=\u001b[39m \u001b[43mrisk_sampled\u001b[49m\u001b[43m(\u001b[49m\u001b[43msamples\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43msamples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt_stage\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mstage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgiven_diagnoses\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdiagnose_looper\u001b[49m\u001b[43m,\u001b[49m\u001b[43mmidline_extension\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmidline_extension\u001b[49m\u001b[43m)\u001b[49m     \n\u001b[1;32m    315\u001b[0m spared_lnls, total_risk, ranked_combined, treated_lnls, treated_array, treated_ipsi, treated_contra, sampled_total_risks \u001b[38;5;241m=\u001b[39mlevels_to_spare_ci(threshold, model, mean_risk, sampled_risks)\n\u001b[1;32m    316\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m treated_lnls:\n",
      "File \u001b[0;32m~/Risk_tables/sparing_scripts.py:121\u001b[0m, in \u001b[0;36mrisk_sampled\u001b[0;34m(samples, model, t_stage, midline_extension, given_diagnoses, central)\u001b[0m\n\u001b[1;32m    102\u001b[0m     params \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmixing\u001b[39m\u001b[38;5;124m'\u001b[39m: sample[\u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m    103\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mipsi_primarytoI_spread\u001b[39m\u001b[38;5;124m'\u001b[39m: sample[\u001b[38;5;241m1\u001b[39m],\n\u001b[1;32m    104\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mipsi_primarytoII_spread\u001b[39m\u001b[38;5;124m'\u001b[39m: sample[\u001b[38;5;241m2\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIVtoV_spread\u001b[39m\u001b[38;5;124m'\u001b[39m: sample[\u001b[38;5;241m16\u001b[39m],\n\u001b[1;32m    119\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlate_p\u001b[39m\u001b[38;5;124m'\u001b[39m: sample[\u001b[38;5;241m17\u001b[39m]}\n\u001b[1;32m    120\u001b[0m     model\u001b[38;5;241m.\u001b[39mset_params(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams)\n\u001b[0;32m--> 121\u001b[0m     sampled_risks[i] \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrisk\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt_stage\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mt_stage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgiven_diagnoses\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mgiven_diagnoses\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmidline_extension\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmidline_extension\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcentral\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m \n\u001b[1;32m    122\u001b[0m mean_risk \u001b[38;5;241m=\u001b[39m sampled_risks\u001b[38;5;241m.\u001b[39mmean(axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m sampled_risks, mean_risk\n",
      "File \u001b[0;32m~/Risk_tables/.venv/lib/python3.10/site-packages/lymph/models/midline.py:715\u001b[0m, in \u001b[0;36mMidline.risk\u001b[0;34m(self, involvement, given_params, given_diagnoses, t_stage, midline_extension, central, mode)\u001b[0m\n\u001b[1;32m    708\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m midline_extension:\n\u001b[1;32m    709\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mext\u001b[38;5;241m.\u001b[39mrisk(\n\u001b[1;32m    710\u001b[0m         given_diagnoses\u001b[38;5;241m=\u001b[39mgiven_diagnoses,\n\u001b[1;32m    711\u001b[0m         t_stage\u001b[38;5;241m=\u001b[39mt_stage,\n\u001b[1;32m    712\u001b[0m         involvement\u001b[38;5;241m=\u001b[39minvolvement,\n\u001b[1;32m    713\u001b[0m         mode\u001b[38;5;241m=\u001b[39mmode,\n\u001b[1;32m    714\u001b[0m     )\n\u001b[0;32m--> 715\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnoext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrisk\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    716\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgiven_diagnoses\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgiven_diagnoses\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    717\u001b[0m \u001b[43m    \u001b[49m\u001b[43mt_stage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mt_stage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    718\u001b[0m \u001b[43m    \u001b[49m\u001b[43minvolvement\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minvolvement\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    719\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    720\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Risk_tables/.venv/lib/python3.10/site-packages/lymph/models/bilateral.py:649\u001b[0m, in \u001b[0;36mBilateral.risk\u001b[0;34m(self, involvement, given_params, given_diagnoses, t_stage, mode)\u001b[0m\n\u001b[1;32m    629\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Compute risk of an ``involvement`` pattern, given parameters and diagnoses.\u001b[39;00m\n\u001b[1;32m    630\u001b[0m \n\u001b[1;32m    631\u001b[0m \u001b[38;5;124;03mThe parameters can be set via the ``given_params`` and ``given_params``, both\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    646\u001b[0m \u001b[38;5;124;03m        only marginalizes over the states that match the involvement pattern.\u001b[39;00m\n\u001b[1;32m    647\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    648\u001b[0m \u001b[38;5;66;03m# TODO: test this method\u001b[39;00m\n\u001b[0;32m--> 649\u001b[0m posterior_state_probs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mposterior_joint_state_dist\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    650\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgiven_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgiven_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    651\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgiven_diagnoses\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgiven_diagnoses\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    652\u001b[0m \u001b[43m    \u001b[49m\u001b[43mt_stage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mt_stage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    653\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    654\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    656\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m involvement \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    657\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m posterior_state_probs\n",
      "File \u001b[0;32m~/Risk_tables/.venv/lib/python3.10/site-packages/lymph/models/bilateral.py:610\u001b[0m, in \u001b[0;36mBilateral.posterior_joint_state_dist\u001b[0;34m(self, given_params, given_diagnoses, t_stage, mode)\u001b[0m\n\u001b[1;32m    607\u001b[0m     \u001b[38;5;66;03m# vector with P(Z=z|X) for each state X. A data matrix for one \"patient\"\u001b[39;00m\n\u001b[1;32m    608\u001b[0m     diagnose_given_state[side] \u001b[38;5;241m=\u001b[39m diagnose_encoding \u001b[38;5;241m@\u001b[39m observation_matrix\u001b[38;5;241m.\u001b[39mT\n\u001b[0;32m--> 610\u001b[0m joint_state_dist \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstate_dist\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt_stage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mt_stage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    611\u001b[0m \u001b[38;5;66;03m# matrix with P(Zi=zi,Zc=zc|Xi,Xc) * P(Xi,Xc) for all states Xi,Xc.\u001b[39;00m\n\u001b[1;32m    612\u001b[0m joint_diagnose_and_state \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mouter(\n\u001b[1;32m    613\u001b[0m     diagnose_given_state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mipsi\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m    614\u001b[0m     diagnose_given_state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontra\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m    615\u001b[0m ) \u001b[38;5;241m*\u001b[39m joint_state_dist\n",
      "File \u001b[0;32m~/Risk_tables/.venv/lib/python3.10/site-packages/lymph/models/bilateral.py:427\u001b[0m, in \u001b[0;36mBilateral.state_dist\u001b[0;34m(self, t_stage, mode)\u001b[0m\n\u001b[1;32m    413\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Compute the joint distribution over the ipsi- & contralateral hidden states.\u001b[39;00m\n\u001b[1;32m    414\u001b[0m \n\u001b[1;32m    415\u001b[0m \u001b[38;5;124;03mThis computes the state distributions of both sides and returns their outer\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    424\u001b[0m \u001b[38;5;124;03m        combination of ipsi- and contralateral states.\u001b[39;00m\n\u001b[1;32m    425\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    426\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHMM\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 427\u001b[0m     ipsi_state_evo \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mipsi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstate_dist_evo\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    428\u001b[0m     contra_state_evo \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontra\u001b[38;5;241m.\u001b[39mstate_dist_evo()\n\u001b[1;32m    429\u001b[0m     time_marg_matrix \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdiag(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_distribution(t_stage)\u001b[38;5;241m.\u001b[39mpmf)\n",
      "File \u001b[0;32m~/Risk_tables/.venv/lib/python3.10/site-packages/lymph/models/unilateral.py:625\u001b[0m, in \u001b[0;36mUnilateral.state_dist_evo\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    622\u001b[0m state_dists[\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1.\u001b[39m\n\u001b[1;32m    624\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_time \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m--> 625\u001b[0m     state_dists[t] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevolve\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate_dists\u001b[49m\u001b[43m[\u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    627\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m state_dists\n",
      "File \u001b[0;32m~/Risk_tables/.venv/lib/python3.10/site-packages/lymph/models/unilateral.py:605\u001b[0m, in \u001b[0;36mUnilateral.evolve\u001b[0;34m(self, state_dist, num_steps)\u001b[0m\n\u001b[1;32m    597\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Evolve the ``state_dist`` of possible states over ``num_steps``.\u001b[39;00m\n\u001b[1;32m    598\u001b[0m \n\u001b[1;32m    599\u001b[0m \u001b[38;5;124;03mThis is done by multiplying the ``state_dist`` with the transition matrix\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    602\u001b[0m \u001b[38;5;124;03mis the number of steps ``num_steps``.\u001b[39;00m\n\u001b[1;32m    603\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    604\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_steps):\n\u001b[0;32m--> 605\u001b[0m     state_dist \u001b[38;5;241m=\u001b[39m state_dist \u001b[38;5;241m@\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransition_matrix\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    607\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m state_dist\n",
      "File \u001b[0;32m~/Risk_tables/.venv/lib/python3.10/site-packages/lymph/models/unilateral.py:402\u001b[0m, in \u001b[0;36mUnilateral.transition_matrix\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    375\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mtransition_matrix\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m np\u001b[38;5;241m.\u001b[39mndarray:\n\u001b[1;32m    376\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Matrix encoding the probabilities to transition from one state to another.\u001b[39;00m\n\u001b[1;32m    377\u001b[0m \n\u001b[1;32m    378\u001b[0m \u001b[38;5;124;03m    This is the crucial object for modelling the evolution of the probabilistic\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    400\u001b[0m \u001b[38;5;124;03m           [0.  , 0.  , 0.  , 1.  ]])\u001b[39;00m\n\u001b[1;32m    401\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 402\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmatrix\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_transition\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    403\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlnls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgraph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlnls\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    404\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_trinary\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    405\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Risk_tables/.venv/lib/python3.10/site-packages/lymph/matrix.py:58\u001b[0m, in \u001b[0;36mgenerate_transition\u001b[0;34m(lnls, num_states)\u001b[0m\n\u001b[1;32m     49\u001b[0m             parent_state_idx \u001b[38;5;241m=\u001b[39m get_state_idx_matrix(\n\u001b[1;32m     50\u001b[0m                 lnl_idx\u001b[38;5;241m=\u001b[39mparent_node_i,\n\u001b[1;32m     51\u001b[0m                 num_lnls\u001b[38;5;241m=\u001b[39mnum_lnls,\n\u001b[1;32m     52\u001b[0m                 num_states\u001b[38;5;241m=\u001b[39mnum_states,\n\u001b[1;32m     53\u001b[0m             )\n\u001b[1;32m     54\u001b[0m             edge_transition_grid \u001b[38;5;241m=\u001b[39m edge\u001b[38;5;241m.\u001b[39mtransition_tensor[\n\u001b[1;32m     55\u001b[0m                 parent_state_idx, current_state_idx, new_state_idx\n\u001b[1;32m     56\u001b[0m             ]\n\u001b[0;32m---> 58\u001b[0m         lnl_transition_matrix \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwhere\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;66;43;03m# For transitions, we need to compute the probability that none of\u001b[39;49;00m\n\u001b[1;32m     60\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;66;43;03m# the incoming edges of an LNL spread. This is done by multiplying\u001b[39;49;00m\n\u001b[1;32m     61\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;66;43;03m# the probabilities of all edges not spreading and taking the\u001b[39;49;00m\n\u001b[1;32m     62\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;66;43;03m# complement: 1 - (1 - p_1) * (1 - p_2) * ...\u001b[39;49;00m\n\u001b[1;32m     63\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;66;43;03m# If an LNL remains in its current state, the probability is\u001b[39;49;00m\n\u001b[1;32m     64\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;66;43;03m# simply the product of all incoming edges not spreading.\u001b[39;49;00m\n\u001b[1;32m     65\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnew_state_idx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mcurrent_state_idx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mlnl_transition_matrix\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43medge_transition_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[43m            \u001b[49m\u001b[43mlnl_transition_matrix\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43medge_transition_grid\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     70\u001b[0m     transition_matrix \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m lnl_transition_matrix\n\u001b[1;32m     72\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m transition_matrix\n",
      "File \u001b[0;32m~/Risk_tables/.venv/lib/python3.10/site-packages/numpy/core/multiarray.py:346\u001b[0m, in \u001b[0;36mwhere\u001b[0;34m(condition, x, y)\u001b[0m\n\u001b[1;32m    256\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    257\u001b[0m \u001b[38;5;124;03m    inner(a, b, /)\u001b[39;00m\n\u001b[1;32m    258\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    341\u001b[0m \n\u001b[1;32m    342\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m    343\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (a, b)\n\u001b[0;32m--> 346\u001b[0m \u001b[38;5;129m@array_function_from_c_func_and_dispatcher\u001b[39m(_multiarray_umath\u001b[38;5;241m.\u001b[39mwhere)\n\u001b[1;32m    347\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mwhere\u001b[39m(condition, x\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, y\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    348\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    349\u001b[0m \u001b[38;5;124;03m    where(condition, [x, y], /)\u001b[39;00m\n\u001b[1;32m    350\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    416\u001b[0m \u001b[38;5;124;03m           [ 0,  3, -1]])\u001b[39;00m\n\u001b[1;32m    417\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m    418\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (condition, x, y)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "treated_lnls_no_risk, treated_lnls_all, treatment_array, top3_spared, total_risks, treated_ipsi, treated_contra, sampled_risks_array = analysis_treated_lnls_combinations(combinations = all_combinations, model = model, samples = samples_reduced, threshold = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lnls = ['I','II', 'III', 'IV','V', 'VII']\n",
    "involvement_ipsi = []\n",
    "involvement_contra = []\n",
    "for diagnose_type in all_combinations:\n",
    "    involved_ipsi = []\n",
    "    involved_contra = []\n",
    "    for lnl_looper, involved_level in enumerate(lnls):\n",
    "        if diagnose_type[lnl_looper +2] == True:\n",
    "            involved_ipsi.append(involved_level) \n",
    "        if diagnose_type[lnl_looper +8] == True:\n",
    "            involved_contra.append(involved_level)\n",
    "    involvement_ipsi.append(involved_ipsi)\n",
    "    involvement_contra.append(involved_contra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['VII']"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "involvement_ipsi[0]\n",
    "involvement_contra[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "77"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ci.T[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sparing_scripts import ci_multiple\n",
    "df = pd.DataFrame(treatment_array)\n",
    "df.to_csv('treatment_array_full_trial.csv')\n",
    "ci = ci_multiple(sampled_risks_array)\n",
    "data_export = pd.DataFrame({'T-stage': np.array(all_combinations)[:,0],\n",
    "                                'Midline Extension': np.array(all_combinations)[:,1],\n",
    "                                'Involvement Ipsi' : involvement_ipsi,\n",
    "                                'Involvement Contra': involvement_contra,\n",
    "                                'Treated Ipsi':  treated_ipsi,\n",
    "                                'Treated Contra': treated_contra,\n",
    "                                'risk': total_risks,\n",
    "                                'lower bound': ci.T[0],\n",
    "                                'upper bound': ci.T[1],\n",
    "                                'top 3 spared lnls risk': top3_spared\n",
    "\n",
    "})\n",
    "data_export.to_csv('full_trial_table.csv', sep = ';', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Repetition for central tumors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analysis_treated_lnls_sampled_central(combinations, samples) :\n",
    "    treatment_array = np.zeros((len(combinations),12))\n",
    "    top3_spared = []\n",
    "    diagnose_looper = {\"ipsi\": {'max_llh_diagnose':{\n",
    "        \"I\": 0,\n",
    "        \"II\": 0,\n",
    "        \"III\": 0,\n",
    "        \"IV\": 0,\n",
    "        \"V\": 0,\n",
    "        \"VII\": 0\n",
    "    }},\n",
    "    \"contra\": {'max_llh_diagnose':{\n",
    "        \"I\": 0,\n",
    "        \"II\": 0,\n",
    "        \"III\": 0,\n",
    "        \"IV\": 0,\n",
    "        \"V\": 0,\n",
    "        \"VII\": 0\n",
    "    }}}\n",
    "    treated_lnls_all = []\n",
    "    treated_lnls_no_risk = []\n",
    "    total_risks = np.zeros(len(combinations))\n",
    "    sampled_risks_array = np.zeros((len(combinations),216))\n",
    "    treated_ipsi_all = []\n",
    "    treated_contra_all = []\n",
    "    for index, pattern in enumerate(combinations):\n",
    "        treated_looper = set()\n",
    "        stage = pattern[0]\n",
    "        counter_ipsi = 0\n",
    "        for lnl_ipsi, status in diagnose_looper['ipsi']['max_llh_diagnose'].items():\n",
    "            diagnose_looper['ipsi']['max_llh_diagnose'][lnl_ipsi] = pattern[1+counter_ipsi]\n",
    "            counter_ipsi += 1\n",
    "        counter_contra = 0\n",
    "        for lnl_contra, status in diagnose_looper['contra']['max_llh_diagnose'].items():\n",
    "            diagnose_looper['contra']['max_llh_diagnose'][lnl_contra] = pattern[7+counter_contra]\n",
    "            counter_contra += 1\n",
    "        sampled_risks, mean_risk = risk_sampled(samples = samples, model = model, t_stage = stage, given_diagnoses=diagnose_looper,central = True)     \n",
    "        spared_lnls, total_risk, ranked_combined, treated_lnls, treated_array, treated_ipsi, treated_contra, sampled_total_risks =levels_to_spare_ci(0.10, model, mean_risk, sampled_risks)\n",
    "        for i in treated_lnls:\n",
    "            treated_looper.add(i[0])\n",
    "        treated_lnls_all.append(treated_lnls)\n",
    "        treated_lnls_no_risk.append(treated_looper)\n",
    "        treatment_array[index] = treated_array\n",
    "        total_risks[index] = total_risk\n",
    "        sampled_risks_array[index] = sampled_total_risks\n",
    "        top3_spared.append(spared_lnls[::-1][:3])\n",
    "        treated_ipsi_all.append(treated_ipsi)\n",
    "        treated_contra_all.append(treated_contra)\n",
    "    return treated_lnls_no_risk, treated_lnls_all, treatment_array, top3_spared, total_risks, treated_ipsi_all, treated_contra_all, sampled_risks_array\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combination_array_central = np.zeros((2**13,13))\n",
    "for i in range(2**13):\n",
    "    combination_array_central[i] = [\n",
    "        int(digit) for digit in change_base(i, 2, length=13)\n",
    "    ]\n",
    "\n",
    "all_combinations_central = produce_combinations_list(combination_array_central)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "treated_lnls_no_risk_central, treated_lnls_all_central, treatment_array_central, top3_spared_central, total_risks_central, treated_ipsi_central, treated_contra_central, sampled_risks_array_central = analysis_treated_lnls_sampled_central(combinations = all_combinations_central, samples = samples1)\n",
    "set_counts_central = count_number_treatments(treated_lnls_no_risk_central)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lnls = ['I','II', 'III', 'IV','V', 'VII']\n",
    "involvement_ipsi_central = []\n",
    "involvement_contra_central = []\n",
    "for diagnose_type in all_combinations_central:\n",
    "    involved_ipsi = []\n",
    "    involved_contra = []\n",
    "    for lnl_looper, involved_level in enumerate(lnls):\n",
    "        if diagnose_type[lnl_looper +1] == True:\n",
    "            involved_ipsi.append(involved_level) \n",
    "        if diagnose_type[lnl_looper +7] == True:\n",
    "            involved_contra.append(involved_level)\n",
    "    involvement_ipsi_central.append(involved_ipsi)\n",
    "    involvement_contra_central.append(involved_contra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(treatment_array_central)\n",
    "df.to_csv('central_treatment_array_full_trial.csv')\n",
    "ci = ci_calculator(sampled_risks_array_central)\n",
    "data_export = pd.DataFrame({'T-stage': np.array(all_combinations_central)[:,0],\n",
    "                                'Involvement Ipsi' : involvement_ipsi_central,\n",
    "                                'Involvement Contra': involvement_contra_central,\n",
    "                                'Treated Ipsi':  treated_ipsi_central,\n",
    "                                'Treated Contra': treated_contra_central,\n",
    "                                'risk': total_risks_central,\n",
    "                                'lower bound': ci.T[0],\n",
    "                                'upper bound': ci.T[1],\n",
    "                                'top 3 spared lnls risk': top3_spared_central\n",
    "\n",
    "})\n",
    "data_export.to_csv('central_full_trial_table.csv', sep = ';', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
